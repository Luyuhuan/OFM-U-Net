nohup: ignoring input
using port 40920
I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 0 oversample 0.0
worker 0 batch_size 5

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [40, 192, 192], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7958984971046448, 0.7958984971046448], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset701_AbdomenCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.7958984971046448, 0.7958984971046448], 'original_median_shape_after_transp': [97, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 97.29716491699219, 'median': 118.0, 'min': -1024.0, 'percentile_00_5': -958.0, 'percentile_99_5': 270.0, 'std': 137.8484649658203}}} 

2024-04-12 15:54:55.695779: unpacking dataset...
2024-04-12 15:54:55.696214: unpacking done...
2024-04-12 15:54:55.697282: do_dummy_2d_data_aug: False
2024-04-12 15:54:55.713687: Unable to plot network architecture:
2024-04-12 15:54:55.714084: No module named 'hiddenlayer'
2024-04-12 15:54:55.724260: 
2024-04-12 15:54:55.724834: Epoch 0
2024-04-12 15:54:55.725288: Current learning rate: 0.001
I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 1 oversample 0.6600000000000001
worker 1 batch_size 5

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)
do_dummy_2d_data_aug: False

Epoch 0
Current learning rate: 0.001
using pin_memory on device 0
using pin_memory on device 1
using pin_memory on device 1
meanmse:       0.12481766
meanr2:        -0.003695563190176655
train_loss 3.0579
val_loss 2.5617
Pseudo dice [0.5]
Epoch time: 240.0 s
Yayy! New best R2: -0.0037

Epoch 1
Current learning rate: 0.00099
meanmse:       0.12570588
meanr2:        -0.003305056706509349
train_loss 2.5706
val_loss 2.5546
Pseudo dice [0.5]
Epoch time: 198.9 s
Yayy! New best R2: -0.0033

Epoch 2
Current learning rate: 0.00098
meanmse:       0.12563191
meanr2:        -0.006317091925507667
train_loss 2.5433
val_loss 2.5448
Pseudo dice [0.5]
Epoch time: 187.82 s

Epoch 3
Current learning rate: 0.00097
meanmse:       0.12528463
meanr2:        -0.005679084889946537
train_loss 2.5503
val_loss 2.5566
Pseudo dice [0.5]
Epoch time: 187.2 s

Epoch 4
Current learning rate: 0.00096
meanmse:       0.1261316
meanr2:        -0.008842116032982688
train_loss 2.5531
val_loss 2.5529
Pseudo dice [0.5]
Epoch time: 186.82 s

Epoch 5
Current learning rate: 0.00095
meanmse:       0.1258463
meanr2:        -0.0033832705943224687
train_loss 2.5581
val_loss 2.5529
Pseudo dice [0.5]
Epoch time: 186.79 s

Epoch 6
Current learning rate: 0.00095
meanmse:       0.1247813
meanr2:        -0.001493006105551102
train_loss 2.5506
val_loss 2.5383
Pseudo dice [0.5]
Epoch time: 195.34 s
Yayy! New best R2: -0.0015

Epoch 7
Current learning rate: 0.00094
meanmse:       0.12659903
meanr2:        -0.016427514161187307
train_loss 2.5469
val_loss 2.5617
Pseudo dice [0.5]
Epoch time: 191.32 s

Epoch 8
Current learning rate: 0.00093
meanmse:       0.12515898
meanr2:        -0.0026237733579032333
train_loss 2.546
val_loss 2.5507
Pseudo dice [0.5]
Epoch time: 192.69 s

Epoch 9
Current learning rate: 0.00092
meanmse:       0.12320996
meanr2:        0.00897765158622747
train_loss 2.5346
val_loss 2.5184
Pseudo dice [0.5]
Epoch time: 191.37 s
Yayy! New best R2: 0.009

Epoch 10
Current learning rate: 0.00091
meanmse:       0.121334724
meanr2:        0.031242863083904334
train_loss 2.5101
val_loss 2.4991
Pseudo dice [0.5]
Epoch time: 194.08 s
Yayy! New best R2: 0.0312

Epoch 11
Current learning rate: 0.0009
meanmse:       0.10542552
meanr2:        0.1515237626964425
train_loss 2.4295
val_loss 2.3827
Pseudo dice [0.5]
Epoch time: 192.69 s
Yayy! New best R2: 0.1515

Epoch 12
Current learning rate: 0.00089
meanmse:       0.100386426
meanr2:        0.18883901990844795
train_loss 2.3578
val_loss 2.321
Pseudo dice [0.5]
Epoch time: 192.94 s
Yayy! New best R2: 0.1888

Epoch 13
Current learning rate: 0.00088
meanmse:       0.100616105
meanr2:        0.200479941035334
train_loss 2.3124
val_loss 2.3162
Pseudo dice [0.5]
Epoch time: 196.1 s
Yayy! New best R2: 0.2005

Epoch 14
Current learning rate: 0.00087
meanmse:       0.100483745
meanr2:        0.19822279567395773
train_loss 2.2927
val_loss 2.2993
Pseudo dice [0.5]
Epoch time: 193.2 s

Epoch 15
Current learning rate: 0.00086
meanmse:       0.094376735
meanr2:        0.2355986643457822
train_loss 2.2591
val_loss 2.2539
Pseudo dice [0.5]
Epoch time: 187.57 s
Yayy! New best R2: 0.2356

Epoch 16
Current learning rate: 0.00085
meanmse:       0.08791481
meanr2:        0.2943244979348274
train_loss 2.2172
val_loss 2.1648
Pseudo dice [0.5]
Epoch time: 193.05 s
Yayy! New best R2: 0.2943

Epoch 17
Current learning rate: 0.00085
meanmse:       0.08117162
meanr2:        0.3495868066002017
train_loss 2.1272
val_loss 2.097
Pseudo dice [0.5]
Epoch time: 195.34 s
Yayy! New best R2: 0.3496

Epoch 18
Current learning rate: 0.00084
meanmse:       0.072354585
meanr2:        0.42513381664624794
train_loss 2.0537
val_loss 2.0142
Pseudo dice [0.5]
Epoch time: 196.3 s
Yayy! New best R2: 0.4251

Epoch 19
Current learning rate: 0.00083
meanmse:       0.072561204
meanr2:        0.415579347295807
train_loss 2.0099
val_loss 2.0035
Pseudo dice [0.5]
Epoch time: 190.32 s

Epoch 20
Current learning rate: 0.00082
meanmse:       0.06931345
meanr2:        0.4407596366802883
train_loss 1.9641
val_loss 1.9453
Pseudo dice [0.5]
Epoch time: 194.27 s
Yayy! New best R2: 0.4408

Epoch 21
Current learning rate: 0.00081
meanmse:       0.07125216
meanr2:        0.42046764802668884
train_loss 1.958
val_loss 1.9432
Pseudo dice [0.5]
Epoch time: 191.67 s

Epoch 22
Current learning rate: 0.0008
meanmse:       0.06536222
meanr2:        0.4670330046057824
train_loss 1.9575
val_loss 1.8809
Pseudo dice [0.5]
Epoch time: 191.45 s
Yayy! New best R2: 0.467

Epoch 23
Current learning rate: 0.00079
meanmse:       0.06521792
meanr2:        0.47446860776628824
train_loss 1.9437
val_loss 1.8877
Pseudo dice [0.5]
Epoch time: 192.51 s
Yayy! New best R2: 0.4745

Epoch 24
Current learning rate: 0.00078
meanmse:       0.06267094
meanr2:        0.4925848342889456
train_loss 1.8901
val_loss 1.879
Pseudo dice [0.5]
Epoch time: 187.35 s
Yayy! New best R2: 0.4926

Epoch 25
Current learning rate: 0.00077
meanmse:       0.06460056
meanr2:        0.47907537753089924
train_loss 1.864
val_loss 1.8802
Pseudo dice [0.5]
Epoch time: 193.52 s

Epoch 26
Current learning rate: 0.00076
meanmse:       0.061879884
meanr2:        0.5000588751284554
train_loss 1.8563
val_loss 1.8551
Pseudo dice [0.5]
Epoch time: 193.88 s
Yayy! New best R2: 0.5001

Epoch 27
Current learning rate: 0.00075
meanmse:       0.06481304
meanr2:        0.48208092936395847
train_loss 1.8313
val_loss 1.8578
Pseudo dice [0.5]
Epoch time: 192.67 s

Epoch 28
Current learning rate: 0.00074
meanmse:       0.06146796
meanr2:        0.5074686186760877
train_loss 1.8287
val_loss 1.8435
Pseudo dice [0.5]
Epoch time: 200.47 s
Yayy! New best R2: 0.5075

Epoch 29
Current learning rate: 0.00073
meanmse:       0.06073685
meanr2:        0.5059619133426095
train_loss 1.8133
val_loss 1.8425
Pseudo dice [0.5]
Epoch time: 194.04 s

Epoch 30
Current learning rate: 0.00073
meanmse:       0.062539384
meanr2:        0.4979051447217875
train_loss 1.8083
val_loss 1.8342
Pseudo dice [0.5]
Epoch time: 195.61 s

Epoch 31
Current learning rate: 0.00072
meanmse:       0.0604153
meanr2:        0.5127968298851404
train_loss 1.7993
val_loss 1.7987
Pseudo dice [0.5]
Epoch time: 191.57 s
Yayy! New best R2: 0.5128

Epoch 32
Current learning rate: 0.00071
meanmse:       0.058121085
meanr2:        0.536381200724012
train_loss 1.7739
val_loss 1.7858
Pseudo dice [0.5]
Epoch time: 193.71 s
Yayy! New best R2: 0.5364

Epoch 33
Current learning rate: 0.0007
meanmse:       0.054697916
meanr2:        0.5628477297098944
train_loss 1.7202
val_loss 1.7527
Pseudo dice [0.5]
Epoch time: 194.14 s
Yayy! New best R2: 0.5628

Epoch 34
Current learning rate: 0.00069
meanmse:       0.05265589
meanr2:        0.5749271926150903
train_loss 1.6659
val_loss 1.6916
Pseudo dice [0.5]
Epoch time: 195.1 s
Yayy! New best R2: 0.5749

Epoch 35
Current learning rate: 0.00068
meanmse:       0.047400497
meanr2:        0.6192159067977401
train_loss 1.57
val_loss 1.5747
Pseudo dice [0.5]
Epoch time: 185.12 s
Yayy! New best R2: 0.6192

Epoch 36
Current learning rate: 0.00067
meanmse:       0.044583872
meanr2:        0.6402427470810572
train_loss 1.4249
val_loss 1.4717
Pseudo dice [0.5]
Epoch time: 179.45 s
Yayy! New best R2: 0.6402

Epoch 37
Current learning rate: 0.00066
meanmse:       0.04065992
meanr2:        0.6735212646560279
train_loss 1.2912
val_loss 1.3715
Pseudo dice [0.5]
Epoch time: 176.37 s
Yayy! New best R2: 0.6735

Epoch 38
Current learning rate: 0.00065
meanmse:       0.036142632
meanr2:        0.7127066079268564
train_loss 1.1985
val_loss 1.303
Pseudo dice [0.5]
Epoch time: 182.79 s
Yayy! New best R2: 0.7127

Epoch 39
Current learning rate: 0.00064
meanmse:       0.037333615
meanr2:        0.6987749222905522
train_loss 1.1211
val_loss 1.25
Pseudo dice [0.5]
Epoch time: 179.69 s

Epoch 40
Current learning rate: 0.00063
meanmse:       0.033767227
meanr2:        0.7312109794731704
train_loss 1.0804
val_loss 1.1711
Pseudo dice [0.5]
Epoch time: 181.09 s
Yayy! New best R2: 0.7312

Epoch 41
Current learning rate: 0.00062
meanmse:       0.029640412
meanr2:        0.7614045383553875
train_loss 0.9738
val_loss 1.021
Pseudo dice [0.5]
Epoch time: 183.04 s
Yayy! New best R2: 0.7614

Epoch 42
Current learning rate: 0.00061
meanmse:       0.032116894
meanr2:        0.7438163032567746
train_loss 0.869
val_loss 0.9932
Pseudo dice [0.5]
Epoch time: 179.4 s

Epoch 43
Current learning rate: 0.0006
meanmse:       0.03229494
meanr2:        0.7410757780172001
train_loss 0.8081
val_loss 0.9748
Pseudo dice [0.5]
Epoch time: 181.85 s

Epoch 44
Current learning rate: 0.00059
meanmse:       0.024583874
meanr2:        0.8020217918048128
train_loss 0.7479
val_loss 0.8635
Pseudo dice [0.5]
Epoch time: 193.75 s
Yayy! New best R2: 0.802

Epoch 45
Current learning rate: 0.00058
meanmse:       0.023206573
meanr2:        0.8130305215682664
train_loss 0.7033
val_loss 0.8342
Pseudo dice [0.5]
Epoch time: 193.9 s
Yayy! New best R2: 0.813

Epoch 46
Current learning rate: 0.00057
meanmse:       0.022542672
meanr2:        0.8182386227071133
train_loss 0.6918
val_loss 0.7295
Pseudo dice [0.5]
Epoch time: 195.04 s
Yayy! New best R2: 0.8182

Epoch 47
Current learning rate: 0.00056
meanmse:       0.028757144
meanr2:        0.7670823057009339
train_loss 0.6257
val_loss 0.8267
Pseudo dice [0.5]
Epoch time: 193.9 s

Epoch 48
Current learning rate: 0.00056
meanmse:       0.030009853
meanr2:        0.7596031163063711
train_loss 0.594
val_loss 0.8371
Pseudo dice [0.5]
Epoch time: 195.63 s

Epoch 49
Current learning rate: 0.00055
meanmse:       0.022996591
meanr2:        0.8178826728048411
train_loss 0.5866
val_loss 0.7597
Pseudo dice [0.5]
Epoch time: 196.97 s

Epoch 50
Current learning rate: 0.00054
meanmse:       0.027851405
meanr2:        0.7769430345631739
train_loss 0.5735
val_loss 0.7849
Pseudo dice [0.5]
Epoch time: 198.51 s

Epoch 51
Current learning rate: 0.00053
meanmse:       0.027185673
meanr2:        0.7811468681660529
train_loss 0.5482
val_loss 0.7999
Pseudo dice [0.5]
Epoch time: 197.26 s

Epoch 52
Current learning rate: 0.00052
meanmse:       0.020501228
meanr2:        0.8344339843602924
train_loss 0.5357
val_loss 0.6507
Pseudo dice [0.5]
Epoch time: 194.85 s
Yayy! New best R2: 0.8344

Epoch 53
Current learning rate: 0.00051
meanmse:       0.023270715
meanr2:        0.8134680698367862
train_loss 0.5399
val_loss 0.6927
Pseudo dice [0.5]
Epoch time: 199.95 s

Epoch 54
Current learning rate: 0.0005
meanmse:       0.025328243
meanr2:        0.7962885385757555
train_loss 0.5115
val_loss 0.7468
Pseudo dice [0.5]
Epoch time: 200.96 s

Epoch 55
Current learning rate: 0.00049
meanmse:       0.02194643
meanr2:        0.8205459089175036
train_loss 0.5187
val_loss 0.7145
Pseudo dice [0.5]
Epoch time: 195.77 s

Epoch 56
Current learning rate: 0.00048
meanmse:       0.019443216
meanr2:        0.844736986599673
train_loss 0.481
val_loss 0.6217
Pseudo dice [0.5]
Epoch time: 194.88 s
Yayy! New best R2: 0.8447

Epoch 57
Current learning rate: 0.00047
meanmse:       0.026495354
meanr2:        0.7866261065044888
train_loss 0.4753
val_loss 0.732
Pseudo dice [0.5]
Epoch time: 195.93 s

Epoch 58
Current learning rate: 0.00046
meanmse:       0.026378779
meanr2:        0.7864209869134963
train_loss 0.455
val_loss 0.7357
Pseudo dice [0.5]
Epoch time: 195.93 s

Epoch 59
Current learning rate: 0.00045
meanmse:       0.025724154
meanr2:        0.7944251355207649
train_loss 0.4691
val_loss 0.6816
Pseudo dice [0.5]
Epoch time: 195.49 s

Epoch 60
Current learning rate: 0.00044
meanmse:       0.030915499
meanr2:        0.7500711409025747
train_loss 0.4574
val_loss 0.7887
Pseudo dice [0.5]
Epoch time: 197.21 s

Epoch 61
Current learning rate: 0.00043
meanmse:       0.021073833
meanr2:        0.8323889400145308
train_loss 0.4575
val_loss 0.6565
Pseudo dice [0.5]
Epoch time: 198.38 s

Epoch 62
Current learning rate: 0.00042
meanmse:       0.026675463
meanr2:        0.7867927592083248
train_loss 0.4354
val_loss 0.7261
Pseudo dice [0.5]
Epoch time: 200.52 s

Epoch 63
Current learning rate: 0.00041
meanmse:       0.022353189
meanr2:        0.8191580371012523
train_loss 0.4314
val_loss 0.6499
Pseudo dice [0.5]
Epoch time: 192.08 s

Epoch 64
Current learning rate: 0.0004
meanmse:       0.025369175
meanr2:        0.7940806952840492
train_loss 0.4353
val_loss 0.6691
Pseudo dice [0.5]
Epoch time: 197.78 s

Epoch 65
Current learning rate: 0.00039
meanmse:       0.023953991
meanr2:        0.8088035121591368
train_loss 0.4483
val_loss 0.6933
Pseudo dice [0.5]
Epoch time: 197.0 s

Epoch 66
Current learning rate: 0.00038
meanmse:       0.026243769
meanr2:        0.7912426258603894
train_loss 0.4309
val_loss 0.6884
Pseudo dice [0.5]
Epoch time: 195.21 s

Epoch 67
Current learning rate: 0.00037
meanmse:       0.02444769
meanr2:        0.8039649724289231
train_loss 0.413
val_loss 0.636
Pseudo dice [0.5]
Epoch time: 197.49 s

Epoch 68
Current learning rate: 0.00036
meanmse:       0.026835227
meanr2:        0.7876080264905952
train_loss 0.4288
val_loss 0.684
Pseudo dice [0.5]
Epoch time: 193.55 s

Epoch 69
Current learning rate: 0.00035
meanmse:       0.025391953
meanr2:        0.7972743486416505
train_loss 0.4281
val_loss 0.6991
Pseudo dice [0.5]
Epoch time: 192.85 s

Epoch 70
Current learning rate: 0.00034
meanmse:       0.031072665
meanr2:        0.7489553625871562
train_loss 0.42
val_loss 0.7369
Pseudo dice [0.5]
Epoch time: 196.29 s

Epoch 71
Current learning rate: 0.00033
meanmse:       0.025071185
meanr2:        0.800661536345745
train_loss 0.4026
val_loss 0.6794
Pseudo dice [0.5]
Epoch time: 197.12 s

Epoch 72
Current learning rate: 0.00032
meanmse:       0.024843711
meanr2:        0.8019680499175529
train_loss 0.424
val_loss 0.7008
Pseudo dice [0.5]
Epoch time: 194.99 s

Epoch 73
Current learning rate: 0.00031
meanmse:       0.023154104
meanr2:        0.8161345375011955
train_loss 0.4058
val_loss 0.6418
Pseudo dice [0.5]
Epoch time: 196.26 s

Epoch 74
Current learning rate: 0.0003
meanmse:       0.023295762
meanr2:        0.811631650976194
train_loss 0.4025
val_loss 0.6544
Pseudo dice [0.5]
Epoch time: 197.03 s

Epoch 75
Current learning rate: 0.00029
meanmse:       0.019719826
meanr2:        0.8392496224478194
train_loss 0.3978
val_loss 0.6501
Pseudo dice [0.5]
Epoch time: 194.91 s

Epoch 76
Current learning rate: 0.00028
meanmse:       0.02512507
meanr2:        0.7994029568206321
train_loss 0.3857
val_loss 0.6587
Pseudo dice [0.5]
Epoch time: 197.5 s

Epoch 77
Current learning rate: 0.00027
meanmse:       0.024186045
meanr2:        0.8043708381885963
train_loss 0.395
val_loss 0.6422
Pseudo dice [0.5]
Epoch time: 197.7 s

Epoch 78
Current learning rate: 0.00026
meanmse:       0.0262426
meanr2:        0.7892924863806962
train_loss 0.3928
val_loss 0.6666
Pseudo dice [0.5]
Epoch time: 199.75 s

Epoch 79
Current learning rate: 0.00025
meanmse:       0.02413782
meanr2:        0.8062609507124225
train_loss 0.3687
val_loss 0.6302
Pseudo dice [0.5]
Epoch time: 199.27 s

Epoch 80
Current learning rate: 0.00023
meanmse:       0.026169384
meanr2:        0.7915680388870953
train_loss 0.3756
val_loss 0.6311
Pseudo dice [0.5]
Epoch time: 193.73 s

Epoch 81
Current learning rate: 0.00022
meanmse:       0.022890728
meanr2:        0.8135375482567722
train_loss 0.3634
val_loss 0.6651
Pseudo dice [0.5]
Epoch time: 199.77 s

Epoch 82
Current learning rate: 0.00021
meanmse:       0.027659358
meanr2:        0.7763796870788261
train_loss 0.3584
val_loss 0.6678
Pseudo dice [0.5]
Epoch time: 194.39 s

Epoch 83
Current learning rate: 0.0002
meanmse:       0.01866633
meanr2:        0.849716074342176
train_loss 0.3558
val_loss 0.6488
Pseudo dice [0.5]
Epoch time: 191.7 s
Yayy! New best R2: 0.8497

Epoch 84
Current learning rate: 0.00019
meanmse:       0.02354111
meanr2:        0.8112435892497802
train_loss 0.3577
val_loss 0.7094
Pseudo dice [0.5]
Epoch time: 197.23 s

Epoch 85
Current learning rate: 0.00018
meanmse:       0.021843778
meanr2:        0.8251316939574044
train_loss 0.3541
val_loss 0.6028
Pseudo dice [0.5]
Epoch time: 198.5 s

Epoch 86
Current learning rate: 0.00017
meanmse:       0.024672685
meanr2:        0.8029773796023245
train_loss 0.3678
val_loss 0.6725
Pseudo dice [0.5]
Epoch time: 196.5 s

Epoch 87
Current learning rate: 0.00016
meanmse:       0.022509994
meanr2:        0.819310184638734
train_loss 0.3573
val_loss 0.649
Pseudo dice [0.5]
Epoch time: 194.58 s

Epoch 88
Current learning rate: 0.00015
meanmse:       0.020661537
meanr2:        0.8350682513358149
train_loss 0.3512
val_loss 0.6249
Pseudo dice [0.5]
Epoch time: 197.01 s

Epoch 89
Current learning rate: 0.00014
meanmse:       0.025008263
meanr2:        0.7991347379357724
train_loss 0.3433
val_loss 0.6299
Pseudo dice [0.5]
Epoch time: 197.96 s

Epoch 90
Current learning rate: 0.00013
meanmse:       0.022251315
meanr2:        0.8188685932482586
train_loss 0.3233
val_loss 0.631
Pseudo dice [0.5]
Epoch time: 196.54 s

Epoch 91
Current learning rate: 0.00011
meanmse:       0.02192305
meanr2:        0.8238006615478315
train_loss 0.3379
val_loss 0.6142
Pseudo dice [0.5]
Epoch time: 195.96 s

Epoch 92
Current learning rate: 0.0001
meanmse:       0.025526052
meanr2:        0.7946496442165883
train_loss 0.3366
val_loss 0.7056
Pseudo dice [0.5]
Epoch time: 196.7 s

Epoch 93
Current learning rate: 9e-05
meanmse:       0.028106757
meanr2:        0.7749578883226093
train_loss 0.3329
val_loss 0.7047
Pseudo dice [0.5]
Epoch time: 199.04 s

Epoch 94
Current learning rate: 8e-05
meanmse:       0.0257031
meanr2:        0.7935564987805378
train_loss 0.3378
val_loss 0.6455
Pseudo dice [0.5]
Epoch time: 193.07 s

Epoch 95
Current learning rate: 7e-05
meanmse:       0.024887146
meanr2:        0.801125747353159
train_loss 0.3457
val_loss 0.6877
Pseudo dice [0.5]
Epoch time: 196.9 s

Epoch 96
Current learning rate: 6e-05
meanmse:       0.026174318
meanr2:        0.7898763362080031
train_loss 0.3352
val_loss 0.6536
Pseudo dice [0.5]
Epoch time: 193.49 s

Epoch 97
Current learning rate: 4e-05
meanmse:       0.024019176
meanr2:        0.807259925426674
train_loss 0.3454
val_loss 0.6498
Pseudo dice [0.5]
Epoch time: 199.32 s

Epoch 98
Current learning rate: 3e-05
meanmse:       0.030423708
meanr2:        0.7544793148802619
train_loss 0.3783
val_loss 0.6956
Pseudo dice [0.5]
Epoch time: 160.19 s

Epoch 99
Current learning rate: 2e-05
meanmse:       0.023184953
meanr2:        0.8142755614654011
train_loss 0.4141
val_loss 0.6832
Pseudo dice [0.5]
Epoch time: 133.26 s
Training done.
predicting 20190409_105008_139
using pin_memory on device 0
2024-04-12 15:58:55.741552: meanmse:       0.12459974
2024-04-12 15:58:55.743248: meanr2:        -0.009854409013044381
2024-04-12 15:58:55.744288: train_loss 3.0579
2024-04-12 15:58:55.750812: val_loss 2.5617
2024-04-12 15:58:55.751536: Pseudo dice [0.5]
2024-04-12 15:58:55.752254: Epoch time: 240.03 s
2024-04-12 15:58:55.752871: Yayy! New best R2: -0.0099
2024-04-12 15:58:58.494920: 
2024-04-12 15:58:58.495829: Epoch 1
2024-04-12 15:58:58.496412: Current learning rate: 0.00099
2024-04-12 16:02:14.638012: meanmse:       0.12450166
2024-04-12 16:02:14.645137: meanr2:        -0.00707424409981315
2024-04-12 16:02:14.647036: train_loss 2.5706
2024-04-12 16:02:14.647666: val_loss 2.5546
2024-04-12 16:02:14.648469: Pseudo dice [0.5]
2024-04-12 16:02:14.650399: Epoch time: 196.16 s
2024-04-12 16:02:14.654111: Yayy! New best R2: -0.0071
2024-04-12 16:02:18.378431: 
2024-04-12 16:02:18.379515: Epoch 2
2024-04-12 16:02:18.380219: Current learning rate: 0.00098
2024-04-12 16:05:22.465950: meanmse:       0.123798676
2024-04-12 16:05:22.467698: meanr2:        -0.005266925631997998
2024-04-12 16:05:22.468598: train_loss 2.5433
2024-04-12 16:05:22.469211: val_loss 2.5448
2024-04-12 16:05:22.469864: Pseudo dice [0.5]
2024-04-12 16:05:22.470489: Epoch time: 184.1 s
2024-04-12 16:05:22.471149: Yayy! New best R2: -0.0053
2024-04-12 16:05:25.837718: 
2024-04-12 16:05:25.839143: Epoch 3
2024-04-12 16:05:25.839896: Current learning rate: 0.00097
2024-04-12 16:08:29.667531: meanmse:       0.12591578
2024-04-12 16:08:29.668967: meanr2:        -0.006402564973941346
2024-04-12 16:08:29.669578: train_loss 2.5503
2024-04-12 16:08:29.670104: val_loss 2.5566
2024-04-12 16:08:29.670579: Pseudo dice [0.5]
2024-04-12 16:08:29.671072: Epoch time: 183.9 s
2024-04-12 16:08:32.449942: 
2024-04-12 16:08:32.450862: Epoch 4
2024-04-12 16:08:32.451528: Current learning rate: 0.00096
2024-04-12 16:11:36.488464: meanmse:       0.12554654
2024-04-12 16:11:36.489431: meanr2:        -0.008692839265847675
2024-04-12 16:11:36.489908: train_loss 2.5531
2024-04-12 16:11:36.490323: val_loss 2.5529
2024-04-12 16:11:36.490714: Pseudo dice [0.5]
2024-04-12 16:11:36.491140: Epoch time: 184.05 s
2024-04-12 16:11:39.302506: 
2024-04-12 16:11:39.303406: Epoch 5
2024-04-12 16:11:39.303992: Current learning rate: 0.00095
2024-04-12 16:14:43.275868: meanmse:       0.12509829
2024-04-12 16:14:43.277234: meanr2:        -0.006415261255023705
2024-04-12 16:14:43.278247: train_loss 2.5581
2024-04-12 16:14:43.278913: val_loss 2.5529
2024-04-12 16:14:43.279526: Pseudo dice [0.5]
2024-04-12 16:14:43.280093: Epoch time: 183.98 s
2024-04-12 16:14:45.930759: 
2024-04-12 16:14:45.932473: Epoch 6
2024-04-12 16:14:45.943067: Current learning rate: 0.00095
2024-04-12 16:17:58.579364: meanmse:       0.123367354
2024-04-12 16:17:58.617301: meanr2:        -0.005567497034260571
2024-04-12 16:17:58.618107: train_loss 2.5506
2024-04-12 16:17:58.618591: val_loss 2.5383
2024-04-12 16:17:58.619125: Pseudo dice [0.5]
2024-04-12 16:17:58.619685: Epoch time: 192.69 s
2024-04-12 16:18:00.998346: 
2024-04-12 16:18:00.999228: Epoch 7
2024-04-12 16:18:00.999825: Current learning rate: 0.00094
2024-04-12 16:21:09.934342: meanmse:       0.12829176
2024-04-12 16:21:09.936219: meanr2:        -0.02776433704782618
2024-04-12 16:21:09.937230: train_loss 2.5469
2024-04-12 16:21:09.938008: val_loss 2.5617
2024-04-12 16:21:09.938630: Pseudo dice [0.5]
2024-04-12 16:21:09.939255: Epoch time: 188.95 s
2024-04-12 16:21:12.693987: 
2024-04-12 16:21:12.717793: Epoch 8
2024-04-12 16:21:12.718543: Current learning rate: 0.00093
2024-04-12 16:24:22.628174: meanmse:       0.12571369
2024-04-12 16:24:22.629654: meanr2:        -0.005651411723599509
2024-04-12 16:24:22.630428: train_loss 2.546
2024-04-12 16:24:22.631115: val_loss 2.5507
2024-04-12 16:24:22.631724: Pseudo dice [0.5]
2024-04-12 16:24:22.632312: Epoch time: 189.94 s
2024-04-12 16:24:25.919143: 
2024-04-12 16:24:25.920637: Epoch 9
2024-04-12 16:24:25.921439: Current learning rate: 0.00092
2024-04-12 16:27:33.994150: meanmse:       0.12216702
2024-04-12 16:27:33.995634: meanr2:        0.009964884976752166
2024-04-12 16:27:33.996321: train_loss 2.5346
2024-04-12 16:27:33.996907: val_loss 2.5184
2024-04-12 16:27:33.997439: Pseudo dice [0.5]
2024-04-12 16:27:33.997965: Epoch time: 188.1 s
2024-04-12 16:27:34.544676: Yayy! New best R2: 0.01
2024-04-12 16:27:37.526302: 
2024-04-12 16:27:37.527401: Epoch 10
2024-04-12 16:27:37.528114: Current learning rate: 0.00091
2024-04-12 16:30:48.073696: meanmse:       0.120035
2024-04-12 16:30:48.075162: meanr2:        0.03618799588063926
2024-04-12 16:30:48.075887: train_loss 2.5101
2024-04-12 16:30:48.076477: val_loss 2.4991
2024-04-12 16:30:48.077058: Pseudo dice [0.5]
2024-04-12 16:30:48.077632: Epoch time: 190.56 s
2024-04-12 16:30:48.078227: Yayy! New best R2: 0.0362
2024-04-12 16:30:51.026474: 
2024-04-12 16:30:51.027353: Epoch 11
2024-04-12 16:30:51.027937: Current learning rate: 0.0009
2024-04-12 16:34:00.768749: meanmse:       0.106161736
2024-04-12 16:34:00.770006: meanr2:        0.14992088132368522
2024-04-12 16:34:00.770626: train_loss 2.4295
2024-04-12 16:34:00.771231: val_loss 2.3827
2024-04-12 16:34:00.771698: Pseudo dice [0.5]
2024-04-12 16:34:00.772145: Epoch time: 189.75 s
2024-04-12 16:34:00.772643: Yayy! New best R2: 0.1499
2024-04-12 16:34:04.074875: 
2024-04-12 16:34:04.075975: Epoch 12
2024-04-12 16:34:04.076634: Current learning rate: 0.00089
2024-04-12 16:37:13.707542: meanmse:       0.10061094
2024-04-12 16:37:13.708925: meanr2:        0.18848426365976537
2024-04-12 16:37:13.709656: train_loss 2.3578
2024-04-12 16:37:13.710263: val_loss 2.321
2024-04-12 16:37:13.710852: Pseudo dice [0.5]
2024-04-12 16:37:13.711435: Epoch time: 189.64 s
2024-04-12 16:37:13.712033: Yayy! New best R2: 0.1885
2024-04-12 16:37:17.108063: 
2024-04-12 16:37:17.108989: Epoch 13
2024-04-12 16:37:17.109612: Current learning rate: 0.00088
2024-04-12 16:40:29.810233: meanmse:       0.09956504
2024-04-12 16:40:29.811517: meanr2:        0.19518887736675936
2024-04-12 16:40:29.812075: train_loss 2.3124
2024-04-12 16:40:29.812549: val_loss 2.3162
2024-04-12 16:40:29.813030: Pseudo dice [0.5]
2024-04-12 16:40:29.813489: Epoch time: 192.71 s
2024-04-12 16:40:29.813961: Yayy! New best R2: 0.1952
2024-04-12 16:40:33.424416: 
2024-04-12 16:40:33.425078: Epoch 14
2024-04-12 16:40:33.425622: Current learning rate: 0.00087
2024-04-12 16:43:43.008689: meanmse:       0.09832363
2024-04-12 16:43:43.010102: meanr2:        0.2247304804888997
2024-04-12 16:43:43.010717: train_loss 2.2927
2024-04-12 16:43:43.011187: val_loss 2.2993
2024-04-12 16:43:43.017228: Pseudo dice [0.5]
2024-04-12 16:43:43.017758: Epoch time: 189.59 s
2024-04-12 16:43:43.018322: Yayy! New best R2: 0.2247
2024-04-12 16:43:46.441892: 
2024-04-12 16:43:46.442813: Epoch 15
2024-04-12 16:43:46.443490: Current learning rate: 0.00086
2024-04-12 16:46:50.577932: meanmse:       0.09561338
2024-04-12 16:46:50.579837: meanr2:        0.23397577006249556
2024-04-12 16:46:50.580630: train_loss 2.2591
2024-04-12 16:46:50.581185: val_loss 2.2539
2024-04-12 16:46:50.581718: Pseudo dice [0.5]
2024-04-12 16:46:50.582314: Epoch time: 184.15 s
2024-04-12 16:46:50.583265: Yayy! New best R2: 0.234
2024-04-12 16:46:54.335363: 
2024-04-12 16:46:54.336266: Epoch 16
2024-04-12 16:46:54.336853: Current learning rate: 0.00085
2024-04-12 16:50:03.623775: meanmse:       0.087625414
2024-04-12 16:50:03.625213: meanr2:        0.29164905919988077
2024-04-12 16:50:03.625932: train_loss 2.2172
2024-04-12 16:50:03.626477: val_loss 2.1648
2024-04-12 16:50:03.626962: Pseudo dice [0.5]
2024-04-12 16:50:03.627472: Epoch time: 189.31 s
2024-04-12 16:50:03.627996: Yayy! New best R2: 0.2916
2024-04-12 16:50:07.431655: 
2024-04-12 16:50:07.432799: Epoch 17
2024-04-12 16:50:07.433702: Current learning rate: 0.00085
2024-04-12 16:53:18.962291: meanmse:       0.08054958
2024-04-12 16:53:18.963834: meanr2:        0.3522365578328258
2024-04-12 16:53:18.964484: train_loss 2.1272
2024-04-12 16:53:18.964976: val_loss 2.097
2024-04-12 16:53:18.965475: Pseudo dice [0.5]
2024-04-12 16:53:18.966171: Epoch time: 191.55 s
2024-04-12 16:53:18.966936: Yayy! New best R2: 0.3522
2024-04-12 16:53:21.970305: 
2024-04-12 16:53:21.971199: Epoch 18
2024-04-12 16:53:21.971797: Current learning rate: 0.00084
2024-04-12 16:56:35.258596: meanmse:       0.075339146
2024-04-12 16:56:35.260105: meanr2:        0.3965350312196136
2024-04-12 16:56:35.260874: train_loss 2.0537
2024-04-12 16:56:35.261383: val_loss 2.0142
2024-04-12 16:56:35.261927: Pseudo dice [0.5]
2024-04-12 16:56:35.262659: Epoch time: 193.3 s
2024-04-12 16:56:35.263254: Yayy! New best R2: 0.3965
2024-04-12 16:56:39.301262: 
2024-04-12 16:56:39.302068: Epoch 19
2024-04-12 16:56:39.302571: Current learning rate: 0.00083
2024-04-12 16:59:45.582536: meanmse:       0.07554341
2024-04-12 16:59:45.583640: meanr2:        0.4012586100113879
2024-04-12 16:59:45.584179: train_loss 2.0099
2024-04-12 16:59:45.584613: val_loss 2.0035
2024-04-12 16:59:45.584997: Pseudo dice [0.5]
2024-04-12 16:59:45.585643: Epoch time: 186.29 s
2024-04-12 16:59:46.390790: Yayy! New best R2: 0.4013
2024-04-12 16:59:49.599374: 
2024-04-12 16:59:49.600645: Epoch 20
2024-04-12 16:59:49.601436: Current learning rate: 0.00082
2024-04-12 17:02:59.853162: meanmse:       0.06983436
2024-04-12 17:02:59.854892: meanr2:        0.4397017774167841
2024-04-12 17:02:59.855674: train_loss 1.9641
2024-04-12 17:02:59.856319: val_loss 1.9453
2024-04-12 17:02:59.856952: Pseudo dice [0.5]
2024-04-12 17:02:59.857569: Epoch time: 190.27 s
2024-04-12 17:02:59.858183: Yayy! New best R2: 0.4397
2024-04-12 17:03:03.705524: 
2024-04-12 17:03:03.706203: Epoch 21
2024-04-12 17:03:03.706669: Current learning rate: 0.00081
2024-04-12 17:06:11.525436: meanmse:       0.066956416
2024-04-12 17:06:11.526612: meanr2:        0.45639446190377764
2024-04-12 17:06:11.527278: train_loss 1.958
2024-04-12 17:06:11.527786: val_loss 1.9432
2024-04-12 17:06:11.528265: Pseudo dice [0.5]
2024-04-12 17:06:11.528773: Epoch time: 187.83 s
2024-04-12 17:06:11.529341: Yayy! New best R2: 0.4564
2024-04-12 17:06:14.344516: 
2024-04-12 17:06:14.345524: Epoch 22
2024-04-12 17:06:14.346178: Current learning rate: 0.0008
2024-04-12 17:09:22.972914: meanmse:       0.06546333
2024-04-12 17:09:22.974155: meanr2:        0.4715280598740001
2024-04-12 17:09:22.974798: train_loss 1.9575
2024-04-12 17:09:22.975339: val_loss 1.8809
2024-04-12 17:09:22.975971: Pseudo dice [0.5]
2024-04-12 17:09:22.976511: Epoch time: 188.64 s
2024-04-12 17:09:22.977038: Yayy! New best R2: 0.4715
2024-04-12 17:09:26.316379: 
2024-04-12 17:09:26.317128: Epoch 23
2024-04-12 17:09:26.317663: Current learning rate: 0.00079
2024-04-12 17:12:35.479144: meanmse:       0.066539094
2024-04-12 17:12:35.480489: meanr2:        0.4606788037750366
2024-04-12 17:12:35.481214: train_loss 1.9437
2024-04-12 17:12:35.481785: val_loss 1.8877
2024-04-12 17:12:35.482310: Pseudo dice [0.5]
2024-04-12 17:12:35.482864: Epoch time: 189.17 s
2024-04-12 17:12:38.312374: 
2024-04-12 17:12:38.313240: Epoch 24
2024-04-12 17:12:38.313842: Current learning rate: 0.00078
2024-04-12 17:15:42.824636: meanmse:       0.06373349
2024-04-12 17:15:42.825870: meanr2:        0.4902293919788402
2024-04-12 17:15:42.826460: train_loss 1.8901
2024-04-12 17:15:42.826966: val_loss 1.879
2024-04-12 17:15:42.827474: Pseudo dice [0.5]
2024-04-12 17:15:42.827975: Epoch time: 184.52 s
2024-04-12 17:15:42.828488: Yayy! New best R2: 0.4902
2024-04-12 17:15:45.889608: 
2024-04-12 17:15:45.890688: Epoch 25
2024-04-12 17:15:45.891410: Current learning rate: 0.00077
2024-04-12 17:18:56.343227: meanmse:       0.0647104
2024-04-12 17:18:56.344571: meanr2:        0.4721947089139119
2024-04-12 17:18:56.345252: train_loss 1.864
2024-04-12 17:18:56.345834: val_loss 1.8802
2024-04-12 17:18:56.346386: Pseudo dice [0.5]
2024-04-12 17:18:56.346993: Epoch time: 190.47 s
2024-04-12 17:18:58.954765: 
2024-04-12 17:18:58.955806: Epoch 26
2024-04-12 17:18:58.956511: Current learning rate: 0.00076
2024-04-12 17:22:10.225843: meanmse:       0.06368609
2024-04-12 17:22:10.238602: meanr2:        0.49110779527812504
2024-04-12 17:22:10.240011: train_loss 1.8563
2024-04-12 17:22:10.240881: val_loss 1.8551
2024-04-12 17:22:10.332746: Pseudo dice [0.5]
2024-04-12 17:22:10.333852: Epoch time: 191.29 s
2024-04-12 17:22:10.334491: Yayy! New best R2: 0.4911
2024-04-12 17:22:13.437517: 
2024-04-12 17:22:13.438795: Epoch 27
2024-04-12 17:22:13.439579: Current learning rate: 0.00075
2024-04-12 17:25:22.899389: meanmse:       0.06160724
2024-04-12 17:25:22.900448: meanr2:        0.5073047116857307
2024-04-12 17:25:22.900969: train_loss 1.8313
2024-04-12 17:25:22.901367: val_loss 1.8578
2024-04-12 17:25:22.901733: Pseudo dice [0.5]
2024-04-12 17:25:22.902110: Epoch time: 189.47 s
2024-04-12 17:25:22.902521: Yayy! New best R2: 0.5073
2024-04-12 17:25:25.973383: 
2024-04-12 17:25:26.023620: Epoch 28
2024-04-12 17:25:26.024606: Current learning rate: 0.00074
2024-04-12 17:28:43.371723: meanmse:       0.062233053
2024-04-12 17:28:43.373219: meanr2:        0.5027773828039186
2024-04-12 17:28:43.373971: train_loss 1.8287
2024-04-12 17:28:43.374689: val_loss 1.8435
2024-04-12 17:28:43.376187: Pseudo dice [0.5]
2024-04-12 17:28:43.376954: Epoch time: 197.41 s
2024-04-12 17:28:45.980487: 
2024-04-12 17:28:45.981345: Epoch 29
2024-04-12 17:28:45.981887: Current learning rate: 0.00073
2024-04-12 17:31:57.413524: meanmse:       0.06148264
2024-04-12 17:31:57.414685: meanr2:        0.5064826587827266
2024-04-12 17:31:57.415381: train_loss 1.8133
2024-04-12 17:31:57.415931: val_loss 1.8425
2024-04-12 17:31:57.416403: Pseudo dice [0.5]
2024-04-12 17:31:57.416906: Epoch time: 191.44 s
2024-04-12 17:32:00.945343: 
2024-04-12 17:32:00.946520: Epoch 30
2024-04-12 17:32:00.947445: Current learning rate: 0.00073
2024-04-12 17:35:13.021310: meanmse:       0.059805382
2024-04-12 17:35:13.022498: meanr2:        0.5116284085683547
2024-04-12 17:35:13.023068: train_loss 1.8083
2024-04-12 17:35:13.023677: val_loss 1.8342
2024-04-12 17:35:13.024146: Pseudo dice [0.5]
2024-04-12 17:35:13.024665: Epoch time: 192.09 s
2024-04-12 17:35:13.025286: Yayy! New best R2: 0.5116
2024-04-12 17:35:16.527680: 
2024-04-12 17:35:16.528831: Epoch 31
2024-04-12 17:35:16.529560: Current learning rate: 0.00072
2024-04-12 17:38:24.589023: meanmse:       0.058947098
2024-04-12 17:38:24.590088: meanr2:        0.5188318306717127
2024-04-12 17:38:24.590587: train_loss 1.7993
2024-04-12 17:38:24.590989: val_loss 1.7987
2024-04-12 17:38:24.591420: Pseudo dice [0.5]
2024-04-12 17:38:24.591831: Epoch time: 188.07 s
2024-04-12 17:38:24.592228: Yayy! New best R2: 0.5188
2024-04-12 17:38:27.910016: 
2024-04-12 17:38:27.911163: Epoch 32
2024-04-12 17:38:27.911828: Current learning rate: 0.00071
2024-04-12 17:41:38.299577: meanmse:       0.057391606
2024-04-12 17:41:38.300894: meanr2:        0.535626691714768
2024-04-12 17:41:38.321067: train_loss 1.7739
2024-04-12 17:41:38.322128: val_loss 1.7858
2024-04-12 17:41:38.322839: Pseudo dice [0.5]
2024-04-12 17:41:38.323512: Epoch time: 190.42 s
2024-04-12 17:41:38.324213: Yayy! New best R2: 0.5356
2024-04-12 17:41:41.297839: 
2024-04-12 17:41:41.298635: Epoch 33
2024-04-12 17:41:41.299185: Current learning rate: 0.0007
2024-04-12 17:44:52.435279: meanmse:       0.058266714
2024-04-12 17:44:52.436667: meanr2:        0.5357012435421147
2024-04-12 17:44:52.437264: train_loss 1.7202
2024-04-12 17:44:52.437759: val_loss 1.7527
2024-04-12 17:44:52.438264: Pseudo dice [0.5]
2024-04-12 17:44:52.438807: Epoch time: 191.15 s
2024-04-12 17:44:52.439379: Yayy! New best R2: 0.5357
2024-04-12 17:44:56.623365: 
2024-04-12 17:44:56.624839: Epoch 34
2024-04-12 17:44:56.625736: Current learning rate: 0.00069
2024-04-12 17:48:07.536448: meanmse:       0.05313771
2024-04-12 17:48:07.537843: meanr2:        0.5710590944687068
2024-04-12 17:48:07.538494: train_loss 1.6659
2024-04-12 17:48:07.538988: val_loss 1.6916
2024-04-12 17:48:07.539540: Pseudo dice [0.5]
2024-04-12 17:48:07.540133: Epoch time: 190.95 s
2024-04-12 17:48:07.540707: Yayy! New best R2: 0.5711
2024-04-12 17:48:10.819213: 
2024-04-12 17:48:10.820198: Epoch 35
2024-04-12 17:48:10.820764: Current learning rate: 0.00068
2024-04-12 17:51:12.655728: meanmse:       0.046859037
2024-04-12 17:51:12.657266: meanr2:        0.6154687698253514
2024-04-12 17:51:12.658484: train_loss 1.57
2024-04-12 17:51:12.659119: val_loss 1.5747
2024-04-12 17:51:12.659732: Pseudo dice [0.5]
2024-04-12 17:51:12.660343: Epoch time: 181.85 s
2024-04-12 17:51:12.660900: Yayy! New best R2: 0.6155
2024-04-12 17:51:15.955278: 
2024-04-12 17:51:15.956250: Epoch 36
2024-04-12 17:51:15.956945: Current learning rate: 0.00067
2024-04-12 17:54:12.103430: meanmse:       0.04105805
2024-04-12 17:54:12.107361: meanr2:        0.6702905668892166
2024-04-12 17:54:12.108219: train_loss 1.4249
2024-04-12 17:54:12.109476: val_loss 1.4717
2024-04-12 17:54:12.110089: Pseudo dice [0.5]
2024-04-12 17:54:12.111585: Epoch time: 176.16 s
2024-04-12 17:54:12.112088: Yayy! New best R2: 0.6703
2024-04-12 17:54:15.713018: 
2024-04-12 17:54:15.713921: Epoch 37
2024-04-12 17:54:15.725970: Current learning rate: 0.00066
2024-04-12 17:57:08.472768: meanmse:       0.039244525
2024-04-12 17:57:08.474039: meanr2:        0.6839874284856192
2024-04-12 17:57:08.474634: train_loss 1.2912
2024-04-12 17:57:08.475099: val_loss 1.3715
2024-04-12 17:57:08.475535: Pseudo dice [0.5]
2024-04-12 17:57:08.475986: Epoch time: 172.77 s
2024-04-12 17:57:08.517289: Yayy! New best R2: 0.684
2024-04-12 17:57:12.085397: 
2024-04-12 17:57:12.086243: Epoch 38
2024-04-12 17:57:12.086774: Current learning rate: 0.00065
2024-04-12 18:00:11.267577: meanmse:       0.03796265
2024-04-12 18:00:11.268793: meanr2:        0.6972704396045771
2024-04-12 18:00:11.269371: train_loss 1.1985
2024-04-12 18:00:11.269836: val_loss 1.303
2024-04-12 18:00:11.270301: Pseudo dice [0.5]
2024-04-12 18:00:11.270761: Epoch time: 179.19 s
2024-04-12 18:00:11.271238: Yayy! New best R2: 0.6973
2024-04-12 18:00:14.761300: 
2024-04-12 18:00:14.762060: Epoch 39
2024-04-12 18:00:14.762583: Current learning rate: 0.00064
2024-04-12 18:03:10.961052: meanmse:       0.035809595
2024-04-12 18:03:10.962133: meanr2:        0.7143621284201932
2024-04-12 18:03:10.962686: train_loss 1.1211
2024-04-12 18:03:10.963089: val_loss 1.25
2024-04-12 18:03:10.963480: Pseudo dice [0.5]
2024-04-12 18:03:10.963871: Epoch time: 176.21 s
2024-04-12 18:03:11.448972: Yayy! New best R2: 0.7144
2024-04-12 18:03:14.704630: 
2024-04-12 18:03:14.705444: Epoch 40
2024-04-12 18:03:14.705925: Current learning rate: 0.00063
2024-04-12 18:06:12.049266: meanmse:       0.034837794
2024-04-12 18:06:12.050646: meanr2:        0.7207905838573923
2024-04-12 18:06:12.051259: train_loss 1.0804
2024-04-12 18:06:12.051820: val_loss 1.1711
2024-04-12 18:06:12.052368: Pseudo dice [0.5]
2024-04-12 18:06:12.052891: Epoch time: 177.35 s
2024-04-12 18:06:12.053386: Yayy! New best R2: 0.7208
2024-04-12 18:06:15.736055: 
2024-04-12 18:06:15.737594: Epoch 41
2024-04-12 18:06:15.738538: Current learning rate: 0.00062
2024-04-12 18:09:15.087757: meanmse:       0.030418457
2024-04-12 18:09:15.088949: meanr2:        0.7539525289457452
2024-04-12 18:09:15.089517: train_loss 0.9738
2024-04-12 18:09:15.089971: val_loss 1.021
2024-04-12 18:09:15.090439: Pseudo dice [0.5]
2024-04-12 18:09:15.090889: Epoch time: 179.36 s
2024-04-12 18:09:15.091429: Yayy! New best R2: 0.754
2024-04-12 18:09:18.010402: 
2024-04-12 18:09:18.011088: Epoch 42
2024-04-12 18:09:18.011543: Current learning rate: 0.00061
2024-04-12 18:12:14.485485: meanmse:       0.027798532
2024-04-12 18:12:14.488060: meanr2:        0.7780701428630906
2024-04-12 18:12:14.489256: train_loss 0.869
2024-04-12 18:12:14.490904: val_loss 0.9932
2024-04-12 18:12:14.492028: Pseudo dice [0.5]
2024-04-12 18:12:14.493122: Epoch time: 176.48 s
2024-04-12 18:12:14.493952: Yayy! New best R2: 0.7781
2024-04-12 18:12:17.748416: 
2024-04-12 18:12:17.749206: Epoch 43
2024-04-12 18:12:17.749768: Current learning rate: 0.0006
2024-04-12 18:15:16.338754: meanmse:       0.028245462
2024-04-12 18:15:16.341483: meanr2:        0.7731503702578381
2024-04-12 18:15:16.343673: train_loss 0.8081
2024-04-12 18:15:16.347615: val_loss 0.9748
2024-04-12 18:15:16.348385: Pseudo dice [0.5]
2024-04-12 18:15:16.349038: Epoch time: 178.6 s
2024-04-12 18:15:19.612581: 
2024-04-12 18:15:19.613456: Epoch 44
2024-04-12 18:15:19.614032: Current learning rate: 0.00059
2024-04-12 18:18:30.085453: meanmse:       0.028941734
2024-04-12 18:18:30.086672: meanr2:        0.7670274009019663
2024-04-12 18:18:30.087355: train_loss 0.7479
2024-04-12 18:18:30.087846: val_loss 0.8635
2024-04-12 18:18:30.088258: Pseudo dice [0.5]
2024-04-12 18:18:30.088685: Epoch time: 190.48 s
2024-04-12 18:18:32.667839: 
2024-04-12 18:18:32.668841: Epoch 45
2024-04-12 18:18:32.669499: Current learning rate: 0.00058
2024-04-12 18:21:43.988965: meanmse:       0.029291183
2024-04-12 18:21:43.990366: meanr2:        0.7628367832961206
2024-04-12 18:21:43.991136: train_loss 0.7033
2024-04-12 18:21:43.991678: val_loss 0.8342
2024-04-12 18:21:43.992197: Pseudo dice [0.5]
2024-04-12 18:21:43.992700: Epoch time: 191.33 s
2024-04-12 18:21:46.547539: 
2024-04-12 18:21:46.548298: Epoch 46
2024-04-12 18:21:46.548757: Current learning rate: 0.00057
2024-04-12 18:24:59.026152: meanmse:       0.02065398
2024-04-12 18:24:59.028002: meanr2:        0.8344222244277278
2024-04-12 18:24:59.028957: train_loss 0.6918
2024-04-12 18:24:59.029610: val_loss 0.7295
2024-04-12 18:24:59.030235: Pseudo dice [0.5]
2024-04-12 18:24:59.030801: Epoch time: 192.49 s
2024-04-12 18:24:59.031470: Yayy! New best R2: 0.8344
2024-04-12 18:25:02.254426: 
2024-04-12 18:25:02.255226: Epoch 47
2024-04-12 18:25:02.255719: Current learning rate: 0.00056
2024-04-12 18:28:12.926945: meanmse:       0.024799954
2024-04-12 18:28:12.928626: meanr2:        0.8014965450701858
2024-04-12 18:28:12.929941: train_loss 0.6257
2024-04-12 18:28:12.930753: val_loss 0.8267
2024-04-12 18:28:12.931454: Pseudo dice [0.5]
2024-04-12 18:28:12.932247: Epoch time: 190.68 s
2024-04-12 18:28:15.576598: 
2024-04-12 18:28:15.577427: Epoch 48
2024-04-12 18:28:15.578083: Current learning rate: 0.00056
2024-04-12 18:31:28.555226: meanmse:       0.02754156
2024-04-12 18:31:28.556408: meanr2:        0.7778170916001148
2024-04-12 18:31:28.556939: train_loss 0.594
2024-04-12 18:31:28.557358: val_loss 0.8371
2024-04-12 18:31:28.557771: Pseudo dice [0.5]
2024-04-12 18:31:28.558228: Epoch time: 192.99 s
2024-04-12 18:31:30.974180: 
2024-04-12 18:31:30.975501: Epoch 49
2024-04-12 18:31:30.976241: Current learning rate: 0.00055
2024-04-12 18:34:45.524906: meanmse:       0.026979314
2024-04-12 18:34:45.526013: meanr2:        0.7821191733790848
2024-04-12 18:34:45.526606: train_loss 0.5866
2024-04-12 18:34:45.527107: val_loss 0.7597
2024-04-12 18:34:45.527560: Pseudo dice [0.5]
2024-04-12 18:34:45.528001: Epoch time: 194.56 s
2024-04-12 18:34:48.889722: 
2024-04-12 18:34:48.891048: Epoch 50
2024-04-12 18:34:48.891992: Current learning rate: 0.00054
2024-04-12 18:38:04.031016: meanmse:       0.025833799
2024-04-12 18:38:04.032462: meanr2:        0.7931584853888787
2024-04-12 18:38:04.033163: train_loss 0.5735
2024-04-12 18:38:04.033895: val_loss 0.7849
2024-04-12 18:38:04.034673: Pseudo dice [0.5]
2024-04-12 18:38:04.035416: Epoch time: 195.15 s
2024-04-12 18:38:06.609157: 
2024-04-12 18:38:06.610183: Epoch 51
2024-04-12 18:38:06.610808: Current learning rate: 0.00053
2024-04-12 18:41:21.288630: meanmse:       0.029899351
2024-04-12 18:41:21.289764: meanr2:        0.7594645859889113
2024-04-12 18:41:21.290263: train_loss 0.5482
2024-04-12 18:41:21.290633: val_loss 0.7999
2024-04-12 18:41:21.290999: Pseudo dice [0.5]
2024-04-12 18:41:21.291369: Epoch time: 194.69 s
2024-04-12 18:41:23.728671: 
2024-04-12 18:41:23.729412: Epoch 52
2024-04-12 18:41:23.729954: Current learning rate: 0.00052
2024-04-12 18:44:36.140083: meanmse:       0.019830994
2024-04-12 18:44:36.141153: meanr2:        0.839744796216693
2024-04-12 18:44:36.141731: train_loss 0.5357
2024-04-12 18:44:36.142165: val_loss 0.6507
2024-04-12 18:44:36.142589: Pseudo dice [0.5]
2024-04-12 18:44:36.143024: Epoch time: 192.42 s
2024-04-12 18:44:36.143434: Yayy! New best R2: 0.8397
2024-04-12 18:44:39.900238: 
2024-04-12 18:44:39.901095: Epoch 53
2024-04-12 18:44:39.901687: Current learning rate: 0.00051
2024-04-12 18:47:56.088000: meanmse:       0.021558525
2024-04-12 18:47:56.119119: meanr2:        0.8249837367811511
2024-04-12 18:47:56.119910: train_loss 0.5399
2024-04-12 18:47:56.120520: val_loss 0.6927
2024-04-12 18:47:56.141994: Pseudo dice [0.5]
2024-04-12 18:47:56.142639: Epoch time: 196.23 s
2024-04-12 18:47:58.893312: 
2024-04-12 18:47:58.894197: Epoch 54
2024-04-12 18:47:58.894759: Current learning rate: 0.0005
2024-04-12 18:51:17.049286: meanmse:       0.02704799
2024-04-12 18:51:17.050440: meanr2:        0.7858850489864686
2024-04-12 18:51:17.051108: train_loss 0.5115
2024-04-12 18:51:17.051613: val_loss 0.7468
2024-04-12 18:51:17.052067: Pseudo dice [0.5]
2024-04-12 18:51:17.052585: Epoch time: 198.17 s
2024-04-12 18:51:19.836496: 
2024-04-12 18:51:19.837684: Epoch 55
2024-04-12 18:51:19.838359: Current learning rate: 0.00049
2024-04-12 18:54:32.824347: meanmse:       0.02717814
2024-04-12 18:54:32.825790: meanr2:        0.7801413481373413
2024-04-12 18:54:32.826376: train_loss 0.5187
2024-04-12 18:54:32.826770: val_loss 0.7145
2024-04-12 18:54:32.827162: Pseudo dice [0.5]
2024-04-12 18:54:32.827588: Epoch time: 193.0 s
2024-04-12 18:54:35.335280: 
2024-04-12 18:54:35.336134: Epoch 56
2024-04-12 18:54:35.336661: Current learning rate: 0.00048
2024-04-12 18:57:47.708701: meanmse:       0.020403745
2024-04-12 18:57:47.709975: meanr2:        0.8378604324545169
2024-04-12 18:57:47.710676: train_loss 0.481
2024-04-12 18:57:47.711179: val_loss 0.6217
2024-04-12 18:57:47.711610: Pseudo dice [0.5]
2024-04-12 18:57:47.712066: Epoch time: 192.38 s
2024-04-12 18:57:50.225442: 
2024-04-12 18:57:50.226394: Epoch 57
2024-04-12 18:57:50.227009: Current learning rate: 0.00047
2024-04-12 19:01:03.638113: meanmse:       0.025984848
2024-04-12 19:01:03.639118: meanr2:        0.7911102381416697
2024-04-12 19:01:03.639641: train_loss 0.4753
2024-04-12 19:01:03.640055: val_loss 0.732
2024-04-12 19:01:03.640445: Pseudo dice [0.5]
2024-04-12 19:01:03.640867: Epoch time: 193.45 s
2024-04-12 19:01:06.417531: 
2024-04-12 19:01:06.418349: Epoch 58
2024-04-12 19:01:06.418858: Current learning rate: 0.00046
2024-04-12 19:04:19.568131: meanmse:       0.027166395
2024-04-12 19:04:19.569133: meanr2:        0.7816126961153937
2024-04-12 19:04:19.569657: train_loss 0.455
2024-04-12 19:04:19.570115: val_loss 0.7357
2024-04-12 19:04:19.570502: Pseudo dice [0.5]
2024-04-12 19:04:19.570899: Epoch time: 193.19 s
2024-04-12 19:04:22.661447: 
2024-04-12 19:04:22.662258: Epoch 59
2024-04-12 19:04:22.662844: Current learning rate: 0.00045
2024-04-12 19:07:35.054600: meanmse:       0.021433583
2024-04-12 19:07:35.055815: meanr2:        0.8280530931868264
2024-04-12 19:07:35.056474: train_loss 0.4691
2024-04-12 19:07:35.056930: val_loss 0.6816
2024-04-12 19:07:35.057358: Pseudo dice [0.5]
2024-04-12 19:07:35.057799: Epoch time: 192.4 s
2024-04-12 19:07:37.968649: 
2024-04-12 19:07:37.969617: Epoch 60
2024-04-12 19:07:37.970290: Current learning rate: 0.00044
2024-04-12 19:10:52.265883: meanmse:       0.02733643
2024-04-12 19:10:52.273083: meanr2:        0.7815256549512758
2024-04-12 19:10:52.273761: train_loss 0.4574
2024-04-12 19:10:52.274253: val_loss 0.7887
2024-04-12 19:10:52.274733: Pseudo dice [0.5]
2024-04-12 19:10:52.275225: Epoch time: 194.31 s
2024-04-12 19:10:55.260602: 
2024-04-12 19:10:55.261431: Epoch 61
2024-04-12 19:10:55.261924: Current learning rate: 0.00043
2024-04-12 19:14:10.649775: meanmse:       0.022600831
2024-04-12 19:14:10.650840: meanr2:        0.8183759679057225
2024-04-12 19:14:10.651355: train_loss 0.4575
2024-04-12 19:14:10.651838: val_loss 0.6565
2024-04-12 19:14:10.652221: Pseudo dice [0.5]
2024-04-12 19:14:10.652678: Epoch time: 195.4 s
2024-04-12 19:14:14.073172: 
2024-04-12 19:14:14.074201: Epoch 62
2024-04-12 19:14:14.074857: Current learning rate: 0.00042
2024-04-12 19:17:31.173316: meanmse:       0.025743783
2024-04-12 19:17:31.174653: meanr2:        0.7947478537483375
2024-04-12 19:17:31.175352: train_loss 0.4354
2024-04-12 19:17:31.175837: val_loss 0.7261
2024-04-12 19:17:31.176364: Pseudo dice [0.5]
2024-04-12 19:17:31.176927: Epoch time: 197.11 s
2024-04-12 19:17:33.819476: 
2024-04-12 19:17:33.820203: Epoch 63
2024-04-12 19:17:33.820675: Current learning rate: 0.00041
2024-04-12 19:20:43.249889: meanmse:       0.021186717
2024-04-12 19:20:43.251018: meanr2:        0.8327985324724899
2024-04-12 19:20:43.251638: train_loss 0.4314
2024-04-12 19:20:43.253063: val_loss 0.6499
2024-04-12 19:20:43.253670: Pseudo dice [0.5]
2024-04-12 19:20:43.254272: Epoch time: 189.44 s
2024-04-12 19:20:46.084122: 
2024-04-12 19:20:46.085532: Epoch 64
2024-04-12 19:20:46.086412: Current learning rate: 0.0004
2024-04-12 19:24:01.031194: meanmse:       0.021580148
2024-04-12 19:24:01.032251: meanr2:        0.8256016293402847
2024-04-12 19:24:01.032879: train_loss 0.4353
2024-04-12 19:24:01.033380: val_loss 0.6691
2024-04-12 19:24:01.033794: Pseudo dice [0.5]
2024-04-12 19:24:01.034245: Epoch time: 194.96 s
2024-04-12 19:24:03.843626: 
2024-04-12 19:24:03.847661: Epoch 65
2024-04-12 19:24:03.849323: Current learning rate: 0.00039
2024-04-12 19:27:18.029817: meanmse:       0.025969362
2024-04-12 19:27:18.065233: meanr2:        0.7940855161647785
2024-04-12 19:27:18.066284: train_loss 0.4483
2024-04-12 19:27:18.066920: val_loss 0.6933
2024-04-12 19:27:18.067604: Pseudo dice [0.5]
2024-04-12 19:27:18.068166: Epoch time: 194.23 s
2024-04-12 19:27:20.914175: 
2024-04-12 19:27:20.914772: Epoch 66
2024-04-12 19:27:20.915222: Current learning rate: 0.00038
2024-04-12 19:30:33.239393: meanmse:       0.023020802
2024-04-12 19:30:33.240805: meanr2:        0.8184720320203195
2024-04-12 19:30:33.241595: train_loss 0.4309
2024-04-12 19:30:33.242092: val_loss 0.6884
2024-04-12 19:30:33.242844: Pseudo dice [0.5]
2024-04-12 19:30:33.243527: Epoch time: 192.33 s
2024-04-12 19:30:35.931574: 
2024-04-12 19:30:35.932454: Epoch 67
2024-04-12 19:30:35.932997: Current learning rate: 0.00037
2024-04-12 19:33:50.731256: meanmse:       0.019271733
2024-04-12 19:33:50.732405: meanr2:        0.8453845925032443
2024-04-12 19:33:50.733015: train_loss 0.413
2024-04-12 19:33:50.733554: val_loss 0.636
2024-04-12 19:33:50.733998: Pseudo dice [0.5]
2024-04-12 19:33:50.734470: Epoch time: 194.81 s
2024-04-12 19:33:50.734944: Yayy! New best R2: 0.8454
2024-04-12 19:33:54.504449: 
2024-04-12 19:33:54.505198: Epoch 68
2024-04-12 19:33:54.505789: Current learning rate: 0.00036
2024-04-12 19:37:04.282792: meanmse:       0.022028457
2024-04-12 19:37:04.284443: meanr2:        0.8202933419297384
2024-04-12 19:37:04.285266: train_loss 0.4288
2024-04-12 19:37:04.285910: val_loss 0.684
2024-04-12 19:37:04.286545: Pseudo dice [0.5]
2024-04-12 19:37:04.287227: Epoch time: 189.79 s
2024-04-12 19:37:06.861431: 
2024-04-12 19:37:06.862489: Epoch 69
2024-04-12 19:37:06.863149: Current learning rate: 0.00035
2024-04-12 19:40:17.134184: meanmse:       0.025108965
2024-04-12 19:40:17.136653: meanr2:        0.7958329469316002
2024-04-12 19:40:17.137367: train_loss 0.4281
2024-04-12 19:40:17.137805: val_loss 0.6991
2024-04-12 19:40:17.144334: Pseudo dice [0.5]
2024-04-12 19:40:17.144951: Epoch time: 190.28 s
2024-04-12 19:40:20.648369: 
2024-04-12 19:40:20.649958: Epoch 70
2024-04-12 19:40:20.650842: Current learning rate: 0.00034
2024-04-12 19:43:33.424256: meanmse:       0.024767227
2024-04-12 19:43:33.425454: meanr2:        0.800581022629277
2024-04-12 19:43:33.426075: train_loss 0.42
2024-04-12 19:43:33.426596: val_loss 0.7369
2024-04-12 19:43:33.427045: Pseudo dice [0.5]
2024-04-12 19:43:33.427484: Epoch time: 192.79 s
2024-04-12 19:43:36.123140: 
2024-04-12 19:43:36.124229: Epoch 71
2024-04-12 19:43:36.125726: Current learning rate: 0.00033
2024-04-12 19:46:50.541639: meanmse:       0.023478681
2024-04-12 19:46:50.543124: meanr2:        0.8104262313066806
2024-04-12 19:46:50.551324: train_loss 0.4026
2024-04-12 19:46:50.552698: val_loss 0.6794
2024-04-12 19:46:50.554094: Pseudo dice [0.5]
2024-04-12 19:46:50.554726: Epoch time: 194.46 s
2024-04-12 19:46:53.427919: 
2024-04-12 19:46:53.429368: Epoch 72
2024-04-12 19:46:53.429969: Current learning rate: 0.00032
2024-04-12 19:50:05.531790: meanmse:       0.025988625
2024-04-12 19:50:05.532985: meanr2:        0.7934895236743766
2024-04-12 19:50:05.534007: train_loss 0.424
2024-04-12 19:50:05.534478: val_loss 0.7008
2024-04-12 19:50:05.534897: Pseudo dice [0.5]
2024-04-12 19:50:05.535326: Epoch time: 192.11 s
2024-04-12 19:50:08.480625: 
2024-04-12 19:50:08.481271: Epoch 73
2024-04-12 19:50:08.481792: Current learning rate: 0.00031
2024-04-12 19:53:21.791104: meanmse:       0.022007024
2024-04-12 19:53:21.792048: meanr2:        0.8231615029810448
2024-04-12 19:53:21.794735: train_loss 0.4058
2024-04-12 19:53:21.795397: val_loss 0.6418
2024-04-12 19:53:21.796132: Pseudo dice [0.5]
2024-04-12 19:53:21.796861: Epoch time: 193.32 s
2024-04-12 19:53:25.065813: 
2024-04-12 19:53:25.067015: Epoch 74
2024-04-12 19:53:25.067657: Current learning rate: 0.0003
2024-04-12 19:56:38.823686: meanmse:       0.023203237
2024-04-12 19:56:38.824742: meanr2:        0.8152663316581854
2024-04-12 19:56:38.825630: train_loss 0.4025
2024-04-12 19:56:38.826115: val_loss 0.6544
2024-04-12 19:56:38.826506: Pseudo dice [0.5]
2024-04-12 19:56:38.826900: Epoch time: 193.77 s
2024-04-12 19:56:41.857539: 
2024-04-12 19:56:41.858378: Epoch 75
2024-04-12 19:56:41.858961: Current learning rate: 0.00029
2024-04-12 19:59:53.730385: meanmse:       0.026907563
2024-04-12 19:59:53.731627: meanr2:        0.7848201706297716
2024-04-12 19:59:53.732206: train_loss 0.3978
2024-04-12 19:59:53.732655: val_loss 0.6501
2024-04-12 19:59:53.733032: Pseudo dice [0.5]
2024-04-12 19:59:53.733477: Epoch time: 191.88 s
2024-04-12 19:59:56.442395: 
2024-04-12 19:59:56.443303: Epoch 76
2024-04-12 19:59:56.443933: Current learning rate: 0.00028
2024-04-12 20:03:11.226311: meanmse:       0.02167926
2024-04-12 20:03:11.227492: meanr2:        0.8231829770695761
2024-04-12 20:03:11.228163: train_loss 0.3857
2024-04-12 20:03:11.228696: val_loss 0.6587
2024-04-12 20:03:11.229184: Pseudo dice [0.5]
2024-04-12 20:03:11.229659: Epoch time: 194.79 s
2024-04-12 20:03:14.423753: 
2024-04-12 20:03:14.424680: Epoch 77
2024-04-12 20:03:14.425262: Current learning rate: 0.00027
2024-04-12 20:06:28.923384: meanmse:       0.021953896
2024-04-12 20:06:28.940089: meanr2:        0.8244808475786948
2024-04-12 20:06:28.940938: train_loss 0.395
2024-04-12 20:06:28.941442: val_loss 0.6422
2024-04-12 20:06:28.941885: Pseudo dice [0.5]
2024-04-12 20:06:28.942320: Epoch time: 194.52 s
2024-04-12 20:06:31.608039: 
2024-04-12 20:06:31.608762: Epoch 78
2024-04-12 20:06:31.609284: Current learning rate: 0.00026
2024-04-12 20:09:48.676737: meanmse:       0.022303848
2024-04-12 20:09:48.678165: meanr2:        0.8189914147596039
2024-04-12 20:09:48.678900: train_loss 0.3928
2024-04-12 20:09:48.679364: val_loss 0.6666
2024-04-12 20:09:48.679815: Pseudo dice [0.5]
2024-04-12 20:09:48.680457: Epoch time: 197.08 s
2024-04-12 20:09:51.693897: 
2024-04-12 20:09:51.694558: Epoch 79
2024-04-12 20:09:51.695065: Current learning rate: 0.00025
2024-04-12 20:13:07.948177: meanmse:       0.021427674
2024-04-12 20:13:07.949545: meanr2:        0.8301582394780399
2024-04-12 20:13:07.950453: train_loss 0.3687
2024-04-12 20:13:07.951167: val_loss 0.6302
2024-04-12 20:13:07.951988: Pseudo dice [0.5]
2024-04-12 20:13:07.952638: Epoch time: 196.26 s
2024-04-12 20:13:11.803486: 
2024-04-12 20:13:11.804353: Epoch 80
2024-04-12 20:13:11.804918: Current learning rate: 0.00023
2024-04-12 20:16:21.675456: meanmse:       0.018382525
2024-04-12 20:16:21.677049: meanr2:        0.852984606726702
2024-04-12 20:16:21.677842: train_loss 0.3756
2024-04-12 20:16:21.678430: val_loss 0.6311
2024-04-12 20:16:21.679111: Pseudo dice [0.5]
2024-04-12 20:16:21.680108: Epoch time: 189.88 s
2024-04-12 20:16:21.680720: Yayy! New best R2: 0.853
2024-04-12 20:16:25.301710: 
2024-04-12 20:16:25.302691: Epoch 81
2024-04-12 20:16:25.303308: Current learning rate: 0.00022
2024-04-12 20:19:41.449645: meanmse:       0.026176743
2024-04-12 20:19:41.450892: meanr2:        0.7913544448978057
2024-04-12 20:19:41.451477: train_loss 0.3634
2024-04-12 20:19:41.451919: val_loss 0.6651
2024-04-12 20:19:41.452357: Pseudo dice [0.5]
2024-04-12 20:19:41.452794: Epoch time: 196.26 s
2024-04-12 20:19:44.016752: 
2024-04-12 20:19:44.017689: Epoch 82
2024-04-12 20:19:44.018261: Current learning rate: 0.00021
2024-04-12 20:22:55.842261: meanmse:       0.02249948
2024-04-12 20:22:55.843511: meanr2:        0.8204888633734284
2024-04-12 20:22:55.844174: train_loss 0.3584
2024-04-12 20:22:55.844689: val_loss 0.6678
2024-04-12 20:22:55.845154: Pseudo dice [0.5]
2024-04-12 20:22:55.845626: Epoch time: 191.83 s
2024-04-12 20:22:58.673343: 
2024-04-12 20:22:58.674137: Epoch 83
2024-04-12 20:22:58.674670: Current learning rate: 0.0002
2024-04-12 20:26:07.538713: meanmse:       0.02785036
2024-04-12 20:26:07.540591: meanr2:        0.7787229031325684
2024-04-12 20:26:07.541308: train_loss 0.3558
2024-04-12 20:26:07.541803: val_loss 0.6488
2024-04-12 20:26:07.542358: Pseudo dice [0.5]
2024-04-12 20:26:07.542879: Epoch time: 188.87 s
2024-04-12 20:26:10.390412: 
2024-04-12 20:26:10.391294: Epoch 84
2024-04-12 20:26:10.391849: Current learning rate: 0.00019
2024-04-12 20:29:24.768068: meanmse:       0.030301701
2024-04-12 20:29:24.769305: meanr2:        0.7589381456285099
2024-04-12 20:29:24.770062: train_loss 0.3577
2024-04-12 20:29:24.770532: val_loss 0.7094
2024-04-12 20:29:24.771267: Pseudo dice [0.5]
2024-04-12 20:29:24.771778: Epoch time: 194.39 s
2024-04-12 20:29:27.598213: 
2024-04-12 20:29:27.598889: Epoch 85
2024-04-12 20:29:27.599334: Current learning rate: 0.00018
2024-04-12 20:32:43.270799: meanmse:       0.021082487
2024-04-12 20:32:43.272105: meanr2:        0.8295761464528422
2024-04-12 20:32:43.272830: train_loss 0.3541
2024-04-12 20:32:43.273330: val_loss 0.6028
2024-04-12 20:32:43.273822: Pseudo dice [0.5]
2024-04-12 20:32:43.274295: Epoch time: 195.68 s
2024-04-12 20:32:45.992916: 
2024-04-12 20:32:45.994039: Epoch 86
2024-04-12 20:32:45.994681: Current learning rate: 0.00017
2024-04-12 20:35:59.774298: meanmse:       0.025566868
2024-04-12 20:35:59.775717: meanr2:        0.7949259934000769
2024-04-12 20:35:59.776500: train_loss 0.3678
2024-04-12 20:35:59.777055: val_loss 0.6725
2024-04-12 20:35:59.777577: Pseudo dice [0.5]
2024-04-12 20:35:59.778095: Epoch time: 193.79 s
2024-04-12 20:36:02.272046: 
2024-04-12 20:36:02.273006: Epoch 87
2024-04-12 20:36:02.273679: Current learning rate: 0.00016
2024-04-12 20:39:14.353258: meanmse:       0.025305308
2024-04-12 20:39:14.354416: meanr2:        0.7927266775515761
2024-04-12 20:39:14.355036: train_loss 0.3573
2024-04-12 20:39:14.355543: val_loss 0.649
2024-04-12 20:39:14.356042: Pseudo dice [0.5]
2024-04-12 20:39:14.356526: Epoch time: 192.09 s
2024-04-12 20:39:16.913508: 
2024-04-12 20:39:16.914430: Epoch 88
2024-04-12 20:39:16.915028: Current learning rate: 0.00015
2024-04-12 20:42:31.359226: meanmse:       0.02363575
2024-04-12 20:42:31.360818: meanr2:        0.8108176527325314
2024-04-12 20:42:31.361789: train_loss 0.3512
2024-04-12 20:42:31.362425: val_loss 0.6249
2024-04-12 20:42:31.362971: Pseudo dice [0.5]
2024-04-12 20:42:31.363499: Epoch time: 194.45 s
2024-04-12 20:42:34.387418: 
2024-04-12 20:42:34.388293: Epoch 89
2024-04-12 20:42:34.388927: Current learning rate: 0.00014
2024-04-12 20:45:49.324248: meanmse:       0.02013008
2024-04-12 20:45:49.329395: meanr2:        0.8396483262929633
2024-04-12 20:45:49.330184: train_loss 0.3433
2024-04-12 20:45:49.330665: val_loss 0.6299
2024-04-12 20:45:49.331105: Pseudo dice [0.5]
2024-04-12 20:45:49.331599: Epoch time: 194.95 s
2024-04-12 20:45:52.247351: 
2024-04-12 20:45:52.248183: Epoch 90
2024-04-12 20:45:52.248807: Current learning rate: 0.00013
2024-04-12 20:49:05.869024: meanmse:       0.022515254
2024-04-12 20:49:05.870193: meanr2:        0.8202666574110307
2024-04-12 20:49:05.870837: train_loss 0.3233
2024-04-12 20:49:05.871324: val_loss 0.631
2024-04-12 20:49:05.871760: Pseudo dice [0.5]
2024-04-12 20:49:05.872229: Epoch time: 193.63 s
2024-04-12 20:49:09.151163: 
2024-04-12 20:49:09.152152: Epoch 91
2024-04-12 20:49:09.152861: Current learning rate: 0.00011
2024-04-12 20:52:21.825769: meanmse:       0.02262172
2024-04-12 20:52:21.827213: meanr2:        0.8166349238953109
2024-04-12 20:52:21.828398: train_loss 0.3379
2024-04-12 20:52:21.828983: val_loss 0.6142
2024-04-12 20:52:21.829511: Pseudo dice [0.5]
2024-04-12 20:52:21.830045: Epoch time: 192.68 s
2024-04-12 20:52:24.583588: 
2024-04-12 20:52:24.584593: Epoch 92
2024-04-12 20:52:24.585433: Current learning rate: 0.0001
2024-04-12 20:55:38.529957: meanmse:       0.028619563
2024-04-12 20:55:38.531674: meanr2:        0.7721870817433106
2024-04-12 20:55:38.532650: train_loss 0.3366
2024-04-12 20:55:38.533302: val_loss 0.7056
2024-04-12 20:55:38.533894: Pseudo dice [0.5]
2024-04-12 20:55:38.534594: Epoch time: 193.96 s
2024-04-12 20:55:41.022151: 
2024-04-12 20:55:41.022963: Epoch 93
2024-04-12 20:55:41.023507: Current learning rate: 9e-05
2024-04-12 20:58:57.564291: meanmse:       0.026620578
2024-04-12 20:58:57.565424: meanr2:        0.7857097171181084
2024-04-12 20:58:57.566078: train_loss 0.3329
2024-04-12 20:58:57.566509: val_loss 0.7047
2024-04-12 20:58:57.566974: Pseudo dice [0.5]
2024-04-12 20:58:57.567440: Epoch time: 196.56 s
2024-04-12 20:59:00.072507: 
2024-04-12 20:59:00.073345: Epoch 94
2024-04-12 20:59:00.073931: Current learning rate: 8e-05
2024-04-12 21:02:10.632267: meanmse:       0.021791046
2024-04-12 21:02:10.633566: meanr2:        0.8240181903760309
2024-04-12 21:02:10.634242: train_loss 0.3378
2024-04-12 21:02:10.635124: val_loss 0.6455
2024-04-12 21:02:10.635590: Pseudo dice [0.5]
2024-04-12 21:02:10.636047: Epoch time: 190.57 s
2024-04-12 21:02:13.404394: 
2024-04-12 21:02:13.405270: Epoch 95
2024-04-12 21:02:13.405965: Current learning rate: 7e-05
2024-04-12 21:05:27.532781: meanmse:       0.026212256
2024-04-12 21:05:27.534602: meanr2:        0.7884827571745231
2024-04-12 21:05:27.535326: train_loss 0.3457
2024-04-12 21:05:27.535804: val_loss 0.6877
2024-04-12 21:05:27.536251: Pseudo dice [0.5]
2024-04-12 21:05:27.536749: Epoch time: 194.14 s
2024-04-12 21:05:30.134169: 
2024-04-12 21:05:30.135142: Epoch 96
2024-04-12 21:05:30.135797: Current learning rate: 6e-05
2024-04-12 21:08:41.024199: meanmse:       0.020315476
2024-04-12 21:08:41.025263: meanr2:        0.8377157369123964
2024-04-12 21:08:41.025800: train_loss 0.3352
2024-04-12 21:08:41.026243: val_loss 0.6536
2024-04-12 21:08:41.026653: Pseudo dice [0.5]
2024-04-12 21:08:41.027099: Epoch time: 190.9 s
2024-04-12 21:08:44.224652: 
2024-04-12 21:08:44.225509: Epoch 97
2024-04-12 21:08:44.226080: Current learning rate: 4e-05
2024-04-12 21:12:00.341799: meanmse:       0.023094248
2024-04-12 21:12:00.343567: meanr2:        0.8139551856970695
2024-04-12 21:12:00.344426: train_loss 0.3454
2024-04-12 21:12:00.345017: val_loss 0.6498
2024-04-12 21:12:00.345601: Pseudo dice [0.5]
2024-04-12 21:12:00.346292: Epoch time: 196.13 s
2024-04-12 21:12:02.713314: 
2024-04-12 21:12:02.714153: Epoch 98
2024-04-12 21:12:02.714778: Current learning rate: 3e-05
2024-04-12 21:14:40.531811: meanmse:       0.02226863
2024-04-12 21:14:40.532966: meanr2:        0.821533763760364
2024-04-12 21:14:40.538319: train_loss 0.3783
2024-04-12 21:14:40.538902: val_loss 0.6956
2024-04-12 21:14:40.539386: Pseudo dice [0.5]
2024-04-12 21:14:40.539885: Epoch time: 157.83 s
2024-04-12 21:14:43.740858: 
2024-04-12 21:14:43.745336: Epoch 99
2024-04-12 21:14:43.756740: Current learning rate: 2e-05
2024-04-12 21:16:53.789628: meanmse:       0.027516602
2024-04-12 21:16:53.828420: meanr2:        0.7770919776544788
2024-04-12 21:16:53.829359: train_loss 0.4141
2024-04-12 21:16:53.829909: val_loss 0.6832
2024-04-12 21:16:53.830453: Pseudo dice [0.5]
2024-04-12 21:16:53.831127: Epoch time: 130.1 s
2024-04-12 21:16:56.890152: Training done.
2024-04-12 21:16:56.921243: predicting 20190411_162615_159
Traceback (most recent call last):
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 274, in <module>
    run_training_entry()
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 268, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 171, in run_training
    mp.spawn(run_ddp,
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 134, in run_ddp
    nnunet_trainer.perform_actual_validation(npz)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1385, in perform_actual_validation
    data = torch.from_numpy(data)
TypeError: expected np.ndarray (got str)

