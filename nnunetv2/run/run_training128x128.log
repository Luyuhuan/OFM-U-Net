nohup: ignoring input
using port 38161
[W socket.cpp:601] [c10d] The client socket has failed to connect to [localhost]:38161 (errno: 101 - Network is unreachable).
I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 0 oversample 0.0
worker 0 batch_size 5

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (mamba_layers): ModuleList(
      (0): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
      (1): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (2-3): 2 x MambaLayer(
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=128, out_features=512, bias=False)
          (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
          (act): SiLU()
          (x_proj): Linear(in_features=256, out_features=40, bias=False)
          (dt_proj): Linear(in_features=8, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=128, bias=False)
        )
      )
      (4): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (5): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (mamba_layers): ModuleList(
        (0): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
        (1): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (2-3): 2 x MambaLayer(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
        )
        (4): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (5): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-3): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=128, out_features=32, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=32, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [48, 128, 128], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7958984971046448, 0.7958984971046448], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset701_AbdomenCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.7958984971046448, 0.7958984971046448], 'original_median_shape_after_transp': [97, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 97.29716491699219, 'median': 118.0, 'min': -1024.0, 'percentile_00_5': -958.0, 'percentile_99_5': 270.0, 'std': 137.8484649658203}}} 

2024-03-31 10:52:40.257148: unpacking dataset...
2024-03-31 10:52:40.257517: unpacking done...
2024-03-31 10:52:40.259384: do_dummy_2d_data_aug: False
2024-03-31 10:52:40.273933: Unable to plot network architecture:
2024-03-31 10:52:40.274335: No module named 'hiddenlayer'
2024-03-31 10:52:40.284378: 
2024-03-31 10:52:40.284854: Epoch 0
2024-03-31 10:52:40.285369: Current learning rate: 0.0001
I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 1 oversample 0.6600000000000001
worker 1 batch_size 5

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (mamba_layers): ModuleList(
      (0): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
      (1): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (2-3): 2 x MambaLayer(
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=128, out_features=512, bias=False)
          (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
          (act): SiLU()
          (x_proj): Linear(in_features=256, out_features=40, bias=False)
          (dt_proj): Linear(in_features=8, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=128, bias=False)
        )
      )
      (4): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (5): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (mamba_layers): ModuleList(
        (0): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
        (1): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (2-3): 2 x MambaLayer(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
        )
        (4): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (5): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-3): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=128, out_features=32, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=32, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)
do_dummy_2d_data_aug: False

Epoch 0
Current learning rate: 0.0001
using pin_memory on device 1
using pin_memory on device 0
using pin_memory on device 1
meanmse:       0.20473197
meanr2:        -0.6762436340725179
train_loss 1.0737
val_loss 0.834
Pseudo dice [0.5]
Epoch time: 137.8 s
self._now_r2:  -0.6762436340725179    max(self._all_r2):   -0.6762436340725179
Yayy! New best R2: -0.6762

Epoch 1
Current learning rate: 0.0001
meanmse:       0.15202843
meanr2:        -0.20437726340293738
train_loss 0.9659
val_loss 0.783
Pseudo dice [0.5]
Epoch time: 47.74 s
self._now_r2:  -0.20437726340293738    max(self._all_r2):   -0.20437726340293738
Yayy! New best R2: -0.2044

Epoch 2
Current learning rate: 0.0001
meanmse:       0.14377601
meanr2:        -0.15672805011734306
train_loss 0.8048
val_loss 0.7339
Pseudo dice [0.5]
Epoch time: 75.5 s
self._now_r2:  -0.15672805011734306    max(self._all_r2):   -0.15672805011734306
Yayy! New best R2: -0.1567

Epoch 3
Current learning rate: 0.0001
meanmse:       0.14621623
meanr2:        -0.18305976988672135
train_loss 0.8094
val_loss 0.7025
Pseudo dice [0.5]
Epoch time: 66.92 s

Epoch 4
Current learning rate: 0.0001
meanmse:       0.15525618
meanr2:        -0.2489975118418439
train_loss 0.7704
val_loss 0.6787
Pseudo dice [0.5]
Epoch time: 70.77 s

Epoch 5
Current learning rate: 0.0001
meanmse:       0.14581999
meanr2:        -0.15915159742084548
train_loss 0.7494
val_loss 0.6624
Pseudo dice [0.5]
Epoch time: 69.84 s

Epoch 6
Current learning rate: 9e-05
meanmse:       0.13873626
meanr2:        -0.11097202104613846
train_loss 0.7403
val_loss 0.6468
Pseudo dice [0.5]
Epoch time: 68.72 s
self._now_r2:  -0.11097202104613846    max(self._all_r2):   -0.11097202104613846
Yayy! New best R2: -0.111

Epoch 7
Current learning rate: 9e-05
meanmse:       0.13709626
meanr2:        -0.10764963723097273
train_loss 0.6835
val_loss 0.6343
Pseudo dice [0.5]
Epoch time: 66.05 s
self._now_r2:  -0.10764963723097273    max(self._all_r2):   -0.10764963723097273
Yayy! New best R2: -0.1076

Epoch 8
Current learning rate: 9e-05
meanmse:       0.14005814
meanr2:        -0.13235604730668538
train_loss 0.8565
val_loss 0.6323
Pseudo dice [0.5]
Epoch time: 66.26 s

Epoch 9
Current learning rate: 9e-05
meanmse:       0.13814509
meanr2:        -0.1139108546287057
train_loss 0.6656
val_loss 0.6228
Pseudo dice [0.5]
Epoch time: 68.02 s

Epoch 10
Current learning rate: 9e-05
meanmse:       0.1409374
meanr2:        -0.1124864411867806
train_loss 0.8109
val_loss 0.6219
Pseudo dice [0.5]
Epoch time: 62.03 s

Epoch 11
Current learning rate: 9e-05
meanmse:       0.13894087
meanr2:        -0.11471804483520118
train_loss 0.6976
val_loss 0.6257
Pseudo dice [0.5]
Epoch time: 65.97 s

Epoch 12
Current learning rate: 9e-05
meanmse:       0.13747524
meanr2:        -0.09323263300772447
train_loss 0.6206
val_loss 0.6234
Pseudo dice [0.5]
Epoch time: 62.53 s
self._now_r2:  -0.09323263300772447    max(self._all_r2):   -0.09323263300772447
Yayy! New best R2: -0.0932

Epoch 13
Current learning rate: 9e-05
meanmse:       0.13721922
meanr2:        -0.109201339610126
train_loss 0.653
val_loss 0.6158
Pseudo dice [0.5]
Epoch time: 63.58 s

Epoch 14
Current learning rate: 9e-05
meanmse:       0.14105032
meanr2:        -0.12809744016167815
train_loss 0.7274
val_loss 0.6173
Pseudo dice [0.5]
Epoch time: 63.29 s

Epoch 15
Current learning rate: 9e-05
meanmse:       0.13958538
meanr2:        -0.1271364751399218
train_loss 0.7291
val_loss 0.6176
Pseudo dice [0.5]
Epoch time: 61.4 s

Epoch 16
Current learning rate: 9e-05
meanmse:       0.13624924
meanr2:        -0.09390808075142794
train_loss 0.6188
val_loss 0.6154
Pseudo dice [0.5]
Epoch time: 61.09 s

Epoch 17
Current learning rate: 8e-05
meanmse:       0.13667491
meanr2:        -0.08998058812019642
train_loss 0.7253
val_loss 0.618
Pseudo dice [0.5]
Epoch time: 58.1 s
self._now_r2:  -0.08998058812019642    max(self._all_r2):   -0.08998058812019642
Yayy! New best R2: -0.09

Epoch 18
Current learning rate: 8e-05
meanmse:       0.1379986
meanr2:        -0.10355448199313161
train_loss 0.6165
val_loss 0.6178
Pseudo dice [0.5]
Epoch time: 63.72 s

Epoch 19
Current learning rate: 8e-05
meanmse:       0.13795906
meanr2:        -0.10213941219308983
train_loss 0.6173
val_loss 0.6172
Pseudo dice [0.5]
Epoch time: 63.99 s

Epoch 20
Current learning rate: 8e-05
meanmse:       0.13556819
meanr2:        -0.08188283301181018
train_loss 0.6939
val_loss 0.615
Pseudo dice [0.5]
Epoch time: 60.49 s
self._now_r2:  -0.08188283301181018    max(self._all_r2):   -0.08188283301181018
Yayy! New best R2: -0.0819

Epoch 21
Current learning rate: 8e-05
meanmse:       0.1379041
meanr2:        -0.10861306509153258
train_loss 0.7282
val_loss 0.6105
Pseudo dice [0.5]
Epoch time: 64.9 s

Epoch 22
Current learning rate: 8e-05
meanmse:       0.14093505
meanr2:        -0.12759331697891974
train_loss 0.6872
val_loss 0.6164
Pseudo dice [0.5]
Epoch time: 61.74 s

Epoch 23
Current learning rate: 8e-05
meanmse:       0.13680203
meanr2:        -0.10949598194744775
train_loss 0.7229
val_loss 0.6102
Pseudo dice [0.5]
Epoch time: 61.29 s

Epoch 24
Current learning rate: 8e-05
meanmse:       0.13797405
meanr2:        -0.09763415732516137
train_loss 0.6494
val_loss 0.6169
Pseudo dice [0.5]
Epoch time: 64.82 s

Epoch 25
Current learning rate: 8e-05
meanmse:       0.13833652
meanr2:        -0.11060409268369292
train_loss 0.6568
val_loss 0.6181
Pseudo dice [0.5]
Epoch time: 58.65 s

Epoch 26
Current learning rate: 8e-05
meanmse:       0.13744701
meanr2:        -0.10286937685816394
train_loss 0.7673
val_loss 0.611
Pseudo dice [0.5]
Epoch time: 64.73 s

Epoch 27
Current learning rate: 8e-05
meanmse:       0.13564862
meanr2:        -0.09146311328280841
train_loss 0.7285
val_loss 0.611
Pseudo dice [0.5]
Epoch time: 61.97 s

Epoch 28
Current learning rate: 7e-05
meanmse:       0.13761112
meanr2:        -0.10456715474544438
train_loss 0.6843
val_loss 0.6131
Pseudo dice [0.5]
Epoch time: 63.75 s

Epoch 29
Current learning rate: 7e-05
meanmse:       0.13862984
meanr2:        -0.10116048468841894
train_loss 0.6521
val_loss 0.6138
Pseudo dice [0.5]
Epoch time: 59.15 s

Epoch 30
Current learning rate: 7e-05
meanmse:       0.13571079
meanr2:        -0.0698701515429277
train_loss 0.6826
val_loss 0.6144
Pseudo dice [0.5]
Epoch time: 61.57 s
self._now_r2:  -0.0698701515429277    max(self._all_r2):   -0.0698701515429277
Yayy! New best R2: -0.0699

Epoch 31
Current learning rate: 7e-05
meanmse:       0.13622114
meanr2:        -0.0699362900442854
train_loss 0.7985
val_loss 0.6156
Pseudo dice [0.5]
Epoch time: 60.43 s

Epoch 32
Current learning rate: 7e-05
meanmse:       0.13645285
meanr2:        -0.077163515424901
train_loss 0.7213
val_loss 0.61
Pseudo dice [0.5]
Epoch time: 62.53 s

Epoch 33
Current learning rate: 7e-05
meanmse:       0.13702457
meanr2:        -0.094815759894063
train_loss 0.7151
val_loss 0.611
Pseudo dice [0.5]
Epoch time: 62.67 s

Epoch 34
Current learning rate: 7e-05
meanmse:       0.13673276
meanr2:        -0.10413198523585228
train_loss 0.6385
val_loss 0.5937
Pseudo dice [0.5]
Epoch time: 62.65 s

Epoch 35
Current learning rate: 7e-05
meanmse:       0.13325062
meanr2:        -0.06140953877424374
train_loss 0.7577
val_loss 0.5704
Pseudo dice [0.5]
Epoch time: 58.66 s
self._now_r2:  -0.06140953877424374    max(self._all_r2):   -0.06140953877424374
Yayy! New best R2: -0.0614

Epoch 36
Current learning rate: 7e-05
meanmse:       0.12892108
meanr2:        -0.03265125053701586
train_loss 0.5821
val_loss 0.5413
Pseudo dice [0.5]
Epoch time: 63.32 s
self._now_r2:  -0.03265125053701586    max(self._all_r2):   -0.03265125053701586
Yayy! New best R2: -0.0327

Epoch 37
Current learning rate: 7e-05
meanmse:       0.13118884
meanr2:        -0.054630838700529157
train_loss 0.5472
val_loss 0.5506
Pseudo dice [0.5]
Epoch time: 60.7 s

Epoch 38
Current learning rate: 7e-05
meanmse:       0.1278086
meanr2:        -0.019711120952897447
train_loss 0.661
val_loss 0.5228
Pseudo dice [0.5]
Epoch time: 63.17 s
self._now_r2:  -0.019711120952897447    max(self._all_r2):   -0.019711120952897447
Yayy! New best R2: -0.0197

Epoch 39
Current learning rate: 6e-05
meanmse:       0.12426911
meanr2:        0.002082755495498819
train_loss 0.6514
val_loss 0.5187
Pseudo dice [0.5]
Epoch time: 64.21 s
self._now_r2:  0.002082755495498819    max(self._all_r2):   0.002082755495498819
Yayy! New best R2: 0.0021

Epoch 40
Current learning rate: 6e-05
meanmse:       0.12611833
meanr2:        -0.012516333184259869
train_loss 0.6074
val_loss 0.5147
Pseudo dice [0.5]
Epoch time: 63.43 s

Epoch 41
Current learning rate: 6e-05
meanmse:       0.12810244
meanr2:        -0.0221869430602682
train_loss 0.5156
val_loss 0.5184
Pseudo dice [0.5]
Epoch time: 64.87 s

Epoch 42
Current learning rate: 6e-05
meanmse:       0.12720996
meanr2:        -0.004794262925369479
train_loss 0.577
val_loss 0.5152
Pseudo dice [0.5]
Epoch time: 64.79 s

Epoch 43
Current learning rate: 6e-05
meanmse:       0.12627144
meanr2:        -0.007749626817935155
train_loss 0.61
val_loss 0.5135
Pseudo dice [0.5]
Epoch time: 65.9 s

Epoch 44
Current learning rate: 6e-05
meanmse:       0.12428714
meanr2:        -0.0026520073084031915
train_loss 0.5426
val_loss 0.5115
Pseudo dice [0.5]
Epoch time: 58.9 s

Epoch 45
Current learning rate: 6e-05
meanmse:       0.12352785
meanr2:        -0.005310652070507664
train_loss 0.6353
val_loss 0.5093
Pseudo dice [0.5]
Epoch time: 61.91 s

Epoch 46
Current learning rate: 6e-05
meanmse:       0.12811995
meanr2:        -0.02032616794684862
train_loss 0.5712
val_loss 0.5132
Pseudo dice [0.5]
Epoch time: 64.4 s

Epoch 47
Current learning rate: 6e-05
meanmse:       0.12476872
meanr2:        0.002256938043132465
train_loss 0.5115
val_loss 0.5105
Pseudo dice [0.5]
Epoch time: 58.33 s
self._now_r2:  0.002256938043132465    max(self._all_r2):   0.002256938043132465
Yayy! New best R2: 0.0023

Epoch 48
Current learning rate: 6e-05
meanmse:       0.12423865
meanr2:        0.006891336957858029
train_loss 0.5407
val_loss 0.5077
Pseudo dice [0.5]
Epoch time: 61.27 s
self._now_r2:  0.006891336957858029    max(self._all_r2):   0.006891336957858029
Yayy! New best R2: 0.0069

Epoch 49
Current learning rate: 5e-05
meanmse:       0.12699418
meanr2:        -0.013167223796698928
train_loss 0.5735
val_loss 0.5119
Pseudo dice [0.5]
Epoch time: 61.82 s

Epoch 50
Current learning rate: 5e-05
meanmse:       0.12336736
meanr2:        0.003982276890491378
train_loss 0.5391
val_loss 0.5103
Pseudo dice [0.5]
Epoch time: 55.69 s

Epoch 51
Current learning rate: 5e-05
meanmse:       0.12570898
meanr2:        -0.0034950161802782664
train_loss 0.6082
val_loss 0.5096
Pseudo dice [0.5]
Epoch time: 63.9 s

Epoch 52
Current learning rate: 5e-05
meanmse:       0.12401393
meanr2:        -0.0015996871392543897
train_loss 0.5403
val_loss 0.507
Pseudo dice [0.5]
Epoch time: 60.11 s

Epoch 53
Current learning rate: 5e-05
meanmse:       0.12530544
meanr2:        -0.0044197974923263494
train_loss 0.5748
val_loss 0.5139
Pseudo dice [0.5]
Epoch time: 61.68 s

Epoch 54
Current learning rate: 5e-05
meanmse:       0.12654662
meanr2:        -0.013140195385087285
train_loss 0.5115
val_loss 0.5113
Pseudo dice [0.5]
Epoch time: 60.27 s

Epoch 55
Current learning rate: 5e-05
meanmse:       0.12460009
meanr2:        0.0033673193940819937
train_loss 0.6302
val_loss 0.5119
Pseudo dice [0.5]
Epoch time: 56.35 s

Epoch 56
Current learning rate: 5e-05
meanmse:       0.12661757
meanr2:        -0.008232995855040472
train_loss 0.5734
val_loss 0.5161
Pseudo dice [0.5]
Epoch time: 58.51 s

Epoch 57
Current learning rate: 5e-05
meanmse:       0.12465925
meanr2:        0.0004694159231625441
train_loss 0.6349
val_loss 0.5102
Pseudo dice [0.5]
Epoch time: 59.35 s

Epoch 58
Current learning rate: 5e-05
meanmse:       0.12459736
meanr2:        -0.0035172616717676786
train_loss 0.5445
val_loss 0.5078
Pseudo dice [0.5]
Epoch time: 56.92 s

Epoch 59
Current learning rate: 4e-05
meanmse:       0.12608321
meanr2:        -0.007903106831110963
train_loss 0.6062
val_loss 0.516
Pseudo dice [0.5]
Epoch time: 57.98 s

Epoch 60
Current learning rate: 4e-05
meanmse:       0.122146964
meanr2:        -0.0016568084506291486
train_loss 0.5089
val_loss 0.5061
Pseudo dice [0.5]
Epoch time: 56.21 s

Epoch 61
Current learning rate: 4e-05
meanmse:       0.124307156
meanr2:        -0.005075283486485116
train_loss 0.5681
val_loss 0.5101
Pseudo dice [0.5]
Epoch time: 58.93 s

Epoch 62
Current learning rate: 4e-05
meanmse:       0.12531407
meanr2:        -0.005222931084622351
train_loss 0.5714
val_loss 0.5118
Pseudo dice [0.5]
Epoch time: 57.26 s

Epoch 63
Current learning rate: 4e-05
meanmse:       0.12523378
meanr2:        -0.011314529414378764
train_loss 0.6042
val_loss 0.5082
Pseudo dice [0.5]
Epoch time: 53.81 s

Epoch 64
Current learning rate: 4e-05
meanmse:       0.1255328
meanr2:        0.0010605846264862952
train_loss 0.6116
val_loss 0.5113
Pseudo dice [0.5]
Epoch time: 58.23 s

Epoch 65
Current learning rate: 4e-05
meanmse:       0.12284514
meanr2:        -0.0006858896748986135
train_loss 0.6051
val_loss 0.5084
Pseudo dice [0.5]
Epoch time: 55.6 s

Epoch 66
Current learning rate: 4e-05
meanmse:       0.12505834
meanr2:        -0.004223635788078705
train_loss 0.5099
val_loss 0.5146
Pseudo dice [0.5]
Epoch time: 57.99 s

Epoch 67
Current learning rate: 4e-05
meanmse:       0.12384529
meanr2:        -0.0014054730717674897
train_loss 0.5704
val_loss 0.5107
Pseudo dice [0.5]
Epoch time: 52.47 s

Epoch 68
Current learning rate: 4e-05
meanmse:       0.13013346
meanr2:        -0.02771023248179103
train_loss 0.5095
val_loss 0.5191
Pseudo dice [0.5]
Epoch time: 56.12 s

Epoch 69
Current learning rate: 3e-05
meanmse:       0.12578408
meanr2:        -0.0029429908167231244
train_loss 0.5367
val_loss 0.5117
Pseudo dice [0.5]
Epoch time: 59.37 s

Epoch 70
Current learning rate: 3e-05
meanmse:       0.12168336
meanr2:        0.005709428657742908
train_loss 0.6065
val_loss 0.5097
Pseudo dice [0.5]
Epoch time: 55.55 s

Epoch 71
Current learning rate: 3e-05
meanmse:       0.12516294
meanr2:        0.0012068538769075049
train_loss 0.6952
val_loss 0.5117
Pseudo dice [0.5]
Epoch time: 55.89 s

Epoch 72
Current learning rate: 3e-05
meanmse:       0.12616932
meanr2:        0.0004019902366849558
train_loss 0.5672
val_loss 0.5134
Pseudo dice [0.5]
Epoch time: 59.81 s

Epoch 73
Current learning rate: 3e-05
meanmse:       0.12505585
meanr2:        -0.004514154268923333
train_loss 0.6341
val_loss 0.5119
Pseudo dice [0.5]
Epoch time: 53.41 s

Epoch 74
Current learning rate: 3e-05
meanmse:       0.12579177
meanr2:        -0.0031347984181056368
train_loss 0.5436
val_loss 0.5112
Pseudo dice [0.5]
Epoch time: 57.32 s

Epoch 75
Current learning rate: 3e-05
meanmse:       0.12684359
meanr2:        -0.014911409524648237
train_loss 0.5411
val_loss 0.5108
Pseudo dice [0.5]
Epoch time: 55.59 s

Epoch 76
Current learning rate: 3e-05
meanmse:       0.12686357
meanr2:        -0.013443956961420657
train_loss 0.5397
val_loss 0.5161
Pseudo dice [0.5]
Epoch time: 56.2 s

Epoch 77
Current learning rate: 3e-05
meanmse:       0.12507805
meanr2:        -0.0050719765640275805
train_loss 0.5729
val_loss 0.5124
Pseudo dice [0.5]
Epoch time: 57.42 s

Epoch 78
Current learning rate: 3e-05
meanmse:       0.124452725
meanr2:        -0.0005307915647345797
train_loss 0.5741
val_loss 0.5088
Pseudo dice [0.5]
Epoch time: 54.18 s

Epoch 79
Current learning rate: 2e-05
meanmse:       0.12529385
meanr2:        -0.010147841157991302
train_loss 0.5414
val_loss 0.5101
Pseudo dice [0.5]
Epoch time: 55.61 s

Epoch 80
Current learning rate: 2e-05
meanmse:       0.12280142
meanr2:        0.006448112139531929
train_loss 0.5372
val_loss 0.5057
Pseudo dice [0.5]
Epoch time: 59.45 s

Epoch 81
Current learning rate: 2e-05
meanmse:       0.12644434
meanr2:        -0.0011665062086483448
train_loss 0.634
val_loss 0.515
Pseudo dice [0.5]
Epoch time: 57.08 s

Epoch 82
Current learning rate: 2e-05
meanmse:       0.12473292
meanr2:        -0.0003839846617977501
train_loss 0.5762
val_loss 0.5105
Pseudo dice [0.5]
Epoch time: 59.39 s

Epoch 83
Current learning rate: 2e-05
meanmse:       0.12834938
meanr2:        -0.02325786713113271
train_loss 0.6315
val_loss 0.5125
Pseudo dice [0.5]
Epoch time: 54.66 s

Epoch 84
Current learning rate: 2e-05
meanmse:       0.12618403
meanr2:        -0.008509505315548553
train_loss 0.6268
val_loss 0.5151
Pseudo dice [0.5]
Epoch time: 55.81 s

Epoch 85
Current learning rate: 2e-05
meanmse:       0.12684925
meanr2:        -0.012145535937156468
train_loss 0.5366
val_loss 0.5148
Pseudo dice [0.5]
Epoch time: 56.64 s

Epoch 86
Current learning rate: 2e-05
meanmse:       0.12322671
meanr2:        0.001708330518831606
train_loss 0.5665
val_loss 0.5092
Pseudo dice [0.5]
Epoch time: 57.18 s

Epoch 87
Current learning rate: 2e-05
meanmse:       0.12385705
meanr2:        -0.0025097080092311153
train_loss 0.5429
val_loss 0.5075
Pseudo dice [0.5]
Epoch time: 55.29 s

Epoch 88
Current learning rate: 1e-05
meanmse:       0.12560207
meanr2:        -0.008859582272755307
train_loss 0.6325
val_loss 0.5106
Pseudo dice [0.5]
Epoch time: 59.19 s

Epoch 89
Current learning rate: 1e-05
meanmse:       0.12515156
meanr2:        -9.900608866026456e-05
train_loss 0.5702
val_loss 0.5096
Pseudo dice [0.5]
Epoch time: 54.82 s

Epoch 90
Current learning rate: 1e-05
meanmse:       0.12731017
meanr2:        -0.0054878419435675264
train_loss 0.5691
val_loss 0.5111
Pseudo dice [0.5]
Epoch time: 56.99 s

Epoch 91
Current learning rate: 1e-05
meanmse:       0.12858649
meanr2:        -0.011854781096277923
train_loss 0.5404
val_loss 0.5141
Pseudo dice [0.5]
Epoch time: 58.58 s

Epoch 92
Current learning rate: 1e-05
meanmse:       0.12616883
meanr2:        0.0027626367215475905
train_loss 0.6321
val_loss 0.5101
Pseudo dice [0.5]
Epoch time: 53.27 s

Epoch 93
Current learning rate: 1e-05
meanmse:       0.124735266
meanr2:        -0.005786411330675268
train_loss 0.5705
val_loss 0.5103
Pseudo dice [0.5]
Epoch time: 60.93 s

Epoch 94
Current learning rate: 1e-05
meanmse:       0.12750824
meanr2:        -0.008170216754148652
train_loss 0.5106
val_loss 0.5125
Pseudo dice [0.5]
Epoch time: 53.32 s

Epoch 95
Current learning rate: 1e-05
meanmse:       0.12645382
meanr2:        -0.012122878284784878
train_loss 0.512
val_loss 0.5122
Pseudo dice [0.5]
Epoch time: 54.68 s

Epoch 96
Current learning rate: 1e-05
meanmse:       0.12476333
meanr2:        -0.0048281675696937925
train_loss 0.5399
val_loss 0.5117
Pseudo dice [0.5]
Epoch time: 58.1 s

Epoch 97
Current learning rate: 0.0
meanmse:       0.1253122
meanr2:        -0.0015560382287465899
train_loss 0.572
val_loss 0.5103
Pseudo dice [0.5]
Epoch time: 53.53 s

Epoch 98
Current learning rate: 0.0
meanmse:       0.12834364
meanr2:        -0.02722284178270788
train_loss 0.5702
val_loss 0.5145
Pseudo dice [0.5]
Epoch time: 56.19 s

Epoch 99
Current learning rate: 0.0
meanmse:       0.12362916
meanr2:        0.005024832640614905
train_loss 0.5116
val_loss 0.5079
Pseudo dice [0.5]
Epoch time: 55.72 s
Training done.
predicting 20190412_103119_129
using pin_memory on device 0
2024-03-31 10:54:58.086542: meanmse:       0.2021705
2024-03-31 10:54:58.087723: meanr2:        -0.6093961439424397
2024-03-31 10:54:58.088246: train_loss 1.0737
2024-03-31 10:54:58.088755: val_loss 0.834
2024-03-31 10:54:58.089139: Pseudo dice [0.5]
2024-03-31 10:54:58.089545: Epoch time: 137.81 s
self._now_r2:  -0.6093961439424397    max(self._all_r2):   -0.6093961439424397
2024-03-31 10:54:58.089926: Yayy! New best R2: -0.6094
2024-03-31 10:55:00.627241: 
2024-03-31 10:55:00.628735: Epoch 1
2024-03-31 10:55:00.629376: Current learning rate: 0.0001
2024-03-31 10:55:45.824812: meanmse:       0.15434659
2024-03-31 10:55:45.828051: meanr2:        -0.21505970847720823
2024-03-31 10:55:45.828865: train_loss 0.9659
2024-03-31 10:55:45.829357: val_loss 0.783
2024-03-31 10:55:45.829882: Pseudo dice [0.5]
2024-03-31 10:55:45.830635: Epoch time: 45.21 s
self._now_r2:  -0.21505970847720823    max(self._all_r2):   -0.21505970847720823
2024-03-31 10:55:45.832383: Yayy! New best R2: -0.2151
2024-03-31 10:55:53.938821: 
2024-03-31 10:55:53.940244: Epoch 2
2024-03-31 10:55:53.940875: Current learning rate: 0.0001
2024-03-31 10:57:01.332458: meanmse:       0.14380285
2024-03-31 10:57:01.334401: meanr2:        -0.13892379992335346
2024-03-31 10:57:01.335319: train_loss 0.8048
2024-03-31 10:57:01.336082: val_loss 0.7339
2024-03-31 10:57:01.336594: Pseudo dice [0.5]
2024-03-31 10:57:01.337178: Epoch time: 67.42 s
self._now_r2:  -0.13892379992335346    max(self._all_r2):   -0.13892379992335346
2024-03-31 10:57:01.337662: Yayy! New best R2: -0.1389
2024-03-31 10:57:10.871286: 
2024-03-31 10:57:10.884690: Epoch 3
2024-03-31 10:57:10.918308: Current learning rate: 0.0001
2024-03-31 10:58:08.251109: meanmse:       0.14230664
2024-03-31 10:58:08.258970: meanr2:        -0.14503745969526013
2024-03-31 10:58:08.259911: train_loss 0.8094
2024-03-31 10:58:08.260336: val_loss 0.7025
2024-03-31 10:58:08.282992: Pseudo dice [0.5]
2024-03-31 10:58:08.283717: Epoch time: 57.4 s
2024-03-31 10:58:12.862269: 
2024-03-31 10:58:12.863277: Epoch 4
2024-03-31 10:58:12.863811: Current learning rate: 0.0001
2024-03-31 10:59:19.022102: meanmse:       0.15198725
2024-03-31 10:59:19.023079: meanr2:        -0.2305998614112319
2024-03-31 10:59:19.023522: train_loss 0.7704
2024-03-31 10:59:19.023948: val_loss 0.6787
2024-03-31 10:59:19.024511: Pseudo dice [0.5]
2024-03-31 10:59:19.025280: Epoch time: 66.17 s
2024-03-31 10:59:24.563234: 
2024-03-31 10:59:24.564322: Epoch 5
2024-03-31 10:59:24.564875: Current learning rate: 0.0001
2024-03-31 11:00:28.863553: meanmse:       0.14752963
2024-03-31 11:00:28.865299: meanr2:        -0.18074627900345863
2024-03-31 11:00:28.866130: train_loss 0.7494
2024-03-31 11:00:28.866637: val_loss 0.6624
2024-03-31 11:00:28.867127: Pseudo dice [0.5]
2024-03-31 11:00:28.867642: Epoch time: 64.31 s
2024-03-31 11:00:33.940366: 
2024-03-31 11:00:33.941842: Epoch 6
2024-03-31 11:00:33.944031: Current learning rate: 9e-05
2024-03-31 11:01:37.583036: meanmse:       0.14220998
2024-03-31 11:01:37.584294: meanr2:        -0.13432168047773946
2024-03-31 11:01:37.584778: train_loss 0.7403
2024-03-31 11:01:37.585206: val_loss 0.6468
2024-03-31 11:01:37.585769: Pseudo dice [0.5]
2024-03-31 11:01:37.586372: Epoch time: 63.65 s
self._now_r2:  -0.13432168047773946    max(self._all_r2):   -0.13432168047773946
2024-03-31 11:01:37.587108: Yayy! New best R2: -0.1343
2024-03-31 11:01:47.375039: 
2024-03-31 11:01:47.467270: Epoch 7
2024-03-31 11:01:47.468992: Current learning rate: 9e-05
2024-03-31 11:02:43.633124: meanmse:       0.13808858
2024-03-31 11:02:43.634995: meanr2:        -0.1165944567013771
2024-03-31 11:02:43.636333: train_loss 0.6835
2024-03-31 11:02:43.637075: val_loss 0.6343
2024-03-31 11:02:43.639527: Pseudo dice [0.5]
2024-03-31 11:02:43.641757: Epoch time: 56.27 s
self._now_r2:  -0.1165944567013771    max(self._all_r2):   -0.1165944567013771
2024-03-31 11:02:43.642922: Yayy! New best R2: -0.1166
2024-03-31 11:02:51.123725: 
2024-03-31 11:02:51.124696: Epoch 8
2024-03-31 11:02:51.125257: Current learning rate: 9e-05
2024-03-31 11:03:49.900232: meanmse:       0.1374482
2024-03-31 11:03:49.932308: meanr2:        -0.10196882017080143
2024-03-31 11:03:49.933105: train_loss 0.8565
2024-03-31 11:03:49.933656: val_loss 0.6323
2024-03-31 11:03:49.934193: Pseudo dice [0.5]
2024-03-31 11:03:49.938075: Epoch time: 58.83 s
self._now_r2:  -0.10196882017080143    max(self._all_r2):   -0.10196882017080143
2024-03-31 11:03:49.941747: Yayy! New best R2: -0.102
2024-03-31 11:03:55.830049: 
2024-03-31 11:03:55.832195: Epoch 9
2024-03-31 11:03:55.833582: Current learning rate: 9e-05
2024-03-31 11:04:57.921131: meanmse:       0.1405699
2024-03-31 11:04:57.922242: meanr2:        -0.11900250714762303
2024-03-31 11:04:57.922753: train_loss 0.6656
2024-03-31 11:04:57.923159: val_loss 0.6228
2024-03-31 11:04:57.923643: Pseudo dice [0.5]
2024-03-31 11:04:57.924081: Epoch time: 62.1 s
2024-03-31 11:05:05.125990: 
2024-03-31 11:05:05.151698: Epoch 10
2024-03-31 11:05:05.152827: Current learning rate: 9e-05
2024-03-31 11:05:59.956260: meanmse:       0.13963895
2024-03-31 11:05:59.961323: meanr2:        -0.1381260947752603
2024-03-31 11:05:59.962034: train_loss 0.8109
2024-03-31 11:05:59.962482: val_loss 0.6219
2024-03-31 11:05:59.963068: Pseudo dice [0.5]
2024-03-31 11:05:59.963611: Epoch time: 54.92 s
2024-03-31 11:06:05.030664: 
2024-03-31 11:06:05.044086: Epoch 11
2024-03-31 11:06:05.045029: Current learning rate: 9e-05
2024-03-31 11:07:05.929134: meanmse:       0.13893308
2024-03-31 11:07:05.930584: meanr2:        -0.09619029089777957
2024-03-31 11:07:05.931206: train_loss 0.6976
2024-03-31 11:07:05.931610: val_loss 0.6257
2024-03-31 11:07:05.932114: Pseudo dice [0.5]
2024-03-31 11:07:05.932640: Epoch time: 60.92 s
self._now_r2:  -0.09619029089777957    max(self._all_r2):   -0.09619029089777957
2024-03-31 11:07:05.933135: Yayy! New best R2: -0.0962
2024-03-31 11:07:11.737497: 
2024-03-31 11:07:11.738453: Epoch 12
2024-03-31 11:07:11.739408: Current learning rate: 9e-05
2024-03-31 11:08:08.457553: meanmse:       0.13827926
2024-03-31 11:08:08.459933: meanr2:        -0.10568137964824159
2024-03-31 11:08:08.460600: train_loss 0.6206
2024-03-31 11:08:08.461195: val_loss 0.6234
2024-03-31 11:08:08.461710: Pseudo dice [0.5]
2024-03-31 11:08:08.462188: Epoch time: 56.74 s
2024-03-31 11:08:13.243487: 
2024-03-31 11:08:13.244460: Epoch 13
2024-03-31 11:08:13.245121: Current learning rate: 9e-05
2024-03-31 11:09:12.040485: meanmse:       0.1349656
2024-03-31 11:09:12.049073: meanr2:        -0.10222778039306712
2024-03-31 11:09:12.049789: train_loss 0.653
2024-03-31 11:09:12.050247: val_loss 0.6158
2024-03-31 11:09:12.050695: Pseudo dice [0.5]
2024-03-31 11:09:12.051157: Epoch time: 58.81 s
2024-03-31 11:09:16.673774: 
2024-03-31 11:09:16.674584: Epoch 14
2024-03-31 11:09:16.675227: Current learning rate: 9e-05
2024-03-31 11:10:15.335794: meanmse:       0.14223117
2024-03-31 11:10:15.338776: meanr2:        -0.1697170843568533
2024-03-31 11:10:15.341990: train_loss 0.7274
2024-03-31 11:10:15.342874: val_loss 0.6173
2024-03-31 11:10:15.343535: Pseudo dice [0.5]
2024-03-31 11:10:15.346398: Epoch time: 58.68 s
2024-03-31 11:10:19.629098: 
2024-03-31 11:10:19.630961: Epoch 15
2024-03-31 11:10:19.632562: Current learning rate: 9e-05
2024-03-31 11:11:16.737626: meanmse:       0.14256257
2024-03-31 11:11:16.739393: meanr2:        -0.13922523554918706
2024-03-31 11:11:16.742158: train_loss 0.7291
2024-03-31 11:11:16.746135: val_loss 0.6176
2024-03-31 11:11:16.746669: Pseudo dice [0.5]
2024-03-31 11:11:16.747204: Epoch time: 57.12 s
2024-03-31 11:11:21.831465: 
2024-03-31 11:11:21.832256: Epoch 16
2024-03-31 11:11:21.832816: Current learning rate: 9e-05
2024-03-31 11:12:17.825986: meanmse:       0.13620837
2024-03-31 11:12:17.827485: meanr2:        -0.08517606663574427
2024-03-31 11:12:17.828223: train_loss 0.6188
2024-03-31 11:12:17.828786: val_loss 0.6154
2024-03-31 11:12:17.829446: Pseudo dice [0.5]
2024-03-31 11:12:17.830051: Epoch time: 56.01 s
self._now_r2:  -0.08517606663574427    max(self._all_r2):   -0.08517606663574427
2024-03-31 11:12:17.830635: Yayy! New best R2: -0.0852
2024-03-31 11:12:24.328716: 
2024-03-31 11:12:24.330419: Epoch 17
2024-03-31 11:12:24.331429: Current learning rate: 8e-05
2024-03-31 11:13:15.929904: meanmse:       0.13891472
2024-03-31 11:13:15.931431: meanr2:        -0.09106128619186087
2024-03-31 11:13:15.932014: train_loss 0.7253
2024-03-31 11:13:15.932517: val_loss 0.618
2024-03-31 11:13:15.932934: Pseudo dice [0.5]
2024-03-31 11:13:15.933443: Epoch time: 51.61 s
2024-03-31 11:13:23.281744: 
2024-03-31 11:13:23.282747: Epoch 18
2024-03-31 11:13:23.283367: Current learning rate: 8e-05
2024-03-31 11:14:19.649838: meanmse:       0.13518152
2024-03-31 11:14:19.650804: meanr2:        -0.09214047819762701
2024-03-31 11:14:19.651380: train_loss 0.6165
2024-03-31 11:14:19.652083: val_loss 0.6178
2024-03-31 11:14:19.652570: Pseudo dice [0.5]
2024-03-31 11:14:19.653012: Epoch time: 56.38 s
2024-03-31 11:14:23.878220: 
2024-03-31 11:14:23.917377: Epoch 19
2024-03-31 11:14:23.928505: Current learning rate: 8e-05
2024-03-31 11:15:23.636560: meanmse:       0.13729161
2024-03-31 11:15:23.643642: meanr2:        -0.10410617346648632
2024-03-31 11:15:23.645057: train_loss 0.6173
2024-03-31 11:15:23.645719: val_loss 0.6172
2024-03-31 11:15:23.646331: Pseudo dice [0.5]
2024-03-31 11:15:23.647144: Epoch time: 59.78 s
2024-03-31 11:15:29.331528: 
2024-03-31 11:15:29.333369: Epoch 20
2024-03-31 11:15:29.334211: Current learning rate: 8e-05
2024-03-31 11:16:24.126475: meanmse:       0.13707873
2024-03-31 11:16:24.172009: meanr2:        -0.09385864665400774
2024-03-31 11:16:24.172569: train_loss 0.6939
2024-03-31 11:16:24.172927: val_loss 0.615
2024-03-31 11:16:24.173294: Pseudo dice [0.5]
2024-03-31 11:16:24.173722: Epoch time: 54.85 s
2024-03-31 11:16:29.263650: 
2024-03-31 11:16:29.265428: Epoch 21
2024-03-31 11:16:29.266976: Current learning rate: 8e-05
2024-03-31 11:17:29.027463: meanmse:       0.13771082
2024-03-31 11:17:29.028709: meanr2:        -0.1255613320943524
2024-03-31 11:17:29.029450: train_loss 0.7282
2024-03-31 11:17:29.031270: val_loss 0.6105
2024-03-31 11:17:29.032310: Pseudo dice [0.5]
2024-03-31 11:17:29.033079: Epoch time: 59.79 s
2024-03-31 11:17:34.725873: 
2024-03-31 11:17:34.726600: Epoch 22
2024-03-31 11:17:34.727127: Current learning rate: 8e-05
2024-03-31 11:18:30.766784: meanmse:       0.13965367
2024-03-31 11:18:30.768182: meanr2:        -0.1335331883616872
2024-03-31 11:18:30.768800: train_loss 0.6872
2024-03-31 11:18:30.769234: val_loss 0.6164
2024-03-31 11:18:30.769632: Pseudo dice [0.5]
2024-03-31 11:18:30.770067: Epoch time: 56.05 s
2024-03-31 11:18:35.655422: 
2024-03-31 11:18:35.656296: Epoch 23
2024-03-31 11:18:35.656851: Current learning rate: 8e-05
2024-03-31 11:19:32.053074: meanmse:       0.13597332
2024-03-31 11:19:32.120707: meanr2:        -0.10011470589062993
2024-03-31 11:19:32.122248: train_loss 0.7229
2024-03-31 11:19:32.124248: val_loss 0.6102
2024-03-31 11:19:32.125243: Pseudo dice [0.5]
2024-03-31 11:19:32.126340: Epoch time: 56.47 s
2024-03-31 11:19:36.976040: 
2024-03-31 11:19:36.976955: Epoch 24
2024-03-31 11:19:36.977488: Current learning rate: 8e-05
2024-03-31 11:20:36.874824: meanmse:       0.13721782
2024-03-31 11:20:36.876184: meanr2:        -0.08848822154005737
2024-03-31 11:20:36.877287: train_loss 0.6494
2024-03-31 11:20:36.877943: val_loss 0.6169
2024-03-31 11:20:36.878569: Pseudo dice [0.5]
2024-03-31 11:20:36.879107: Epoch time: 59.91 s
2024-03-31 11:20:42.122790: 
2024-03-31 11:20:42.162338: Epoch 25
2024-03-31 11:20:42.163371: Current learning rate: 8e-05
2024-03-31 11:21:35.527991: meanmse:       0.13710219
2024-03-31 11:21:35.529085: meanr2:        -0.07772538140643064
2024-03-31 11:21:35.529716: train_loss 0.6568
2024-03-31 11:21:35.530235: val_loss 0.6181
2024-03-31 11:21:35.530652: Pseudo dice [0.5]
2024-03-31 11:21:35.531095: Epoch time: 53.43 s
self._now_r2:  -0.07772538140643064    max(self._all_r2):   -0.07772538140643064
2024-03-31 11:21:35.531529: Yayy! New best R2: -0.0777
2024-03-31 11:21:42.428258: 
2024-03-31 11:21:42.433298: Epoch 26
2024-03-31 11:21:42.434245: Current learning rate: 8e-05
2024-03-31 11:22:40.261860: meanmse:       0.13555552
2024-03-31 11:22:40.263363: meanr2:        -0.09686339762035837
2024-03-31 11:22:40.264048: train_loss 0.7673
2024-03-31 11:22:40.264723: val_loss 0.611
2024-03-31 11:22:40.265210: Pseudo dice [0.5]
2024-03-31 11:22:40.265664: Epoch time: 57.85 s
2024-03-31 11:22:45.152366: 
2024-03-31 11:22:45.153416: Epoch 27
2024-03-31 11:22:45.154077: Current learning rate: 8e-05
2024-03-31 11:23:42.227458: meanmse:       0.13760045
2024-03-31 11:23:42.228503: meanr2:        -0.10021985930654607
2024-03-31 11:23:42.228991: train_loss 0.7285
2024-03-31 11:23:42.229362: val_loss 0.611
2024-03-31 11:23:42.229824: Pseudo dice [0.5]
2024-03-31 11:23:42.230430: Epoch time: 57.08 s
2024-03-31 11:23:46.824510: 
2024-03-31 11:23:46.825639: Epoch 28
2024-03-31 11:23:46.826547: Current learning rate: 7e-05
2024-03-31 11:24:45.976769: meanmse:       0.13654879
2024-03-31 11:24:45.978125: meanr2:        -0.08572275404542114
2024-03-31 11:24:45.978651: train_loss 0.6843
2024-03-31 11:24:45.979063: val_loss 0.6131
2024-03-31 11:24:45.979504: Pseudo dice [0.5]
2024-03-31 11:24:45.979958: Epoch time: 59.17 s
2024-03-31 11:24:50.535418: 
2024-03-31 11:24:50.536062: Epoch 29
2024-03-31 11:24:50.537184: Current learning rate: 7e-05
2024-03-31 11:25:45.124123: meanmse:       0.1394017
2024-03-31 11:25:45.169716: meanr2:        -0.12020293498672409
2024-03-31 11:25:45.175593: train_loss 0.6521
2024-03-31 11:25:45.176348: val_loss 0.6138
2024-03-31 11:25:45.180154: Pseudo dice [0.5]
2024-03-31 11:25:45.180677: Epoch time: 54.65 s
2024-03-31 11:25:50.420754: 
2024-03-31 11:25:50.421835: Epoch 30
2024-03-31 11:25:50.422376: Current learning rate: 7e-05
2024-03-31 11:26:46.694333: meanmse:       0.13306083
2024-03-31 11:26:46.695359: meanr2:        -0.051196616547981674
2024-03-31 11:26:46.695938: train_loss 0.6826
2024-03-31 11:26:46.696388: val_loss 0.6144
2024-03-31 11:26:46.696933: Pseudo dice [0.5]
2024-03-31 11:26:46.697433: Epoch time: 56.3 s
self._now_r2:  -0.051196616547981674    max(self._all_r2):   -0.051196616547981674
2024-03-31 11:26:46.697874: Yayy! New best R2: -0.0512
2024-03-31 11:26:51.754255: 
2024-03-31 11:26:51.755005: Epoch 31
2024-03-31 11:26:51.755511: Current learning rate: 7e-05
2024-03-31 11:27:47.127501: meanmse:       0.13851634
2024-03-31 11:27:47.145723: meanr2:        -0.11521272702032556
2024-03-31 11:27:47.146370: train_loss 0.7985
2024-03-31 11:27:47.146813: val_loss 0.6156
2024-03-31 11:27:47.147364: Pseudo dice [0.5]
2024-03-31 11:27:47.147827: Epoch time: 55.4 s
2024-03-31 11:27:51.945586: 
2024-03-31 11:27:51.947071: Epoch 32
2024-03-31 11:27:51.947739: Current learning rate: 7e-05
2024-03-31 11:28:49.654013: meanmse:       0.13845912
2024-03-31 11:28:49.654963: meanr2:        -0.10843215126083885
2024-03-31 11:28:49.655592: train_loss 0.7213
2024-03-31 11:28:49.656126: val_loss 0.61
2024-03-31 11:28:49.656555: Pseudo dice [0.5]
2024-03-31 11:28:49.657132: Epoch time: 57.72 s
2024-03-31 11:28:54.780938: 
2024-03-31 11:28:54.793578: Epoch 33
2024-03-31 11:28:54.794485: Current learning rate: 7e-05
2024-03-31 11:29:52.324382: meanmse:       0.14085515
2024-03-31 11:29:52.334339: meanr2:        -0.12142891518575137
2024-03-31 11:29:52.336271: train_loss 0.7151
2024-03-31 11:29:52.337184: val_loss 0.611
2024-03-31 11:29:52.337831: Pseudo dice [0.5]
2024-03-31 11:29:52.338503: Epoch time: 57.56 s
2024-03-31 11:29:57.435395: 
2024-03-31 11:29:57.437595: Epoch 34
2024-03-31 11:29:57.438466: Current learning rate: 7e-05
2024-03-31 11:30:54.971833: meanmse:       0.13548088
2024-03-31 11:30:54.972866: meanr2:        -0.08053259034191435
2024-03-31 11:30:54.973496: train_loss 0.6385
2024-03-31 11:30:54.973984: val_loss 0.5937
2024-03-31 11:30:54.974512: Pseudo dice [0.5]
2024-03-31 11:30:54.975011: Epoch time: 57.55 s
2024-03-31 11:30:59.520540: 
2024-03-31 11:30:59.521854: Epoch 35
2024-03-31 11:30:59.523355: Current learning rate: 7e-05
2024-03-31 11:31:53.635897: meanmse:       0.13254447
2024-03-31 11:31:53.636718: meanr2:        -0.06261485236415962
2024-03-31 11:31:53.637295: train_loss 0.7577
2024-03-31 11:31:53.638131: val_loss 0.5704
2024-03-31 11:31:53.638572: Pseudo dice [0.5]
2024-03-31 11:31:53.639050: Epoch time: 54.17 s
2024-03-31 11:31:58.742373: 
2024-03-31 11:31:58.744176: Epoch 36
2024-03-31 11:31:58.744950: Current learning rate: 7e-05
2024-03-31 11:32:56.959709: meanmse:       0.12921435
2024-03-31 11:32:56.961175: meanr2:        -0.03271435294485249
2024-03-31 11:32:56.961731: train_loss 0.5821
2024-03-31 11:32:56.962134: val_loss 0.5413
2024-03-31 11:32:56.962629: Pseudo dice [0.5]
2024-03-31 11:32:56.963271: Epoch time: 58.24 s
self._now_r2:  -0.03271435294485249    max(self._all_r2):   -0.03271435294485249
2024-03-31 11:32:56.963879: Yayy! New best R2: -0.0327
2024-03-31 11:33:03.251322: 
2024-03-31 11:33:03.252521: Epoch 37
2024-03-31 11:33:03.253185: Current learning rate: 7e-05
2024-03-31 11:33:57.659961: meanmse:       0.13466565
2024-03-31 11:33:57.660927: meanr2:        -0.07462289011267757
2024-03-31 11:33:57.661388: train_loss 0.5472
2024-03-31 11:33:57.661707: val_loss 0.5506
2024-03-31 11:33:57.662011: Pseudo dice [0.5]
2024-03-31 11:33:57.662427: Epoch time: 54.42 s
2024-03-31 11:34:04.437645: 
2024-03-31 11:34:04.438552: Epoch 38
2024-03-31 11:34:04.439209: Current learning rate: 7e-05
2024-03-31 11:35:00.834103: meanmse:       0.12625447
2024-03-31 11:35:00.835645: meanr2:        -0.0296801665160765
2024-03-31 11:35:00.836413: train_loss 0.661
2024-03-31 11:35:00.836848: val_loss 0.5228
2024-03-31 11:35:00.837340: Pseudo dice [0.5]
2024-03-31 11:35:00.837826: Epoch time: 56.41 s
self._now_r2:  -0.0296801665160765    max(self._all_r2):   -0.0296801665160765
2024-03-31 11:35:00.863949: Yayy! New best R2: -0.0297
2024-03-31 11:35:07.862470: 
2024-03-31 11:35:07.864487: Epoch 39
2024-03-31 11:35:07.865471: Current learning rate: 6e-05
2024-03-31 11:36:05.039997: meanmse:       0.12679651
2024-03-31 11:36:05.041276: meanr2:        -0.018502482990102796
2024-03-31 11:36:05.042035: train_loss 0.6514
2024-03-31 11:36:05.042812: val_loss 0.5187
2024-03-31 11:36:05.043316: Pseudo dice [0.5]
2024-03-31 11:36:05.043714: Epoch time: 57.19 s
self._now_r2:  -0.018502482990102796    max(self._all_r2):   -0.018502482990102796
2024-03-31 11:36:06.162855: Yayy! New best R2: -0.0185
2024-03-31 11:36:12.126550: 
2024-03-31 11:36:12.127726: Epoch 40
2024-03-31 11:36:12.128593: Current learning rate: 6e-05
2024-03-31 11:37:08.473936: meanmse:       0.12629649
2024-03-31 11:37:08.475793: meanr2:        -0.02357924083445347
2024-03-31 11:37:08.476391: train_loss 0.6074
2024-03-31 11:37:08.476865: val_loss 0.5147
2024-03-31 11:37:08.477366: Pseudo dice [0.5]
2024-03-31 11:37:08.477792: Epoch time: 56.36 s
2024-03-31 11:37:15.355131: 
2024-03-31 11:37:15.356735: Epoch 41
2024-03-31 11:37:15.357560: Current learning rate: 6e-05
2024-03-31 11:38:13.331029: meanmse:       0.12639928
2024-03-31 11:38:13.332112: meanr2:        -0.012515715544467584
2024-03-31 11:38:13.332740: train_loss 0.5156
2024-03-31 11:38:13.333380: val_loss 0.5184
2024-03-31 11:38:13.333951: Pseudo dice [0.5]
2024-03-31 11:38:13.334702: Epoch time: 57.99 s
self._now_r2:  -0.012515715544467584    max(self._all_r2):   -0.012515715544467584
2024-03-31 11:38:13.335329: Yayy! New best R2: -0.0125
2024-03-31 11:38:19.594923: 
2024-03-31 11:38:19.598374: Epoch 42
2024-03-31 11:38:19.599054: Current learning rate: 6e-05
2024-03-31 11:39:18.137297: meanmse:       0.12532878
2024-03-31 11:39:18.139217: meanr2:        -0.014753740927273181
2024-03-31 11:39:18.139812: train_loss 0.577
2024-03-31 11:39:18.140318: val_loss 0.5152
2024-03-31 11:39:18.140745: Pseudo dice [0.5]
2024-03-31 11:39:18.141144: Epoch time: 58.56 s
2024-03-31 11:39:23.047171: 
2024-03-31 11:39:23.048069: Epoch 43
2024-03-31 11:39:23.048556: Current learning rate: 6e-05
2024-03-31 11:40:24.036463: meanmse:       0.12448719
2024-03-31 11:40:24.038898: meanr2:        -0.0018799607840516892
2024-03-31 11:40:24.040583: train_loss 0.61
2024-03-31 11:40:24.042025: val_loss 0.5135
2024-03-31 11:40:24.042585: Pseudo dice [0.5]
2024-03-31 11:40:24.042992: Epoch time: 61.0 s
self._now_r2:  -0.0018799607840516892    max(self._all_r2):   -0.0018799607840516892
2024-03-31 11:40:24.043373: Yayy! New best R2: -0.0019
2024-03-31 11:40:29.518775: 
2024-03-31 11:40:29.519655: Epoch 44
2024-03-31 11:40:29.520349: Current learning rate: 6e-05
2024-03-31 11:41:22.932703: meanmse:       0.12635162
2024-03-31 11:41:22.934867: meanr2:        -0.006402558657446729
2024-03-31 11:41:22.935349: train_loss 0.5426
2024-03-31 11:41:22.935879: val_loss 0.5115
2024-03-31 11:41:22.936288: Pseudo dice [0.5]
2024-03-31 11:41:22.936719: Epoch time: 53.45 s
2024-03-31 11:41:27.759900: 
2024-03-31 11:41:27.761358: Epoch 45
2024-03-31 11:41:27.762102: Current learning rate: 6e-05
2024-03-31 11:42:24.838901: meanmse:       0.12605883
2024-03-31 11:42:24.840068: meanr2:        -0.008803400338833966
2024-03-31 11:42:24.840615: train_loss 0.6353
2024-03-31 11:42:24.841413: val_loss 0.5093
2024-03-31 11:42:24.841902: Pseudo dice [0.5]
2024-03-31 11:42:24.842374: Epoch time: 57.09 s
2024-03-31 11:42:30.726277: 
2024-03-31 11:42:30.728131: Epoch 46
2024-03-31 11:42:30.730412: Current learning rate: 6e-05
2024-03-31 11:43:29.237465: meanmse:       0.12426833
2024-03-31 11:43:29.258715: meanr2:        0.0019463661858634253
2024-03-31 11:43:29.259506: train_loss 0.5712
2024-03-31 11:43:29.260289: val_loss 0.5132
2024-03-31 11:43:29.260758: Pseudo dice [0.5]
2024-03-31 11:43:29.261270: Epoch time: 58.54 s
self._now_r2:  0.0019463661858634253    max(self._all_r2):   0.0019463661858634253
2024-03-31 11:43:29.261774: Yayy! New best R2: 0.0019
2024-03-31 11:43:35.127712: 
2024-03-31 11:43:35.129317: Epoch 47
2024-03-31 11:43:35.130477: Current learning rate: 6e-05
2024-03-31 11:44:27.568060: meanmse:       0.1253558
2024-03-31 11:44:27.572089: meanr2:        -0.009948557877633983
2024-03-31 11:44:27.572962: train_loss 0.5115
2024-03-31 11:44:27.573461: val_loss 0.5105
2024-03-31 11:44:27.573933: Pseudo dice [0.5]
2024-03-31 11:44:27.574397: Epoch time: 52.45 s
2024-03-31 11:44:32.628261: 
2024-03-31 11:44:32.650697: Epoch 48
2024-03-31 11:44:32.651420: Current learning rate: 6e-05
2024-03-31 11:45:28.833913: meanmse:       0.12490462
2024-03-31 11:45:28.835243: meanr2:        -0.002490270944037593
2024-03-31 11:45:28.835988: train_loss 0.5407
2024-03-31 11:45:28.836588: val_loss 0.5077
2024-03-31 11:45:28.837041: Pseudo dice [0.5]
2024-03-31 11:45:28.837566: Epoch time: 56.22 s
2024-03-31 11:45:34.446365: 
2024-03-31 11:45:34.447273: Epoch 49
2024-03-31 11:45:34.447806: Current learning rate: 5e-05
2024-03-31 11:46:30.658082: meanmse:       0.1233425
2024-03-31 11:46:30.659261: meanr2:        -0.001312235465477787
2024-03-31 11:46:30.659877: train_loss 0.5735
2024-03-31 11:46:30.660379: val_loss 0.5119
2024-03-31 11:46:30.660874: Pseudo dice [0.5]
2024-03-31 11:46:30.661348: Epoch time: 56.22 s
2024-03-31 11:46:36.423809: 
2024-03-31 11:46:36.424805: Epoch 50
2024-03-31 11:46:36.425525: Current learning rate: 5e-05
2024-03-31 11:47:26.345911: meanmse:       0.12605451
2024-03-31 11:47:26.346860: meanr2:        -0.00739729424123075
2024-03-31 11:47:26.347442: train_loss 0.5391
2024-03-31 11:47:26.347970: val_loss 0.5103
2024-03-31 11:47:26.348456: Pseudo dice [0.5]
2024-03-31 11:47:26.349009: Epoch time: 49.97 s
2024-03-31 11:47:30.826315: 
2024-03-31 11:47:30.827309: Epoch 51
2024-03-31 11:47:30.870131: Current learning rate: 5e-05
2024-03-31 11:48:30.246920: meanmse:       0.12294985
2024-03-31 11:48:30.257135: meanr2:        0.005148798576661864
2024-03-31 11:48:30.258413: train_loss 0.6082
2024-03-31 11:48:30.259528: val_loss 0.5096
2024-03-31 11:48:30.260143: Pseudo dice [0.5]
2024-03-31 11:48:30.261199: Epoch time: 59.44 s
self._now_r2:  0.005148798576661864    max(self._all_r2):   0.005148798576661864
2024-03-31 11:48:30.262475: Yayy! New best R2: 0.0051
2024-03-31 11:48:35.733156: 
2024-03-31 11:48:35.734313: Epoch 52
2024-03-31 11:48:35.734904: Current learning rate: 5e-05
2024-03-31 11:49:30.362477: meanmse:       0.1233044
2024-03-31 11:49:30.363840: meanr2:        0.00048746467856086717
2024-03-31 11:49:30.364346: train_loss 0.5403
2024-03-31 11:49:30.365513: val_loss 0.507
2024-03-31 11:49:30.366099: Pseudo dice [0.5]
2024-03-31 11:49:30.366740: Epoch time: 54.65 s
2024-03-31 11:49:35.385249: 
2024-03-31 11:49:35.386079: Epoch 53
2024-03-31 11:49:35.386594: Current learning rate: 5e-05
2024-03-31 11:50:32.031407: meanmse:       0.12657434
2024-03-31 11:50:32.041546: meanr2:        -0.01892196242741294
2024-03-31 11:50:32.042246: train_loss 0.5748
2024-03-31 11:50:32.042686: val_loss 0.5139
2024-03-31 11:50:32.043171: Pseudo dice [0.5]
2024-03-31 11:50:32.043636: Epoch time: 56.66 s
2024-03-31 11:50:37.495897: 
2024-03-31 11:50:37.497000: Epoch 54
2024-03-31 11:50:37.497620: Current learning rate: 5e-05
2024-03-31 11:51:32.317189: meanmse:       0.124388784
2024-03-31 11:51:32.318595: meanr2:        -0.0019348135428479932
2024-03-31 11:51:32.319262: train_loss 0.5115
2024-03-31 11:51:32.319823: val_loss 0.5113
2024-03-31 11:51:32.320337: Pseudo dice [0.5]
2024-03-31 11:51:32.320841: Epoch time: 54.83 s
2024-03-31 11:51:36.744521: 
2024-03-31 11:51:36.745184: Epoch 55
2024-03-31 11:51:36.745673: Current learning rate: 5e-05
2024-03-31 11:52:28.666625: meanmse:       0.12693967
2024-03-31 11:52:28.699846: meanr2:        -0.007755469867170572
2024-03-31 11:52:28.786302: train_loss 0.6302
2024-03-31 11:52:28.786837: val_loss 0.5119
2024-03-31 11:52:28.787211: Pseudo dice [0.5]
2024-03-31 11:52:28.787662: Epoch time: 52.05 s
2024-03-31 11:52:34.024609: 
2024-03-31 11:52:34.025885: Epoch 56
2024-03-31 11:52:34.026495: Current learning rate: 5e-05
2024-03-31 11:53:27.178823: meanmse:       0.12777703
2024-03-31 11:53:27.179688: meanr2:        -0.006967738924397233
2024-03-31 11:53:27.180182: train_loss 0.5734
2024-03-31 11:53:27.180536: val_loss 0.5161
2024-03-31 11:53:27.180871: Pseudo dice [0.5]
2024-03-31 11:53:27.181208: Epoch time: 53.16 s
2024-03-31 11:53:33.229275: 
2024-03-31 11:53:33.230275: Epoch 57
2024-03-31 11:53:33.230866: Current learning rate: 5e-05
2024-03-31 11:54:26.533685: meanmse:       0.12562416
2024-03-31 11:54:26.535089: meanr2:        -0.0046832867323851985
2024-03-31 11:54:26.535629: train_loss 0.6349
2024-03-31 11:54:26.536197: val_loss 0.5102
2024-03-31 11:54:26.555784: Pseudo dice [0.5]
2024-03-31 11:54:26.556709: Epoch time: 53.32 s
2024-03-31 11:54:31.976847: 
2024-03-31 11:54:32.030247: Epoch 58
2024-03-31 11:54:32.031165: Current learning rate: 5e-05
2024-03-31 11:55:23.452836: meanmse:       0.12377891
2024-03-31 11:55:23.455074: meanr2:        0.0014129330012159584
2024-03-31 11:55:23.455876: train_loss 0.5445
2024-03-31 11:55:23.456449: val_loss 0.5078
2024-03-31 11:55:23.456929: Pseudo dice [0.5]
2024-03-31 11:55:23.458280: Epoch time: 51.49 s
2024-03-31 11:55:28.350689: 
2024-03-31 11:55:28.355111: Epoch 59
2024-03-31 11:55:28.355891: Current learning rate: 4e-05
2024-03-31 11:56:21.428985: meanmse:       0.12804441
2024-03-31 11:56:21.429972: meanr2:        -0.011996668819904861
2024-03-31 11:56:21.430653: train_loss 0.6062
2024-03-31 11:56:21.431177: val_loss 0.516
2024-03-31 11:56:21.431641: Pseudo dice [0.5]
2024-03-31 11:56:21.432215: Epoch time: 53.09 s
2024-03-31 11:56:27.749063: 
2024-03-31 11:56:27.757185: Epoch 60
2024-03-31 11:56:27.758206: Current learning rate: 4e-05
2024-03-31 11:57:17.635677: meanmse:       0.12485339
2024-03-31 11:57:17.637058: meanr2:        0.0017395469932396995
2024-03-31 11:57:17.637930: train_loss 0.5089
2024-03-31 11:57:17.638478: val_loss 0.5061
2024-03-31 11:57:17.638958: Pseudo dice [0.5]
2024-03-31 11:57:17.639455: Epoch time: 49.9 s
2024-03-31 11:57:24.676042: 
2024-03-31 11:57:24.677042: Epoch 61
2024-03-31 11:57:24.677590: Current learning rate: 4e-05
2024-03-31 11:58:16.562403: meanmse:       0.12653443
2024-03-31 11:58:16.569065: meanr2:        -0.013270903614093381
2024-03-31 11:58:16.570041: train_loss 0.5681
2024-03-31 11:58:16.571527: val_loss 0.5101
2024-03-31 11:58:16.571912: Pseudo dice [0.5]
2024-03-31 11:58:16.572314: Epoch time: 51.9 s
2024-03-31 11:58:22.230622: 
2024-03-31 11:58:22.231638: Epoch 62
2024-03-31 11:58:22.232273: Current learning rate: 4e-05
2024-03-31 11:59:13.827450: meanmse:       0.12594254
2024-03-31 11:59:13.828415: meanr2:        -0.00792504650614033
2024-03-31 11:59:13.829008: train_loss 0.5714
2024-03-31 11:59:13.829500: val_loss 0.5118
2024-03-31 11:59:13.830019: Pseudo dice [0.5]
2024-03-31 11:59:13.830557: Epoch time: 51.61 s
2024-03-31 11:59:19.225569: 
2024-03-31 11:59:19.226941: Epoch 63
2024-03-31 11:59:19.227596: Current learning rate: 4e-05
2024-03-31 12:00:07.641311: meanmse:       0.12420955
2024-03-31 12:00:07.642195: meanr2:        -0.0009264493278383141
2024-03-31 12:00:07.642815: train_loss 0.6042
2024-03-31 12:00:07.643269: val_loss 0.5082
2024-03-31 12:00:07.643890: Pseudo dice [0.5]
2024-03-31 12:00:07.644495: Epoch time: 48.43 s
2024-03-31 12:00:12.948054: 
2024-03-31 12:00:12.949048: Epoch 64
2024-03-31 12:00:12.949689: Current learning rate: 4e-05
2024-03-31 12:01:05.867815: meanmse:       0.12453762
2024-03-31 12:01:05.928531: meanr2:        0.0012264375409665308
2024-03-31 12:01:05.932841: train_loss 0.6116
2024-03-31 12:01:05.934284: val_loss 0.5113
2024-03-31 12:01:05.935114: Pseudo dice [0.5]
2024-03-31 12:01:05.935797: Epoch time: 52.99 s
2024-03-31 12:01:11.618743: 
2024-03-31 12:01:11.619803: Epoch 65
2024-03-31 12:01:11.620446: Current learning rate: 4e-05
2024-03-31 12:02:01.468280: meanmse:       0.12532578
2024-03-31 12:02:01.469816: meanr2:        -0.001330268946473207
2024-03-31 12:02:01.470567: train_loss 0.6051
2024-03-31 12:02:01.471127: val_loss 0.5084
2024-03-31 12:02:01.471770: Pseudo dice [0.5]
2024-03-31 12:02:01.472362: Epoch time: 49.9 s
2024-03-31 12:02:07.073003: 
2024-03-31 12:02:07.074301: Epoch 66
2024-03-31 12:02:07.075351: Current learning rate: 4e-05
2024-03-31 12:02:59.459903: meanmse:       0.12687747
2024-03-31 12:02:59.461469: meanr2:        -0.012094701539698938
2024-03-31 12:02:59.463023: train_loss 0.5099
2024-03-31 12:02:59.463969: val_loss 0.5146
2024-03-31 12:02:59.464597: Pseudo dice [0.5]
2024-03-31 12:02:59.465257: Epoch time: 52.4 s
2024-03-31 12:03:05.150295: 
2024-03-31 12:03:05.152811: Epoch 67
2024-03-31 12:03:05.153409: Current learning rate: 4e-05
2024-03-31 12:03:51.932998: meanmse:       0.12715165
2024-03-31 12:03:51.934325: meanr2:        -0.012854688343386298
2024-03-31 12:03:51.934836: train_loss 0.5704
2024-03-31 12:03:51.935312: val_loss 0.5107
2024-03-31 12:03:51.935759: Pseudo dice [0.5]
2024-03-31 12:03:51.936270: Epoch time: 46.8 s
2024-03-31 12:03:57.340300: 
2024-03-31 12:03:57.342086: Epoch 68
2024-03-31 12:03:57.343876: Current learning rate: 4e-05
2024-03-31 12:04:48.050661: meanmse:       0.12549767
2024-03-31 12:04:48.051595: meanr2:        -0.011021204731341543
2024-03-31 12:04:48.052160: train_loss 0.5095
2024-03-31 12:04:48.052607: val_loss 0.5191
2024-03-31 12:04:48.053066: Pseudo dice [0.5]
2024-03-31 12:04:48.053575: Epoch time: 50.72 s
2024-03-31 12:04:54.044543: 
2024-03-31 12:04:54.045711: Epoch 69
2024-03-31 12:04:54.046302: Current learning rate: 3e-05
2024-03-31 12:05:47.423406: meanmse:       0.12548429
2024-03-31 12:05:47.440518: meanr2:        0.0034459179063403753
2024-03-31 12:05:47.441452: train_loss 0.5367
2024-03-31 12:05:47.442050: val_loss 0.5117
2024-03-31 12:05:47.442714: Pseudo dice [0.5]
2024-03-31 12:05:47.443872: Epoch time: 53.46 s
2024-03-31 12:05:55.150631: 
2024-03-31 12:05:55.158149: Epoch 70
2024-03-31 12:05:55.158862: Current learning rate: 3e-05
2024-03-31 12:06:42.971071: meanmse:       0.12744606
2024-03-31 12:06:42.971676: meanr2:        -0.008882442615882903
2024-03-31 12:06:42.972123: train_loss 0.6065
2024-03-31 12:06:42.972452: val_loss 0.5097
2024-03-31 12:06:42.972765: Pseudo dice [0.5]
2024-03-31 12:06:42.973255: Epoch time: 47.83 s
2024-03-31 12:06:48.154418: 
2024-03-31 12:06:48.166693: Epoch 71
2024-03-31 12:06:48.167365: Current learning rate: 3e-05
2024-03-31 12:07:38.862012: meanmse:       0.12557136
2024-03-31 12:07:38.864442: meanr2:        -0.009968943084959868
2024-03-31 12:07:38.864950: train_loss 0.6952
2024-03-31 12:07:38.865332: val_loss 0.5117
2024-03-31 12:07:38.865716: Pseudo dice [0.5]
2024-03-31 12:07:38.866548: Epoch time: 50.72 s
2024-03-31 12:07:44.042192: 
2024-03-31 12:07:44.050775: Epoch 72
2024-03-31 12:07:44.051424: Current learning rate: 3e-05
2024-03-31 12:08:38.676771: meanmse:       0.12606218
2024-03-31 12:08:38.721298: meanr2:        -0.0022235203148003313
2024-03-31 12:08:38.722904: train_loss 0.5672
2024-03-31 12:08:38.723454: val_loss 0.5134
2024-03-31 12:08:38.724049: Pseudo dice [0.5]
2024-03-31 12:08:38.724640: Epoch time: 54.7 s
2024-03-31 12:08:43.524820: 
2024-03-31 12:08:43.525667: Epoch 73
2024-03-31 12:08:43.526282: Current learning rate: 3e-05
2024-03-31 12:09:32.126167: meanmse:       0.1266411
2024-03-31 12:09:32.161452: meanr2:        -0.006917382468457893
2024-03-31 12:09:32.162154: train_loss 0.6341
2024-03-31 12:09:32.162531: val_loss 0.5119
2024-03-31 12:09:32.162858: Pseudo dice [0.5]
2024-03-31 12:09:32.269735: Epoch time: 48.64 s
2024-03-31 12:09:39.923510: 
2024-03-31 12:09:39.925720: Epoch 74
2024-03-31 12:09:39.926491: Current learning rate: 3e-05
2024-03-31 12:10:29.442410: meanmse:       0.12573521
2024-03-31 12:10:29.443725: meanr2:        -0.009148821908083034
2024-03-31 12:10:29.444334: train_loss 0.5436
2024-03-31 12:10:29.444838: val_loss 0.5112
2024-03-31 12:10:29.445493: Pseudo dice [0.5]
2024-03-31 12:10:29.446037: Epoch time: 49.53 s
2024-03-31 12:10:35.838905: 
2024-03-31 12:10:35.840302: Epoch 75
2024-03-31 12:10:35.841206: Current learning rate: 3e-05
2024-03-31 12:11:25.030329: meanmse:       0.12385228
2024-03-31 12:11:25.035181: meanr2:        0.0053415233177623745
2024-03-31 12:11:25.035840: train_loss 0.5411
2024-03-31 12:11:25.036316: val_loss 0.5108
2024-03-31 12:11:25.036800: Pseudo dice [0.5]
2024-03-31 12:11:25.037188: Epoch time: 49.2 s
self._now_r2:  0.0053415233177623745    max(self._all_r2):   0.0053415233177623745
2024-03-31 12:11:25.037550: Yayy! New best R2: 0.0053
2024-03-31 12:11:32.138006: 
2024-03-31 12:11:32.139678: Epoch 76
2024-03-31 12:11:32.140399: Current learning rate: 3e-05
2024-03-31 12:12:21.229912: meanmse:       0.1269687
2024-03-31 12:12:21.247439: meanr2:        -0.010053511349929009
2024-03-31 12:12:21.248539: train_loss 0.5397
2024-03-31 12:12:21.249372: val_loss 0.5161
2024-03-31 12:12:21.250130: Pseudo dice [0.5]
2024-03-31 12:12:21.253030: Epoch time: 49.12 s
2024-03-31 12:12:27.417962: 
2024-03-31 12:12:27.418765: Epoch 77
2024-03-31 12:12:27.419343: Current learning rate: 3e-05
2024-03-31 12:13:18.648515: meanmse:       0.12675034
2024-03-31 12:13:18.754573: meanr2:        -0.013286063415238513
2024-03-31 12:13:18.755681: train_loss 0.5729
2024-03-31 12:13:18.756438: val_loss 0.5124
2024-03-31 12:13:18.757072: Pseudo dice [0.5]
2024-03-31 12:13:18.757895: Epoch time: 51.39 s
2024-03-31 12:13:25.241265: 
2024-03-31 12:13:25.242585: Epoch 78
2024-03-31 12:13:25.243330: Current learning rate: 3e-05
2024-03-31 12:14:12.825770: meanmse:       0.12428824
2024-03-31 12:14:12.826761: meanr2:        -0.0005962263474762598
2024-03-31 12:14:12.827543: train_loss 0.5741
2024-03-31 12:14:12.828580: val_loss 0.5088
2024-03-31 12:14:12.829229: Pseudo dice [0.5]
2024-03-31 12:14:12.829874: Epoch time: 47.59 s
2024-03-31 12:14:19.232719: 
2024-03-31 12:14:19.236252: Epoch 79
2024-03-31 12:14:19.236810: Current learning rate: 2e-05
2024-03-31 12:15:08.440487: meanmse:       0.12504779
2024-03-31 12:15:08.441461: meanr2:        -0.00474689530341093
2024-03-31 12:15:08.441994: train_loss 0.5414
2024-03-31 12:15:08.442831: val_loss 0.5101
2024-03-31 12:15:08.443388: Pseudo dice [0.5]
2024-03-31 12:15:08.444126: Epoch time: 49.22 s
2024-03-31 12:15:15.261601: 
2024-03-31 12:15:15.262520: Epoch 80
2024-03-31 12:15:15.263100: Current learning rate: 2e-05
2024-03-31 12:16:07.892163: meanmse:       0.124574624
2024-03-31 12:16:07.893720: meanr2:        0.003285635836807891
2024-03-31 12:16:07.894444: train_loss 0.5372
2024-03-31 12:16:07.895205: val_loss 0.5057
2024-03-31 12:16:07.896213: Pseudo dice [0.5]
2024-03-31 12:16:07.896782: Epoch time: 52.64 s
2024-03-31 12:16:12.646270: 
2024-03-31 12:16:12.649473: Epoch 81
2024-03-31 12:16:12.650092: Current learning rate: 2e-05
2024-03-31 12:17:04.976600: meanmse:       0.12658554
2024-03-31 12:17:04.977463: meanr2:        -0.008593168619133161
2024-03-31 12:17:04.978101: train_loss 0.634
2024-03-31 12:17:04.978564: val_loss 0.515
2024-03-31 12:17:04.979035: Pseudo dice [0.5]
2024-03-31 12:17:04.979526: Epoch time: 52.34 s
2024-03-31 12:17:10.319186: 
2024-03-31 12:17:10.320276: Epoch 82
2024-03-31 12:17:10.320822: Current learning rate: 2e-05
2024-03-31 12:18:04.367768: meanmse:       0.12535197
2024-03-31 12:18:04.368752: meanr2:        -0.0021882832270493737
2024-03-31 12:18:04.369469: train_loss 0.5762
2024-03-31 12:18:04.370090: val_loss 0.5105
2024-03-31 12:18:04.370721: Pseudo dice [0.5]
2024-03-31 12:18:04.371397: Epoch time: 54.07 s
2024-03-31 12:18:09.125244: 
2024-03-31 12:18:09.126333: Epoch 83
2024-03-31 12:18:09.126822: Current learning rate: 2e-05
2024-03-31 12:18:59.024099: meanmse:       0.12409552
2024-03-31 12:18:59.025267: meanr2:        0.000840042629229851
2024-03-31 12:18:59.025887: train_loss 0.6315
2024-03-31 12:18:59.026384: val_loss 0.5125
2024-03-31 12:18:59.026824: Pseudo dice [0.5]
2024-03-31 12:18:59.027300: Epoch time: 49.91 s
2024-03-31 12:19:04.318237: 
2024-03-31 12:19:04.320550: Epoch 84
2024-03-31 12:19:04.321207: Current learning rate: 2e-05
2024-03-31 12:19:54.833399: meanmse:       0.12668867
2024-03-31 12:19:54.835094: meanr2:        -0.009901993978040159
2024-03-31 12:19:54.836199: train_loss 0.6268
2024-03-31 12:19:54.836850: val_loss 0.5151
2024-03-31 12:19:54.837590: Pseudo dice [0.5]
2024-03-31 12:19:54.838238: Epoch time: 50.54 s
2024-03-31 12:20:00.074172: 
2024-03-31 12:20:00.075273: Epoch 85
2024-03-31 12:20:00.076032: Current learning rate: 2e-05
2024-03-31 12:20:51.477426: meanmse:       0.12599915
2024-03-31 12:20:51.549005: meanr2:        -0.016930789706591134
2024-03-31 12:20:51.550134: train_loss 0.5366
2024-03-31 12:20:51.550919: val_loss 0.5148
2024-03-31 12:20:51.566942: Pseudo dice [0.5]
2024-03-31 12:20:51.567886: Epoch time: 51.48 s
2024-03-31 12:20:57.048393: 
2024-03-31 12:20:57.049594: Epoch 86
2024-03-31 12:20:57.050212: Current learning rate: 2e-05
2024-03-31 12:21:48.656040: meanmse:       0.12745036
2024-03-31 12:21:48.681291: meanr2:        -0.018466188819686424
2024-03-31 12:21:48.681908: train_loss 0.5665
2024-03-31 12:21:48.682364: val_loss 0.5092
2024-03-31 12:21:48.682790: Pseudo dice [0.5]
2024-03-31 12:21:48.717844: Epoch time: 51.64 s
2024-03-31 12:21:54.603384: 
2024-03-31 12:21:54.604551: Epoch 87
2024-03-31 12:21:54.605242: Current learning rate: 2e-05
2024-03-31 12:22:43.942076: meanmse:       0.124892935
2024-03-31 12:22:43.982442: meanr2:        -0.0047163832964857155
2024-03-31 12:22:43.983256: train_loss 0.5429
2024-03-31 12:22:44.020291: val_loss 0.5075
2024-03-31 12:22:44.021095: Pseudo dice [0.5]
2024-03-31 12:22:44.021519: Epoch time: 49.39 s
2024-03-31 12:22:48.719197: 
2024-03-31 12:22:48.722202: Epoch 88
2024-03-31 12:22:48.722902: Current learning rate: 1e-05
2024-03-31 12:23:43.131436: meanmse:       0.1252442
2024-03-31 12:23:43.132975: meanr2:        -0.0031915227148885273
2024-03-31 12:23:43.134149: train_loss 0.6325
2024-03-31 12:23:43.134767: val_loss 0.5106
2024-03-31 12:23:43.135336: Pseudo dice [0.5]
2024-03-31 12:23:43.135919: Epoch time: 54.47 s
2024-03-31 12:23:48.743463: 
2024-03-31 12:23:48.744951: Epoch 89
2024-03-31 12:23:48.746120: Current learning rate: 1e-05
2024-03-31 12:24:37.952373: meanmse:       0.12492177
2024-03-31 12:24:37.953404: meanr2:        -0.004240186413666229
2024-03-31 12:24:37.954019: train_loss 0.5702
2024-03-31 12:24:37.954488: val_loss 0.5096
2024-03-31 12:24:37.955072: Pseudo dice [0.5]
2024-03-31 12:24:37.955591: Epoch time: 49.22 s
2024-03-31 12:24:43.480852: 
2024-03-31 12:24:43.488342: Epoch 90
2024-03-31 12:24:43.489060: Current learning rate: 1e-05
2024-03-31 12:25:34.943685: meanmse:       0.12349125
2024-03-31 12:25:34.945844: meanr2:        0.005232422354487361
2024-03-31 12:25:35.049408: train_loss 0.5691
2024-03-31 12:25:35.050810: val_loss 0.5111
2024-03-31 12:25:35.052053: Pseudo dice [0.5]
2024-03-31 12:25:35.060233: Epoch time: 51.58 s
2024-03-31 12:25:41.042864: 
2024-03-31 12:25:41.045118: Epoch 91
2024-03-31 12:25:41.045890: Current learning rate: 1e-05
2024-03-31 12:26:33.527895: meanmse:       0.12467931
2024-03-31 12:26:33.528921: meanr2:        -0.0019114653327772081
2024-03-31 12:26:33.540832: train_loss 0.5404
2024-03-31 12:26:33.541471: val_loss 0.5141
2024-03-31 12:26:33.542049: Pseudo dice [0.5]
2024-03-31 12:26:33.543051: Epoch time: 52.51 s
2024-03-31 12:26:38.270859: 
2024-03-31 12:26:38.271775: Epoch 92
2024-03-31 12:26:38.272363: Current learning rate: 1e-05
2024-03-31 12:27:26.798480: meanmse:       0.12405161
2024-03-31 12:27:26.824039: meanr2:        0.006007152675604255
2024-03-31 12:27:26.825122: train_loss 0.6321
2024-03-31 12:27:26.825856: val_loss 0.5101
2024-03-31 12:27:26.826519: Pseudo dice [0.5]
2024-03-31 12:27:26.827219: Epoch time: 48.56 s
self._now_r2:  0.006007152675604255    max(self._all_r2):   0.006007152675604255
2024-03-31 12:27:26.827754: Yayy! New best R2: 0.006
2024-03-31 12:27:32.424598: 
2024-03-31 12:27:32.425701: Epoch 93
2024-03-31 12:27:32.426286: Current learning rate: 1e-05
2024-03-31 12:28:27.727302: meanmse:       0.12539989
2024-03-31 12:28:27.750415: meanr2:        -0.00039889198894368
2024-03-31 12:28:27.751116: train_loss 0.5705
2024-03-31 12:28:27.751651: val_loss 0.5103
2024-03-31 12:28:27.752126: Pseudo dice [0.5]
2024-03-31 12:28:27.752597: Epoch time: 55.37 s
2024-03-31 12:28:32.130917: 
2024-03-31 12:28:32.132013: Epoch 94
2024-03-31 12:28:32.132598: Current learning rate: 1e-05
2024-03-31 12:29:21.051800: meanmse:       0.124649495
2024-03-31 12:29:21.052938: meanr2:        -0.0021232073787395616
2024-03-31 12:29:21.053806: train_loss 0.5106
2024-03-31 12:29:21.054720: val_loss 0.5125
2024-03-31 12:29:21.055295: Pseudo dice [0.5]
2024-03-31 12:29:21.055990: Epoch time: 48.94 s
2024-03-31 12:29:27.641584: 
2024-03-31 12:29:27.658193: Epoch 95
2024-03-31 12:29:27.660097: Current learning rate: 1e-05
2024-03-31 12:30:15.733398: meanmse:       0.124123774
2024-03-31 12:30:15.734754: meanr2:        -0.001318190068633898
2024-03-31 12:30:15.735357: train_loss 0.512
2024-03-31 12:30:15.735807: val_loss 0.5122
2024-03-31 12:30:15.736336: Pseudo dice [0.5]
2024-03-31 12:30:15.736961: Epoch time: 48.1 s
2024-03-31 12:30:20.853863: 
2024-03-31 12:30:20.855627: Epoch 96
2024-03-31 12:30:20.856236: Current learning rate: 1e-05
2024-03-31 12:31:13.828680: meanmse:       0.12676078
2024-03-31 12:31:13.829898: meanr2:        -0.007203001934873554
2024-03-31 12:31:13.830649: train_loss 0.5399
2024-03-31 12:31:13.831247: val_loss 0.5117
2024-03-31 12:31:13.831866: Pseudo dice [0.5]
2024-03-31 12:31:13.832468: Epoch time: 52.99 s
2024-03-31 12:31:19.191021: 
2024-03-31 12:31:19.192389: Epoch 97
2024-03-31 12:31:19.193242: Current learning rate: 0.0
2024-03-31 12:32:07.361479: meanmse:       0.124869294
2024-03-31 12:32:07.370438: meanr2:        -0.0017210753237464225
2024-03-31 12:32:07.372321: train_loss 0.572
2024-03-31 12:32:07.373687: val_loss 0.5103
2024-03-31 12:32:07.382017: Pseudo dice [0.5]
2024-03-31 12:32:07.441252: Epoch time: 48.19 s
2024-03-31 12:32:13.132154: 
2024-03-31 12:32:13.135136: Epoch 98
2024-03-31 12:32:13.135792: Current learning rate: 0.0
2024-03-31 12:33:03.543796: meanmse:       0.1244572
2024-03-31 12:33:03.545918: meanr2:        0.0009960791142891662
2024-03-31 12:33:03.546855: train_loss 0.5702
2024-03-31 12:33:03.547619: val_loss 0.5145
2024-03-31 12:33:03.548189: Pseudo dice [0.5]
2024-03-31 12:33:03.548795: Epoch time: 50.43 s
2024-03-31 12:33:08.225482: 
2024-03-31 12:33:08.226166: Epoch 99
2024-03-31 12:33:08.226695: Current learning rate: 0.0
2024-03-31 12:33:59.276782: meanmse:       0.12563007
2024-03-31 12:33:59.277794: meanr2:        -0.018865929067007608
2024-03-31 12:33:59.281885: train_loss 0.5116
2024-03-31 12:33:59.282667: val_loss 0.5079
2024-03-31 12:33:59.283400: Pseudo dice [0.5]
2024-03-31 12:33:59.284076: Epoch time: 51.06 s
2024-03-31 12:34:03.755324: Training done.
2024-03-31 12:34:03.864931: predicting 1111_0069
Traceback (most recent call last):
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 274, in <module>
    run_training_entry()
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 268, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 171, in run_training
    mp.spawn(run_ddp,
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 134, in run_ddp
    nnunet_trainer.perform_actual_validation(npz)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1360, in perform_actual_validation
TypeError: expected np.ndarray (got str)

