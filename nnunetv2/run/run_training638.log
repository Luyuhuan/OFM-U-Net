nohup: ignoring input
using port 48695
[W socket.cpp:601] [c10d] The client socket has failed to connect to [localhost]:48695 (errno: 101 - Network is unreachable).
I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 0 oversample 0.0
worker 0 batch_size 2

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (mamba_layers): ModuleList(
      (0): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
      (1): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (2-3): 2 x MambaLayer(
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=128, out_features=512, bias=False)
          (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
          (act): SiLU()
          (x_proj): Linear(in_features=256, out_features=40, bias=False)
          (dt_proj): Linear(in_features=8, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=128, bias=False)
        )
      )
      (4): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (5): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (mamba_layers): ModuleList(
        (0): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
        (1): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (2-3): 2 x MambaLayer(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
        )
        (4): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (5): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 192, 192], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7958984971046448, 0.7958984971046448], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset701_AbdomenCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.7958984971046448, 0.7958984971046448], 'original_median_shape_after_transp': [97, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 97.29716491699219, 'median': 118.0, 'min': -1024.0, 'percentile_00_5': -958.0, 'percentile_99_5': 270.0, 'std': 137.8484649658203}}} 

2024-04-05 17:24:20.758054: unpacking dataset...
2024-04-05 17:24:20.758622: unpacking done...
2024-04-05 17:24:20.760014: do_dummy_2d_data_aug: False
2024-04-05 17:24:20.776086: Unable to plot network architecture:
2024-04-05 17:24:20.776527: No module named 'hiddenlayer'
2024-04-05 17:24:20.787702: 
2024-04-05 17:24:20.788343: Epoch 0
2024-04-05 17:24:20.788811: Current learning rate: 0.001
I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 1 oversample 0.6600000000000001
worker 1 batch_size 2

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (mamba_layers): ModuleList(
      (0): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
      (1): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (2-3): 2 x MambaLayer(
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=128, out_features=512, bias=False)
          (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
          (act): SiLU()
          (x_proj): Linear(in_features=256, out_features=40, bias=False)
          (dt_proj): Linear(in_features=8, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=128, bias=False)
        )
      )
      (4): MambaLayer(
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=64, out_features=256, bias=False)
          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
          (act): SiLU()
          (x_proj): Linear(in_features=128, out_features=36, bias=False)
          (dt_proj): Linear(in_features=4, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=64, bias=False)
        )
      )
      (5): MambaLayer(
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mamba): Mamba(
          (in_proj): Linear(in_features=32, out_features=128, bias=False)
          (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
          (act): SiLU()
          (x_proj): Linear(in_features=64, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=64, bias=True)
          (out_proj): Linear(in_features=64, out_features=32, bias=False)
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(5, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (mamba_layers): ModuleList(
        (0): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
        (1): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (2-3): 2 x MambaLayer(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
        )
        (4): MambaLayer(
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=64, out_features=256, bias=False)
            (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
            (act): SiLU()
            (x_proj): Linear(in_features=128, out_features=36, bias=False)
            (dt_proj): Linear(in_features=4, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=64, bias=False)
          )
        )
        (5): MambaLayer(
          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mamba): Mamba(
            (in_proj): Linear(in_features=32, out_features=128, bias=False)
            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)
            (act): SiLU()
            (x_proj): Linear(in_features=64, out_features=34, bias=False)
            (dt_proj): Linear(in_features=2, out_features=64, bias=True)
            (out_proj): Linear(in_features=64, out_features=32, bias=False)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)
do_dummy_2d_data_aug: False

Epoch 0
Current learning rate: 0.001
using pin_memory on device 1
using pin_memory on device 0
using pin_memory on device 1
meanmse:       0.12609136
meanr2:        -0.01588839203838647
train_loss 3.3317
val_loss 2.8277
Pseudo dice [0.5]
Epoch time: 140.18 s
Yayy! New best R2: -0.0159

Epoch 1
Current learning rate: 0.00099
meanmse:       0.124208234
meanr2:        -0.02874870804375925
train_loss 2.7988
val_loss 2.7956
Pseudo dice [0.5]
Epoch time: 78.76 s

Epoch 2
Current learning rate: 0.00098
meanmse:       0.12253057
meanr2:        -0.00044739380541427865
train_loss 2.7934
val_loss 2.7384
Pseudo dice [0.5]
Epoch time: 79.72 s
Yayy! New best R2: -0.0004

Epoch 3
Current learning rate: 0.00097
meanmse:       0.11144173
meanr2:        0.10478051753783019
train_loss 2.7036
val_loss 2.6162
Pseudo dice [0.5]
Epoch time: 78.31 s
Yayy! New best R2: 0.1048

Epoch 4
Current learning rate: 0.00096
meanmse:       0.08248368
meanr2:        0.3174707981546281
train_loss 2.417
val_loss 2.2178
Pseudo dice [0.5]
Epoch time: 80.06 s
Yayy! New best R2: 0.3175

Epoch 5
Current learning rate: 0.00095
meanmse:       0.06658686
meanr2:        0.4496186227995921
train_loss 2.1175
val_loss 1.9156
Pseudo dice [0.5]
Epoch time: 80.44 s
Yayy! New best R2: 0.4496

Epoch 6
Current learning rate: 0.00095
meanmse:       0.05654995
meanr2:        0.5456013827863326
train_loss 1.7583
val_loss 1.6611
Pseudo dice [0.5]
Epoch time: 79.44 s
Yayy! New best R2: 0.5456

Epoch 7
Current learning rate: 0.00094
meanmse:       0.042626318
meanr2:        0.6573039309239126
train_loss 1.4978
val_loss 1.3236
Pseudo dice [0.5]
Epoch time: 78.43 s
Yayy! New best R2: 0.6573

Epoch 8
Current learning rate: 0.00093
meanmse:       0.041875392
meanr2:        0.6588332681583207
train_loss 1.2442
val_loss 1.2056
Pseudo dice [0.5]
Epoch time: 76.01 s
Yayy! New best R2: 0.6588

Epoch 9
Current learning rate: 0.00092
meanmse:       0.032620963
meanr2:        0.7364519615552932
train_loss 1.2459
val_loss 1.1348
Pseudo dice [0.5]
Epoch time: 79.12 s
Yayy! New best R2: 0.7365

Epoch 10
Current learning rate: 0.00091
meanmse:       0.031450436
meanr2:        0.7455363434535449
train_loss 1.1231
val_loss 1.0527
Pseudo dice [0.5]
Epoch time: 75.85 s
Yayy! New best R2: 0.7455

Epoch 11
Current learning rate: 0.0009
meanmse:       0.027284048
meanr2:        0.776482848934723
train_loss 1.0258
val_loss 0.9702
Pseudo dice [0.5]
Epoch time: 77.28 s
Yayy! New best R2: 0.7765

Epoch 12
Current learning rate: 0.00089
meanmse:       0.024264742
meanr2:        0.801674017659025
train_loss 0.9932
val_loss 0.9898
Pseudo dice [0.5]
Epoch time: 82.21 s
Yayy! New best R2: 0.8017

Epoch 13
Current learning rate: 0.00088
meanmse:       0.03142735
meanr2:        0.7512806168042875
train_loss 1.0495
val_loss 0.9998
Pseudo dice [0.5]
Epoch time: 81.85 s

Epoch 14
Current learning rate: 0.00087
meanmse:       0.036740895
meanr2:        0.7020547080971178
train_loss 0.9974
val_loss 1.06
Pseudo dice [0.5]
Epoch time: 80.94 s

Epoch 15
Current learning rate: 0.00086
meanmse:       0.030871302
meanr2:        0.7482268648120076
train_loss 0.9141
val_loss 0.926
Pseudo dice [0.5]
Epoch time: 81.22 s

Epoch 16
Current learning rate: 0.00085
meanmse:       0.027492382
meanr2:        0.7776109490535454
train_loss 0.9103
val_loss 0.9654
Pseudo dice [0.5]
Epoch time: 81.33 s

Epoch 17
Current learning rate: 0.00085
meanmse:       0.025607442
meanr2:        0.7935537152977904
train_loss 0.9031
val_loss 0.87
Pseudo dice [0.5]
Epoch time: 82.77 s

Epoch 18
Current learning rate: 0.00084
meanmse:       0.020148307
meanr2:        0.837516115790029
train_loss 0.8609
val_loss 0.7836
Pseudo dice [0.5]
Epoch time: 81.93 s
Yayy! New best R2: 0.8375

Epoch 19
Current learning rate: 0.00083
meanmse:       0.028366184
meanr2:        0.7705145287964144
train_loss 0.8985
val_loss 0.916
Pseudo dice [0.5]
Epoch time: 83.16 s

Epoch 20
Current learning rate: 0.00082
meanmse:       0.029851587
meanr2:        0.7584853229541193
train_loss 0.8701
val_loss 0.9191
Pseudo dice [0.5]
Epoch time: 85.83 s

Epoch 21
Current learning rate: 0.00081
meanmse:       0.023891456
meanr2:        0.8061294139022327
train_loss 0.8804
val_loss 0.8594
Pseudo dice [0.5]
Epoch time: 83.48 s

Epoch 22
Current learning rate: 0.0008
meanmse:       0.026684428
meanr2:        0.7886403256214738
train_loss 0.8109
val_loss 0.791
Pseudo dice [0.5]
Epoch time: 83.16 s

Epoch 23
Current learning rate: 0.00079
meanmse:       0.017375816
meanr2:        0.8587171708964206
train_loss 0.8237
val_loss 0.7693
Pseudo dice [0.5]
Epoch time: 83.16 s
Yayy! New best R2: 0.8587

Epoch 24
Current learning rate: 0.00078
meanmse:       0.017803421
meanr2:        0.8538374288870272
train_loss 0.7383
val_loss 0.6667
Pseudo dice [0.5]
Epoch time: 82.29 s

Epoch 25
Current learning rate: 0.00077
meanmse:       0.020506017
meanr2:        0.8316763135994744
train_loss 0.7805
val_loss 0.8078
Pseudo dice [0.5]
Epoch time: 82.14 s

Epoch 26
Current learning rate: 0.00076
meanmse:       0.026443642
meanr2:        0.7833438940578881
train_loss 0.7642
val_loss 0.8174
Pseudo dice [0.5]
Epoch time: 81.6 s

Epoch 27
Current learning rate: 0.00075
meanmse:       0.020168817
meanr2:        0.8357152657725024
train_loss 0.7638
val_loss 0.7398
Pseudo dice [0.5]
Epoch time: 80.93 s

Epoch 28
Current learning rate: 0.00074
meanmse:       0.027446045
meanr2:        0.783245502537499
train_loss 0.7079
val_loss 0.8192
Pseudo dice [0.5]
Epoch time: 82.31 s

Epoch 29
Current learning rate: 0.00073
meanmse:       0.025897367
meanr2:        0.7858286853450704
train_loss 0.7374
val_loss 0.7032
Pseudo dice [0.5]
Epoch time: 80.88 s

Epoch 30
Current learning rate: 0.00073
meanmse:       0.028574634
meanr2:        0.7749339108759133
train_loss 0.7521
val_loss 0.821
Pseudo dice [0.5]
Epoch time: 84.0 s

Epoch 31
Current learning rate: 0.00072
meanmse:       0.024736859
meanr2:        0.8036189714900299
train_loss 0.7478
val_loss 0.772
Pseudo dice [0.5]
Epoch time: 79.69 s

Epoch 32
Current learning rate: 0.00071
meanmse:       0.023496263
meanr2:        0.80696244108709
train_loss 0.7418
val_loss 0.7499
Pseudo dice [0.5]
Epoch time: 83.81 s

Epoch 33
Current learning rate: 0.0007
meanmse:       0.023797689
meanr2:        0.8063499527740121
train_loss 0.7264
val_loss 0.7448
Pseudo dice [0.5]
Epoch time: 84.19 s

Epoch 34
Current learning rate: 0.00069
meanmse:       0.021727402
meanr2:        0.827944040524057
train_loss 0.6811
val_loss 0.7127
Pseudo dice [0.5]
Epoch time: 82.09 s

Epoch 35
Current learning rate: 0.00068
meanmse:       0.015550076
meanr2:        0.8756335340774677
train_loss 0.6997
val_loss 0.635
Pseudo dice [0.5]
Epoch time: 84.26 s
Yayy! New best R2: 0.8756

Epoch 36
Current learning rate: 0.00067
meanmse:       0.017263837
meanr2:        0.862672694463742
train_loss 0.6841
val_loss 0.6192
Pseudo dice [0.5]
Epoch time: 85.49 s

Epoch 37
Current learning rate: 0.00066
meanmse:       0.029405586
meanr2:        0.7676841013664994
train_loss 0.6845
val_loss 0.827
Pseudo dice [0.5]
Epoch time: 81.19 s

Epoch 38
Current learning rate: 0.00065
meanmse:       0.019860271
meanr2:        0.8388586834884986
train_loss 0.698
val_loss 0.6871
Pseudo dice [0.5]
Epoch time: 85.94 s

Epoch 39
Current learning rate: 0.00064
meanmse:       0.027951615
meanr2:        0.7750028106088359
train_loss 0.6786
val_loss 0.7327
Pseudo dice [0.5]
Epoch time: 87.73 s

Epoch 40
Current learning rate: 0.00063
meanmse:       0.01731466
meanr2:        0.8573411013776852
train_loss 0.6721
val_loss 0.7719
Pseudo dice [0.5]
Epoch time: 87.93 s

Epoch 41
Current learning rate: 0.00062
meanmse:       0.01993961
meanr2:        0.8380119536449647
train_loss 0.6567
val_loss 0.6891
Pseudo dice [0.5]
Epoch time: 86.47 s

Epoch 42
Current learning rate: 0.00061
meanmse:       0.021440804
meanr2:        0.8294656659855746
train_loss 0.6568
val_loss 0.7312
Pseudo dice [0.5]
Epoch time: 82.02 s

Epoch 43
Current learning rate: 0.0006
meanmse:       0.020298196
meanr2:        0.8357588461086917
train_loss 0.6343
val_loss 0.6437
Pseudo dice [0.5]
Epoch time: 82.11 s

Epoch 44
Current learning rate: 0.00059
meanmse:       0.019539231
meanr2:        0.840508875973203
train_loss 0.6411
val_loss 0.658
Pseudo dice [0.5]
Epoch time: 81.08 s

Epoch 45
Current learning rate: 0.00058
meanmse:       0.021236764
meanr2:        0.8270448624143345
train_loss 0.6217
val_loss 0.6967
Pseudo dice [0.5]
Epoch time: 82.3 s

Epoch 46
Current learning rate: 0.00057
meanmse:       0.01614713
meanr2:        0.8703596999877465
train_loss 0.6482
val_loss 0.6462
Pseudo dice [0.5]
Epoch time: 85.2 s

Epoch 47
Current learning rate: 0.00056
meanmse:       0.021942131
meanr2:        0.8208714178722674
train_loss 0.6544
val_loss 0.7013
Pseudo dice [0.5]
Epoch time: 91.18 s

Epoch 48
Current learning rate: 0.00056
meanmse:       0.020277394
meanr2:        0.8348579117004163
train_loss 0.679
val_loss 0.6089
Pseudo dice [0.5]
Epoch time: 86.27 s

Epoch 49
Current learning rate: 0.00055
meanmse:       0.021037282
meanr2:        0.829084841682775
train_loss 0.6522
val_loss 0.6315
Pseudo dice [0.5]
Epoch time: 80.99 s

Epoch 50
Current learning rate: 0.00054
meanmse:       0.025201617
meanr2:        0.7936805555367162
train_loss 0.5851
val_loss 0.7204
Pseudo dice [0.5]
Epoch time: 81.98 s

Epoch 51
Current learning rate: 0.00053
meanmse:       0.018766912
meanr2:        0.8490159948747379
train_loss 0.5763
val_loss 0.652
Pseudo dice [0.5]
Epoch time: 81.78 s

Epoch 52
Current learning rate: 0.00052
meanmse:       0.017140865
meanr2:        0.8648434790629209
train_loss 0.5702
val_loss 0.6046
Pseudo dice [0.5]
Epoch time: 83.18 s

Epoch 53
Current learning rate: 0.00051
meanmse:       0.022610487
meanr2:        0.8150421392825283
train_loss 0.5966
val_loss 0.7042
Pseudo dice [0.5]
Epoch time: 88.49 s

Epoch 54
Current learning rate: 0.0005
meanmse:       0.017242549
meanr2:        0.8598277788097498
train_loss 0.6094
val_loss 0.6248
Pseudo dice [0.5]
Epoch time: 83.22 s

Epoch 55
Current learning rate: 0.00049
meanmse:       0.019436853
meanr2:        0.8427901245175904
train_loss 0.5726
val_loss 0.6237
Pseudo dice [0.5]
Epoch time: 81.19 s

Epoch 56
Current learning rate: 0.00048
meanmse:       0.023564918
meanr2:        0.8097400108458896
train_loss 0.5856
val_loss 0.6656
Pseudo dice [0.5]
Epoch time: 83.07 s

Epoch 57
Current learning rate: 0.00047
meanmse:       0.019092768
meanr2:        0.8451516380717919
train_loss 0.5661
val_loss 0.6193
Pseudo dice [0.5]
Epoch time: 82.73 s

Epoch 58
Current learning rate: 0.00046
meanmse:       0.01833929
meanr2:        0.8511709977018304
train_loss 0.5547
val_loss 0.6747
Pseudo dice [0.5]
Epoch time: 84.24 s

Epoch 59
Current learning rate: 0.00045
meanmse:       0.02554784
meanr2:        0.7875511362734983
train_loss 0.5815
val_loss 0.7237
Pseudo dice [0.5]
Epoch time: 83.29 s

Epoch 60
Current learning rate: 0.00044
meanmse:       0.016748158
meanr2:        0.8637640749710329
train_loss 0.5758
val_loss 0.6231
Pseudo dice [0.5]
Epoch time: 84.21 s

Epoch 61
Current learning rate: 0.00043
meanmse:       0.020638945
meanr2:        0.8312175926068764
train_loss 0.553
val_loss 0.6621
Pseudo dice [0.5]
Epoch time: 81.46 s

Epoch 62
Current learning rate: 0.00042
meanmse:       0.022742502
meanr2:        0.8161597666573607
train_loss 0.5367
val_loss 0.6605
Pseudo dice [0.5]
Epoch time: 80.63 s

Epoch 63
Current learning rate: 0.00041
meanmse:       0.018896764
meanr2:        0.8457442540720449
train_loss 0.5555
val_loss 0.6911
Pseudo dice [0.5]
Epoch time: 82.06 s

Epoch 64
Current learning rate: 0.0004
meanmse:       0.01956938
meanr2:        0.8447237898296923
train_loss 0.5286
val_loss 0.6536
Pseudo dice [0.5]
Epoch time: 83.45 s

Epoch 65
Current learning rate: 0.00039
meanmse:       0.019017097
meanr2:        0.8443236339410046
train_loss 0.5729
val_loss 0.5885
Pseudo dice [0.5]
Epoch time: 87.31 s

Epoch 66
Current learning rate: 0.00038
meanmse:       0.021025388
meanr2:        0.8287793597422951
train_loss 0.533
val_loss 0.7068
Pseudo dice [0.5]
Epoch time: 82.4 s

Epoch 67
Current learning rate: 0.00037
meanmse:       0.017887466
meanr2:        0.8544104952765085
train_loss 0.5576
val_loss 0.6574
Pseudo dice [0.5]
Epoch time: 83.51 s

Epoch 68
Current learning rate: 0.00036
meanmse:       0.020719357
meanr2:        0.832661664951629
train_loss 0.5178
val_loss 0.6422
Pseudo dice [0.5]
Epoch time: 82.05 s

Epoch 69
Current learning rate: 0.00035
meanmse:       0.019238042
meanr2:        0.844623550298919
train_loss 0.5468
val_loss 0.6249
Pseudo dice [0.5]
Epoch time: 82.47 s

Epoch 70
Current learning rate: 0.00034
meanmse:       0.024979437
meanr2:        0.8007469353830288
train_loss 0.5298
val_loss 0.6977
Pseudo dice [0.5]
Epoch time: 83.5 s

Epoch 71
Current learning rate: 0.00033
meanmse:       0.016065704
meanr2:        0.8655146791791797
train_loss 0.5361
val_loss 0.574
Pseudo dice [0.5]
Epoch time: 84.46 s

Epoch 72
Current learning rate: 0.00032
meanmse:       0.017219404
meanr2:        0.860407066764783
train_loss 0.5475
val_loss 0.6076
Pseudo dice [0.5]
Epoch time: 84.77 s

Epoch 73
Current learning rate: 0.00031
meanmse:       0.020764781
meanr2:        0.8323016189875246
train_loss 0.5197
val_loss 0.5916
Pseudo dice [0.5]
Epoch time: 82.63 s

Epoch 74
Current learning rate: 0.0003
meanmse:       0.016617373
meanr2:        0.8640927604321043
train_loss 0.5088
val_loss 0.6374
Pseudo dice [0.5]
Epoch time: 82.75 s

Epoch 75
Current learning rate: 0.00029
meanmse:       0.026684213
meanr2:        0.7941352206452786
train_loss 0.5086
val_loss 0.7436
Pseudo dice [0.5]
Epoch time: 82.73 s

Epoch 76
Current learning rate: 0.00028
meanmse:       0.027054286
meanr2:        0.7832313498420679
train_loss 0.5107
val_loss 0.7299
Pseudo dice [0.5]
Epoch time: 82.87 s

Epoch 77
Current learning rate: 0.00027
meanmse:       0.02223002
meanr2:        0.8221574787456476
train_loss 0.4954
val_loss 0.6513
Pseudo dice [0.5]
Epoch time: 88.59 s

Epoch 78
Current learning rate: 0.00026
meanmse:       0.015317548
meanr2:        0.8768797054002935
train_loss 0.5156
val_loss 0.5751
Pseudo dice [0.5]
Epoch time: 86.63 s
Yayy! New best R2: 0.8769

Epoch 79
Current learning rate: 0.00025
meanmse:       0.016596416
meanr2:        0.8652236315859867
train_loss 0.5086
val_loss 0.6254
Pseudo dice [0.5]
Epoch time: 82.89 s

Epoch 80
Current learning rate: 0.00023
meanmse:       0.018733187
meanr2:        0.8482711738397971
train_loss 0.4828
val_loss 0.5934
Pseudo dice [0.5]
Epoch time: 83.14 s

Epoch 81
Current learning rate: 0.00022
meanmse:       0.02286154
meanr2:        0.8155061411785419
train_loss 0.5238
val_loss 0.6545
Pseudo dice [0.5]
Epoch time: 82.07 s

Epoch 82
Current learning rate: 0.00021
meanmse:       0.016178282
meanr2:        0.8673369477718136
train_loss 0.4862
val_loss 0.6025
Pseudo dice [0.5]
Epoch time: 84.66 s

Epoch 83
Current learning rate: 0.0002
meanmse:       0.021234943
meanr2:        0.8274670650426604
train_loss 0.4868
val_loss 0.672
Pseudo dice [0.5]
Epoch time: 82.2 s

Epoch 84
Current learning rate: 0.00019
meanmse:       0.017121535
meanr2:        0.8625946012664685
train_loss 0.4911
val_loss 0.581
Pseudo dice [0.5]
Epoch time: 84.45 s

Epoch 85
Current learning rate: 0.00018
meanmse:       0.017886763
meanr2:        0.8523641247069513
train_loss 0.504
val_loss 0.6205
Pseudo dice [0.5]
Epoch time: 83.27 s

Epoch 86
Current learning rate: 0.00017
meanmse:       0.018323334
meanr2:        0.8505749373431001
train_loss 0.5048
val_loss 0.5941
Pseudo dice [0.5]
Epoch time: 82.49 s

Epoch 87
Current learning rate: 0.00016
meanmse:       0.022918845
meanr2:        0.8168988500410888
train_loss 0.4908
val_loss 0.6622
Pseudo dice [0.5]
Epoch time: 83.49 s

Epoch 88
Current learning rate: 0.00015
meanmse:       0.01789763
meanr2:        0.8531564408658572
train_loss 0.4641
val_loss 0.596
Pseudo dice [0.5]
Epoch time: 82.73 s

Epoch 89
Current learning rate: 0.00014
meanmse:       0.01957447
meanr2:        0.8404833572282494
train_loss 0.4527
val_loss 0.6248
Pseudo dice [0.5]
Epoch time: 80.99 s

Epoch 90
Current learning rate: 0.00013
meanmse:       0.018637123
meanr2:        0.8463488175616525
train_loss 0.4554
val_loss 0.6093
Pseudo dice [0.5]
Epoch time: 82.3 s

Epoch 91
Current learning rate: 0.00011
meanmse:       0.021621738
meanr2:        0.8269797467156749
train_loss 0.4388
val_loss 0.6056
Pseudo dice [0.5]
Epoch time: 84.26 s

Epoch 92
Current learning rate: 0.0001
meanmse:       0.01650864
meanr2:        0.8673098281195795
train_loss 0.4766
val_loss 0.6253
Pseudo dice [0.5]
Epoch time: 82.65 s

Epoch 93
Current learning rate: 9e-05
meanmse:       0.022628576
meanr2:        0.8192708200328105
train_loss 0.436
val_loss 0.6325
Pseudo dice [0.5]
Epoch time: 81.96 s

Epoch 94
Current learning rate: 8e-05
meanmse:       0.016572895
meanr2:        0.8653828328146097
train_loss 0.459
val_loss 0.6214
Pseudo dice [0.5]
Epoch time: 82.61 s

Epoch 95
Current learning rate: 7e-05
meanmse:       0.022520522
meanr2:        0.8205673061881232
train_loss 0.4428
val_loss 0.6895
Pseudo dice [0.5]
Epoch time: 83.41 s

Epoch 96
Current learning rate: 6e-05
meanmse:       0.024873318
meanr2:        0.8049660610351164
train_loss 0.4503
val_loss 0.5894
Pseudo dice [0.5]
Epoch time: 81.81 s

Epoch 97
Current learning rate: 4e-05
meanmse:       0.018560005
meanr2:        0.8494644895766856
train_loss 0.43
val_loss 0.6039
Pseudo dice [0.5]
Epoch time: 83.48 s

Epoch 98
Current learning rate: 3e-05
meanmse:       0.022300746
meanr2:        0.8216895062833238
train_loss 0.4405
val_loss 0.6388
Pseudo dice [0.5]
Epoch time: 83.26 s

Epoch 99
Current learning rate: 2e-05
meanmse:       0.017576324
meanr2:        0.8577455503142141
train_loss 0.4265
val_loss 0.5764
Pseudo dice [0.5]
Epoch time: 82.03 s
Training done.
predicting 20190412_103119_129
using pin_memory on device 0
2024-04-05 17:26:40.986306: meanmse:       0.1281541
2024-04-05 17:26:40.987635: meanr2:        -0.03711293188629138
2024-04-05 17:26:40.988350: train_loss 3.3317
2024-04-05 17:26:40.988880: val_loss 2.8277
2024-04-05 17:26:40.989377: Pseudo dice [0.5]
2024-04-05 17:26:40.989891: Epoch time: 140.21 s
2024-04-05 17:26:40.990377: Yayy! New best R2: -0.0371
2024-04-05 17:26:43.555066: 
2024-04-05 17:26:43.556114: Epoch 1
2024-04-05 17:26:43.556742: Current learning rate: 0.00099
2024-04-05 17:27:59.748555: meanmse:       0.1271531
2024-04-05 17:27:59.750168: meanr2:        -0.010864790500000034
2024-04-05 17:27:59.750830: train_loss 2.7988
2024-04-05 17:27:59.751285: val_loss 2.7956
2024-04-05 17:27:59.751802: Pseudo dice [0.5]
2024-04-05 17:27:59.752277: Epoch time: 76.2 s
2024-04-05 17:27:59.752748: Yayy! New best R2: -0.0109
2024-04-05 17:28:04.533394: 
2024-04-05 17:28:04.534223: Epoch 2
2024-04-05 17:28:04.534707: Current learning rate: 0.00098
2024-04-05 17:29:19.471937: meanmse:       0.12377646
2024-04-05 17:29:19.472997: meanr2:        -0.005682688002795947
2024-04-05 17:29:19.473415: train_loss 2.7934
2024-04-05 17:29:19.473732: val_loss 2.7384
2024-04-05 17:29:19.474036: Pseudo dice [0.5]
2024-04-05 17:29:19.474512: Epoch time: 74.95 s
2024-04-05 17:29:19.474962: Yayy! New best R2: -0.0057
2024-04-05 17:29:22.606449: 
2024-04-05 17:29:22.607268: Epoch 3
2024-04-05 17:29:22.607798: Current learning rate: 0.00097
2024-04-05 17:30:37.782379: meanmse:       0.10717538
2024-04-05 17:30:37.783598: meanr2:        0.14257541447790165
2024-04-05 17:30:37.784124: train_loss 2.7036
2024-04-05 17:30:37.784538: val_loss 2.6162
2024-04-05 17:30:37.784929: Pseudo dice [0.5]
2024-04-05 17:30:37.785340: Epoch time: 75.18 s
2024-04-05 17:30:37.785706: Yayy! New best R2: 0.1426
2024-04-05 17:30:40.530992: 
2024-04-05 17:30:40.531855: Epoch 4
2024-04-05 17:30:40.532618: Current learning rate: 0.00096
2024-04-05 17:31:57.844624: meanmse:       0.07949167
2024-04-05 17:31:57.846212: meanr2:        0.34550034685827974
2024-04-05 17:31:57.847129: train_loss 2.417
2024-04-05 17:31:57.848284: val_loss 2.2178
2024-04-05 17:31:57.849199: Pseudo dice [0.5]
2024-04-05 17:31:57.850386: Epoch time: 77.32 s
2024-04-05 17:31:57.851115: Yayy! New best R2: 0.3455
2024-04-05 17:32:02.371985: 
2024-04-05 17:32:02.372830: Epoch 5
2024-04-05 17:32:02.373347: Current learning rate: 0.00095
2024-04-05 17:33:18.299427: meanmse:       0.061329126
2024-04-05 17:33:18.300951: meanr2:        0.49908991026159005
2024-04-05 17:33:18.301755: train_loss 2.1175
2024-04-05 17:33:18.302302: val_loss 1.9156
2024-04-05 17:33:18.302826: Pseudo dice [0.5]
2024-04-05 17:33:18.303362: Epoch time: 75.94 s
2024-04-05 17:33:18.303878: Yayy! New best R2: 0.4991
2024-04-05 17:33:21.424261: 
2024-04-05 17:33:21.425099: Epoch 6
2024-04-05 17:33:21.425568: Current learning rate: 0.00095
2024-04-05 17:34:37.730247: meanmse:       0.05309174
2024-04-05 17:34:37.742807: meanr2:        0.5695911940638466
2024-04-05 17:34:37.744838: train_loss 1.7583
2024-04-05 17:34:37.745713: val_loss 1.6611
2024-04-05 17:34:37.747587: Pseudo dice [0.5]
2024-04-05 17:34:37.749428: Epoch time: 76.33 s
2024-04-05 17:34:37.751540: Yayy! New best R2: 0.5696
2024-04-05 17:34:41.196839: 
2024-04-05 17:34:41.197833: Epoch 7
2024-04-05 17:34:41.198428: Current learning rate: 0.00094
2024-04-05 17:35:56.157067: meanmse:       0.04005877
2024-04-05 17:35:56.158067: meanr2:        0.6680027945775028
2024-04-05 17:35:56.158715: train_loss 1.4978
2024-04-05 17:35:56.159114: val_loss 1.3236
2024-04-05 17:35:56.159500: Pseudo dice [0.5]
2024-04-05 17:35:56.159891: Epoch time: 74.97 s
2024-04-05 17:35:56.160274: Yayy! New best R2: 0.668
2024-04-05 17:35:58.981847: 
2024-04-05 17:35:58.982708: Epoch 8
2024-04-05 17:35:58.983202: Current learning rate: 0.00093
2024-04-05 17:37:12.168078: meanmse:       0.03482236
2024-04-05 17:37:12.169209: meanr2:        0.7124924105431263
2024-04-05 17:37:12.169771: train_loss 1.2442
2024-04-05 17:37:12.170212: val_loss 1.2056
2024-04-05 17:37:12.170626: Pseudo dice [0.5]
2024-04-05 17:37:12.171047: Epoch time: 73.2 s
2024-04-05 17:37:12.171472: Yayy! New best R2: 0.7125
2024-04-05 17:37:15.268761: 
2024-04-05 17:37:15.335340: Epoch 9
2024-04-05 17:37:15.336012: Current learning rate: 0.00092
2024-04-05 17:38:31.290252: meanmse:       0.035896942
2024-04-05 17:38:31.291482: meanr2:        0.7059668655408743
2024-04-05 17:38:31.292062: train_loss 1.2459
2024-04-05 17:38:31.292550: val_loss 1.1348
2024-04-05 17:38:31.293029: Pseudo dice [0.5]
2024-04-05 17:38:31.293504: Epoch time: 76.03 s
2024-04-05 17:38:34.079798: 
2024-04-05 17:38:34.080598: Epoch 10
2024-04-05 17:38:34.081157: Current learning rate: 0.00091
2024-04-05 17:39:47.143789: meanmse:       0.033722892
2024-04-05 17:39:47.144923: meanr2:        0.7342308041765737
2024-04-05 17:39:47.145473: train_loss 1.1231
2024-04-05 17:39:47.145927: val_loss 1.0527
2024-04-05 17:39:47.146362: Pseudo dice [0.5]
2024-04-05 17:39:47.146803: Epoch time: 73.07 s
2024-04-05 17:39:47.147245: Yayy! New best R2: 0.7342
2024-04-05 17:39:51.164440: 
2024-04-05 17:39:51.165168: Epoch 11
2024-04-05 17:39:51.165690: Current learning rate: 0.0009
2024-04-05 17:41:04.423571: meanmse:       0.032540258
2024-04-05 17:41:04.424823: meanr2:        0.7379354126134778
2024-04-05 17:41:04.425534: train_loss 1.0258
2024-04-05 17:41:04.426060: val_loss 0.9702
2024-04-05 17:41:04.426555: Pseudo dice [0.5]
2024-04-05 17:41:04.427030: Epoch time: 73.27 s
2024-04-05 17:41:04.427488: Yayy! New best R2: 0.7379
2024-04-05 17:41:07.977413: 
2024-04-05 17:41:07.978678: Epoch 12
2024-04-05 17:41:07.979648: Current learning rate: 0.00089
2024-04-05 17:42:26.636508: meanmse:       0.038769055
2024-04-05 17:42:26.637795: meanr2:        0.6857113444423196
2024-04-05 17:42:26.638462: train_loss 0.9932
2024-04-05 17:42:26.638931: val_loss 0.9898
2024-04-05 17:42:26.639460: Pseudo dice [0.5]
2024-04-05 17:42:26.639953: Epoch time: 78.67 s
2024-04-05 17:42:28.880541: 
2024-04-05 17:42:28.881399: Epoch 13
2024-04-05 17:42:28.881994: Current learning rate: 0.00088
2024-04-05 17:43:48.482930: meanmse:       0.030998195
2024-04-05 17:43:48.484059: meanr2:        0.7503784914457597
2024-04-05 17:43:48.484683: train_loss 1.0495
2024-04-05 17:43:48.485177: val_loss 0.9998
2024-04-05 17:43:48.485609: Pseudo dice [0.5]
2024-04-05 17:43:48.486047: Epoch time: 79.62 s
2024-04-05 17:43:48.486460: Yayy! New best R2: 0.7504
2024-04-05 17:43:51.081681: 
2024-04-05 17:43:51.082394: Epoch 14
2024-04-05 17:43:51.082835: Current learning rate: 0.00087
2024-04-05 17:45:09.425903: meanmse:       0.03137586
2024-04-05 17:45:09.427172: meanr2:        0.7510382246577266
2024-04-05 17:45:09.427870: train_loss 0.9974
2024-04-05 17:45:09.428444: val_loss 1.06
2024-04-05 17:45:09.429024: Pseudo dice [0.5]
2024-04-05 17:45:09.429663: Epoch time: 78.35 s
2024-04-05 17:45:09.430304: Yayy! New best R2: 0.751
2024-04-05 17:45:12.255676: 
2024-04-05 17:45:12.256515: Epoch 15
2024-04-05 17:45:12.257131: Current learning rate: 0.00086
2024-04-05 17:46:30.649020: meanmse:       0.028762601
2024-04-05 17:46:30.650096: meanr2:        0.7632520541328016
2024-04-05 17:46:30.650576: train_loss 0.9141
2024-04-05 17:46:30.650935: val_loss 0.926
2024-04-05 17:46:30.651261: Pseudo dice [0.5]
2024-04-05 17:46:30.651582: Epoch time: 78.4 s
2024-04-05 17:46:30.651895: Yayy! New best R2: 0.7633
2024-04-05 17:46:33.747848: 
2024-04-05 17:46:33.748951: Epoch 16
2024-04-05 17:46:33.749848: Current learning rate: 0.00085
2024-04-05 17:47:51.981149: meanmse:       0.034956533
2024-04-05 17:47:51.982648: meanr2:        0.7193426214160692
2024-04-05 17:47:51.983454: train_loss 0.9103
2024-04-05 17:47:51.984054: val_loss 0.9654
2024-04-05 17:47:51.984652: Pseudo dice [0.5]
2024-04-05 17:47:51.985276: Epoch time: 78.24 s
2024-04-05 17:47:54.919443: 
2024-04-05 17:47:54.920152: Epoch 17
2024-04-05 17:47:54.920671: Current learning rate: 0.00085
2024-04-05 17:49:14.753914: meanmse:       0.025704952
2024-04-05 17:49:14.828067: meanr2:        0.7882595148386162
2024-04-05 17:49:14.877605: train_loss 0.9031
2024-04-05 17:49:14.880517: val_loss 0.87
2024-04-05 17:49:14.899928: Pseudo dice [0.5]
2024-04-05 17:49:14.900597: Epoch time: 79.99 s
2024-04-05 17:49:14.901081: Yayy! New best R2: 0.7883
2024-04-05 17:49:17.547503: 
2024-04-05 17:49:17.548745: Epoch 18
2024-04-05 17:49:17.549348: Current learning rate: 0.00084
2024-04-05 17:50:36.683824: meanmse:       0.025337232
2024-04-05 17:50:36.684967: meanr2:        0.7966559191086421
2024-04-05 17:50:36.697462: train_loss 0.8609
2024-04-05 17:50:36.697967: val_loss 0.7836
2024-04-05 17:50:36.698396: Pseudo dice [0.5]
2024-04-05 17:50:36.698914: Epoch time: 79.16 s
2024-04-05 17:50:36.699396: Yayy! New best R2: 0.7967
2024-04-05 17:50:40.781181: 
2024-04-05 17:50:40.781857: Epoch 19
2024-04-05 17:50:40.782274: Current learning rate: 0.00083
2024-04-05 17:51:59.847942: meanmse:       0.03096456
2024-04-05 17:51:59.849120: meanr2:        0.7497110180648391
2024-04-05 17:51:59.849660: train_loss 0.8985
2024-04-05 17:51:59.850125: val_loss 0.916
2024-04-05 17:51:59.850536: Pseudo dice [0.5]
2024-04-05 17:51:59.851059: Epoch time: 79.08 s
2024-04-05 17:52:03.410739: 
2024-04-05 17:52:03.413536: Epoch 20
2024-04-05 17:52:03.414109: Current learning rate: 0.00082
2024-04-05 17:53:25.683199: meanmse:       0.028552074
2024-04-05 17:53:25.686706: meanr2:        0.7625520442449836
2024-04-05 17:53:25.687607: train_loss 0.8701
2024-04-05 17:53:25.688565: val_loss 0.9191
2024-04-05 17:53:25.689498: Pseudo dice [0.5]
2024-04-05 17:53:25.690566: Epoch time: 82.28 s
2024-04-05 17:53:27.921913: 
2024-04-05 17:53:27.922655: Epoch 21
2024-04-05 17:53:27.923123: Current learning rate: 0.00081
2024-04-05 17:54:49.164475: meanmse:       0.028842099
2024-04-05 17:54:49.165615: meanr2:        0.7701081601888785
2024-04-05 17:54:49.166315: train_loss 0.8804
2024-04-05 17:54:49.166843: val_loss 0.8594
2024-04-05 17:54:49.167309: Pseudo dice [0.5]
2024-04-05 17:54:49.167785: Epoch time: 81.25 s
2024-04-05 17:54:51.685497: 
2024-04-05 17:54:51.691126: Epoch 22
2024-04-05 17:54:51.691710: Current learning rate: 0.0008
2024-04-05 17:56:12.327112: meanmse:       0.019738937
2024-04-05 17:56:12.327954: meanr2:        0.8420012175439294
2024-04-05 17:56:12.328544: train_loss 0.8109
2024-04-05 17:56:12.328865: val_loss 0.791
2024-04-05 17:56:12.329185: Pseudo dice [0.5]
2024-04-05 17:56:12.329506: Epoch time: 80.65 s
2024-04-05 17:56:12.329825: Yayy! New best R2: 0.842
2024-04-05 17:56:15.151319: 
2024-04-05 17:56:15.167942: Epoch 23
2024-04-05 17:56:15.168652: Current learning rate: 0.00079
2024-04-05 17:57:35.492237: meanmse:       0.028978823
2024-04-05 17:57:35.493374: meanr2:        0.7694516690187108
2024-04-05 17:57:35.493889: train_loss 0.8237
2024-04-05 17:57:35.494326: val_loss 0.7693
2024-04-05 17:57:35.494747: Pseudo dice [0.5]
2024-04-05 17:57:35.495172: Epoch time: 80.35 s
2024-04-05 17:57:38.052498: 
2024-04-05 17:57:38.053298: Epoch 24
2024-04-05 17:57:38.053800: Current learning rate: 0.00078
2024-04-05 17:58:57.783128: meanmse:       0.018581195
2024-04-05 17:58:57.784628: meanr2:        0.849898567094607
2024-04-05 17:58:57.785185: train_loss 0.7383
2024-04-05 17:58:57.785666: val_loss 0.6667
2024-04-05 17:58:57.786146: Pseudo dice [0.5]
2024-04-05 17:58:57.786627: Epoch time: 79.74 s
2024-04-05 17:58:57.787063: Yayy! New best R2: 0.8499
2024-04-05 17:59:00.743005: 
2024-04-05 17:59:00.743970: Epoch 25
2024-04-05 17:59:00.744493: Current learning rate: 0.00077
2024-04-05 18:00:19.923100: meanmse:       0.029827805
2024-04-05 18:00:19.923964: meanr2:        0.7592773054618945
2024-04-05 18:00:19.924413: train_loss 0.7805
2024-04-05 18:00:19.924916: val_loss 0.8078
2024-04-05 18:00:19.925392: Pseudo dice [0.5]
2024-04-05 18:00:19.925848: Epoch time: 79.19 s
2024-04-05 18:00:22.293261: 
2024-04-05 18:00:22.294078: Epoch 26
2024-04-05 18:00:22.294562: Current learning rate: 0.00076
2024-04-05 18:01:41.519610: meanmse:       0.026075799
2024-04-05 18:01:41.533338: meanr2:        0.7890158630747023
2024-04-05 18:01:41.534245: train_loss 0.7642
2024-04-05 18:01:41.534680: val_loss 0.8174
2024-04-05 18:01:41.535106: Pseudo dice [0.5]
2024-04-05 18:01:41.535543: Epoch time: 79.25 s
2024-04-05 18:01:43.869347: 
2024-04-05 18:01:43.869956: Epoch 27
2024-04-05 18:01:43.870419: Current learning rate: 0.00075
2024-04-05 18:03:02.447724: meanmse:       0.025354521
2024-04-05 18:03:02.448885: meanr2:        0.7920461344448939
2024-04-05 18:03:02.449467: train_loss 0.7638
2024-04-05 18:03:02.449883: val_loss 0.7398
2024-04-05 18:03:02.450334: Pseudo dice [0.5]
2024-04-05 18:03:02.450765: Epoch time: 78.59 s
2024-04-05 18:03:04.952378: 
2024-04-05 18:03:04.953041: Epoch 28
2024-04-05 18:03:04.953493: Current learning rate: 0.00074
2024-04-05 18:04:24.757305: meanmse:       0.028459303
2024-04-05 18:04:24.759481: meanr2:        0.7699338322113327
2024-04-05 18:04:24.762030: train_loss 0.7079
2024-04-05 18:04:24.762882: val_loss 0.8192
2024-04-05 18:04:24.763631: Pseudo dice [0.5]
2024-04-05 18:04:24.764376: Epoch time: 79.82 s
2024-04-05 18:04:27.720791: 
2024-04-05 18:04:27.721613: Epoch 29
2024-04-05 18:04:27.722124: Current learning rate: 0.00073
2024-04-05 18:05:45.639427: meanmse:       0.0149541525
2024-04-05 18:05:45.640840: meanr2:        0.8786403801018383
2024-04-05 18:05:45.641580: train_loss 0.7374
2024-04-05 18:05:45.642302: val_loss 0.7032
2024-04-05 18:05:45.642832: Pseudo dice [0.5]
2024-04-05 18:05:45.643336: Epoch time: 77.95 s
2024-04-05 18:05:46.642684: Yayy! New best R2: 0.8786
2024-04-05 18:05:50.533496: 
2024-04-05 18:05:50.550689: Epoch 30
2024-04-05 18:05:50.552135: Current learning rate: 0.00073
2024-04-05 18:07:09.639442: meanmse:       0.024397753
2024-04-05 18:07:09.640964: meanr2:        0.8008362794498164
2024-04-05 18:07:09.641724: train_loss 0.7521
2024-04-05 18:07:09.642341: val_loss 0.821
2024-04-05 18:07:09.642862: Pseudo dice [0.5]
2024-04-05 18:07:09.643408: Epoch time: 79.12 s
2024-04-05 18:07:12.080932: 
2024-04-05 18:07:12.081711: Epoch 31
2024-04-05 18:07:12.082115: Current learning rate: 0.00072
2024-04-05 18:08:29.333796: meanmse:       0.020880058
2024-04-05 18:08:29.335138: meanr2:        0.8321696138212483
2024-04-05 18:08:29.335829: train_loss 0.7478
2024-04-05 18:08:29.336378: val_loss 0.772
2024-04-05 18:08:29.336857: Pseudo dice [0.5]
2024-04-05 18:08:29.337368: Epoch time: 77.26 s
2024-04-05 18:08:33.268492: 
2024-04-05 18:08:33.269681: Epoch 32
2024-04-05 18:08:33.270379: Current learning rate: 0.00071
2024-04-05 18:09:53.147372: meanmse:       0.02322387
2024-04-05 18:09:53.156465: meanr2:        0.8140126976695048
2024-04-05 18:09:53.159501: train_loss 0.7418
2024-04-05 18:09:53.159942: val_loss 0.7499
2024-04-05 18:09:53.160386: Pseudo dice [0.5]
2024-04-05 18:09:53.160787: Epoch time: 79.9 s
2024-04-05 18:09:56.342640: 
2024-04-05 18:09:56.352435: Epoch 33
2024-04-05 18:09:56.353404: Current learning rate: 0.0007
2024-04-05 18:11:17.335284: meanmse:       0.021564586
2024-04-05 18:11:17.336812: meanr2:        0.8222015537940618
2024-04-05 18:11:17.337439: train_loss 0.7264
2024-04-05 18:11:17.337967: val_loss 0.7448
2024-04-05 18:11:17.338418: Pseudo dice [0.5]
2024-04-05 18:11:17.338869: Epoch time: 81.0 s
2024-04-05 18:11:19.810156: 
2024-04-05 18:11:19.810811: Epoch 34
2024-04-05 18:11:19.811232: Current learning rate: 0.00069
2024-04-05 18:12:39.426911: meanmse:       0.020589594
2024-04-05 18:12:39.428147: meanr2:        0.8374270279798346
2024-04-05 18:12:39.428810: train_loss 0.6811
2024-04-05 18:12:39.443200: val_loss 0.7127
2024-04-05 18:12:39.443902: Pseudo dice [0.5]
2024-04-05 18:12:39.444426: Epoch time: 79.63 s
2024-04-05 18:12:41.879015: 
2024-04-05 18:12:41.880204: Epoch 35
2024-04-05 18:12:41.880968: Current learning rate: 0.00068
2024-04-05 18:14:03.684947: meanmse:       0.019403843
2024-04-05 18:14:03.685910: meanr2:        0.8427657881959452
2024-04-05 18:14:03.686382: train_loss 0.6997
2024-04-05 18:14:03.686710: val_loss 0.635
2024-04-05 18:14:03.687030: Pseudo dice [0.5]
2024-04-05 18:14:03.687393: Epoch time: 81.82 s
2024-04-05 18:14:06.089611: 
2024-04-05 18:14:06.090421: Epoch 36
2024-04-05 18:14:06.090974: Current learning rate: 0.00067
2024-04-05 18:15:29.175334: meanmse:       0.017380567
2024-04-05 18:15:29.186336: meanr2:        0.8581220914229095
2024-04-05 18:15:29.187212: train_loss 0.6841
2024-04-05 18:15:29.187708: val_loss 0.6192
2024-04-05 18:15:29.188141: Pseudo dice [0.5]
2024-04-05 18:15:29.188730: Epoch time: 83.11 s
2024-04-05 18:15:31.774634: 
2024-04-05 18:15:31.775559: Epoch 37
2024-04-05 18:15:31.776634: Current learning rate: 0.00066
2024-04-05 18:16:50.370672: meanmse:       0.026343422
2024-04-05 18:16:50.372266: meanr2:        0.7895084912477834
2024-04-05 18:16:50.372989: train_loss 0.6845
2024-04-05 18:16:50.373521: val_loss 0.827
2024-04-05 18:16:50.374086: Pseudo dice [0.5]
2024-04-05 18:16:50.374652: Epoch time: 78.61 s
2024-04-05 18:16:54.755904: 
2024-04-05 18:16:54.756635: Epoch 38
2024-04-05 18:16:54.757085: Current learning rate: 0.00065
2024-04-05 18:18:16.307437: meanmse:       0.021751577
2024-04-05 18:18:16.308734: meanr2:        0.8238274796818217
2024-04-05 18:18:16.309330: train_loss 0.698
2024-04-05 18:18:16.309793: val_loss 0.6871
2024-04-05 18:18:16.310272: Pseudo dice [0.5]
2024-04-05 18:18:16.310716: Epoch time: 81.56 s
2024-04-05 18:18:19.188403: 
2024-04-05 18:18:19.189317: Epoch 39
2024-04-05 18:18:19.189885: Current learning rate: 0.00064
2024-04-05 18:19:44.037475: meanmse:       0.01940193
2024-04-05 18:19:44.038728: meanr2:        0.8430620139621342
2024-04-05 18:19:44.039330: train_loss 0.6786
2024-04-05 18:19:44.039800: val_loss 0.7327
2024-04-05 18:19:44.040315: Pseudo dice [0.5]
2024-04-05 18:19:44.040814: Epoch time: 84.86 s
2024-04-05 18:19:46.726787: 
2024-04-05 18:19:46.727606: Epoch 40
2024-04-05 18:19:46.728091: Current learning rate: 0.00063
2024-04-05 18:21:11.965757: meanmse:       0.033842493
2024-04-05 18:21:11.966777: meanr2:        0.7305514787632984
2024-04-05 18:21:11.967246: train_loss 0.6721
2024-04-05 18:21:11.967608: val_loss 0.7719
2024-04-05 18:21:11.967968: Pseudo dice [0.5]
2024-04-05 18:21:11.968408: Epoch time: 85.25 s
2024-04-05 18:21:14.451783: 
2024-04-05 18:21:14.452624: Epoch 41
2024-04-05 18:21:14.453176: Current learning rate: 0.00062
2024-04-05 18:22:38.435239: meanmse:       0.02379372
2024-04-05 18:22:38.436327: meanr2:        0.805961006596483
2024-04-05 18:22:38.436906: train_loss 0.6567
2024-04-05 18:22:38.437373: val_loss 0.6891
2024-04-05 18:22:38.438112: Pseudo dice [0.5]
2024-04-05 18:22:38.438572: Epoch time: 84.0 s
2024-04-05 18:22:40.689279: 
2024-04-05 18:22:40.690357: Epoch 42
2024-04-05 18:22:40.690878: Current learning rate: 0.00061
2024-04-05 18:24:00.459610: meanmse:       0.025275873
2024-04-05 18:24:00.460887: meanr2:        0.7934288395766075
2024-04-05 18:24:00.461497: train_loss 0.6568
2024-04-05 18:24:00.465128: val_loss 0.7312
2024-04-05 18:24:00.522693: Pseudo dice [0.5]
2024-04-05 18:24:00.523129: Epoch time: 79.78 s
2024-04-05 18:24:02.781848: 
2024-04-05 18:24:02.782446: Epoch 43
2024-04-05 18:24:02.782846: Current learning rate: 0.0006
2024-04-05 18:25:22.565991: meanmse:       0.019201064
2024-04-05 18:25:22.567094: meanr2:        0.8447746777115218
2024-04-05 18:25:22.567660: train_loss 0.6343
2024-04-05 18:25:22.568217: val_loss 0.6437
2024-04-05 18:25:22.568743: Pseudo dice [0.5]
2024-04-05 18:25:22.569265: Epoch time: 79.79 s
2024-04-05 18:25:24.926574: 
2024-04-05 18:25:24.927312: Epoch 44
2024-04-05 18:25:24.927825: Current learning rate: 0.00059
2024-04-05 18:26:43.644715: meanmse:       0.017622419
2024-04-05 18:26:43.645751: meanr2:        0.8557533306261033
2024-04-05 18:26:43.646287: train_loss 0.6411
2024-04-05 18:26:43.646674: val_loss 0.658
2024-04-05 18:26:43.647029: Pseudo dice [0.5]
2024-04-05 18:26:43.647430: Epoch time: 78.73 s
2024-04-05 18:26:48.084930: 
2024-04-05 18:26:48.086300: Epoch 45
2024-04-05 18:26:48.087301: Current learning rate: 0.00058
2024-04-05 18:28:05.947954: meanmse:       0.020234702
2024-04-05 18:28:05.949193: meanr2:        0.8356440231381523
2024-04-05 18:28:05.949810: train_loss 0.6217
2024-04-05 18:28:05.950249: val_loss 0.6967
2024-04-05 18:28:05.950673: Pseudo dice [0.5]
2024-04-05 18:28:05.951134: Epoch time: 77.88 s
2024-04-05 18:28:09.955500: 
2024-04-05 18:28:09.956443: Epoch 46
2024-04-05 18:28:09.957083: Current learning rate: 0.00057
2024-04-05 18:29:31.151739: meanmse:       0.02125571
2024-04-05 18:29:31.152963: meanr2:        0.8283020342241122
2024-04-05 18:29:31.153668: train_loss 0.6482
2024-04-05 18:29:31.154152: val_loss 0.6462
2024-04-05 18:29:31.154734: Pseudo dice [0.5]
2024-04-05 18:29:31.155196: Epoch time: 81.21 s
2024-04-05 18:29:34.107872: 
2024-04-05 18:29:34.113439: Epoch 47
2024-04-05 18:29:34.113950: Current learning rate: 0.00056
2024-04-05 18:31:02.331490: meanmse:       0.023648204
2024-04-05 18:31:02.332756: meanr2:        0.8043815660470568
2024-04-05 18:31:02.333304: train_loss 0.6544
2024-04-05 18:31:02.333722: val_loss 0.7013
2024-04-05 18:31:02.334137: Pseudo dice [0.5]
2024-04-05 18:31:02.334561: Epoch time: 88.23 s
2024-04-05 18:31:04.879104: 
2024-04-05 18:31:04.879886: Epoch 48
2024-04-05 18:31:04.880461: Current learning rate: 0.00056
2024-04-05 18:32:28.604828: meanmse:       0.015389878
2024-04-05 18:32:28.605923: meanr2:        0.8749896705568595
2024-04-05 18:32:28.606386: train_loss 0.679
2024-04-05 18:32:28.606755: val_loss 0.6089
2024-04-05 18:32:28.607109: Pseudo dice [0.5]
2024-04-05 18:32:28.607525: Epoch time: 83.73 s
2024-04-05 18:32:30.770073: 
2024-04-05 18:32:30.770690: Epoch 49
2024-04-05 18:32:30.771129: Current learning rate: 0.00055
2024-04-05 18:33:49.596408: meanmse:       0.01800842
2024-04-05 18:33:49.597793: meanr2:        0.8557484560861179
2024-04-05 18:33:49.598530: train_loss 0.6522
2024-04-05 18:33:49.599054: val_loss 0.6315
2024-04-05 18:33:49.599591: Pseudo dice [0.5]
2024-04-05 18:33:49.600235: Epoch time: 78.83 s
2024-04-05 18:33:54.194482: 
2024-04-05 18:33:54.196965: Epoch 50
2024-04-05 18:33:54.197549: Current learning rate: 0.00054
2024-04-05 18:35:11.572929: meanmse:       0.021603292
2024-04-05 18:35:11.579233: meanr2:        0.8261793760044689
2024-04-05 18:35:11.580054: train_loss 0.5851
2024-04-05 18:35:11.580890: val_loss 0.7204
2024-04-05 18:35:11.581739: Pseudo dice [0.5]
2024-04-05 18:35:11.592081: Epoch time: 77.4 s
2024-04-05 18:35:15.282820: 
2024-04-05 18:35:15.283850: Epoch 51
2024-04-05 18:35:15.284432: Current learning rate: 0.00053
2024-04-05 18:36:33.350566: meanmse:       0.021157878
2024-04-05 18:36:33.352250: meanr2:        0.8305349007842554
2024-04-05 18:36:33.353260: train_loss 0.5763
2024-04-05 18:36:33.354090: val_loss 0.652
2024-04-05 18:36:33.354682: Pseudo dice [0.5]
2024-04-05 18:36:33.355392: Epoch time: 78.08 s
2024-04-05 18:36:36.411528: 
2024-04-05 18:36:36.412253: Epoch 52
2024-04-05 18:36:36.412656: Current learning rate: 0.00052
2024-04-05 18:37:56.533956: meanmse:       0.016675707
2024-04-05 18:37:56.535105: meanr2:        0.8674670596080069
2024-04-05 18:37:56.535673: train_loss 0.5702
2024-04-05 18:37:56.536141: val_loss 0.6046
2024-04-05 18:37:56.536569: Pseudo dice [0.5]
2024-04-05 18:37:56.537011: Epoch time: 80.13 s
2024-04-05 18:37:58.756866: 
2024-04-05 18:37:58.757858: Epoch 53
2024-04-05 18:37:58.758487: Current learning rate: 0.00051
2024-04-05 18:39:25.021377: meanmse:       0.02529719
2024-04-05 18:39:25.023228: meanr2:        0.7912922871304956
2024-04-05 18:39:25.024435: train_loss 0.5966
2024-04-05 18:39:25.025681: val_loss 0.7042
2024-04-05 18:39:25.026380: Pseudo dice [0.5]
2024-04-05 18:39:25.027118: Epoch time: 86.28 s
2024-04-05 18:39:28.604567: 
2024-04-05 18:39:28.605318: Epoch 54
2024-04-05 18:39:28.605815: Current learning rate: 0.0005
2024-04-05 18:40:48.240559: meanmse:       0.01903736
2024-04-05 18:40:48.241822: meanr2:        0.8431541910680931
2024-04-05 18:40:48.242452: train_loss 0.6094
2024-04-05 18:40:48.242891: val_loss 0.6248
2024-04-05 18:40:48.243322: Pseudo dice [0.5]
2024-04-05 18:40:48.243793: Epoch time: 79.65 s
2024-04-05 18:40:51.025497: 
2024-04-05 18:40:51.026477: Epoch 55
2024-04-05 18:40:51.027106: Current learning rate: 0.00049
2024-04-05 18:42:09.431705: meanmse:       0.018686267
2024-04-05 18:42:09.433635: meanr2:        0.8476316773087013
2024-04-05 18:42:09.436152: train_loss 0.5726
2024-04-05 18:42:09.436796: val_loss 0.6237
2024-04-05 18:42:09.440553: Pseudo dice [0.5]
2024-04-05 18:42:09.442678: Epoch time: 78.42 s
2024-04-05 18:42:12.661003: 
2024-04-05 18:42:12.661780: Epoch 56
2024-04-05 18:42:12.662295: Current learning rate: 0.00048
2024-04-05 18:43:32.506453: meanmse:       0.01794848
2024-04-05 18:43:32.507611: meanr2:        0.8528560160167132
2024-04-05 18:43:32.508235: train_loss 0.5856
2024-04-05 18:43:32.508628: val_loss 0.6656
2024-04-05 18:43:32.508986: Pseudo dice [0.5]
2024-04-05 18:43:32.517483: Epoch time: 79.85 s
2024-04-05 18:43:35.778433: 
2024-04-05 18:43:35.779687: Epoch 57
2024-04-05 18:43:35.780417: Current learning rate: 0.00047
2024-04-05 18:44:55.231869: meanmse:       0.017257774
2024-04-05 18:44:55.232822: meanr2:        0.8576316490208995
2024-04-05 18:44:55.233284: train_loss 0.5661
2024-04-05 18:44:55.233641: val_loss 0.6193
2024-04-05 18:44:55.233998: Pseudo dice [0.5]
2024-04-05 18:44:55.234370: Epoch time: 79.47 s
2024-04-05 18:44:58.332666: 
2024-04-05 18:44:58.333688: Epoch 58
2024-04-05 18:44:58.334157: Current learning rate: 0.00046
2024-04-05 18:46:19.473908: meanmse:       0.0229637
2024-04-05 18:46:19.474960: meanr2:        0.8178594592349863
2024-04-05 18:46:19.475508: train_loss 0.5547
2024-04-05 18:46:19.475924: val_loss 0.6747
2024-04-05 18:46:19.476331: Pseudo dice [0.5]
2024-04-05 18:46:19.489416: Epoch time: 81.15 s
2024-04-05 18:46:21.972879: 
2024-04-05 18:46:21.973562: Epoch 59
2024-04-05 18:46:21.973958: Current learning rate: 0.00045
2024-04-05 18:47:42.764555: meanmse:       0.020720014
2024-04-05 18:47:42.765767: meanr2:        0.8331139720265061
2024-04-05 18:47:42.766348: train_loss 0.5815
2024-04-05 18:47:42.766695: val_loss 0.7237
2024-04-05 18:47:42.767036: Pseudo dice [0.5]
2024-04-05 18:47:42.767466: Epoch time: 80.8 s
2024-04-05 18:47:46.014251: 
2024-04-05 18:47:46.015062: Epoch 60
2024-04-05 18:47:46.015597: Current learning rate: 0.00044
2024-04-05 18:49:06.973386: meanmse:       0.021871053
2024-04-05 18:49:06.974526: meanr2:        0.8270249868994756
2024-04-05 18:49:06.975223: train_loss 0.5758
2024-04-05 18:49:06.975728: val_loss 0.6231
2024-04-05 18:49:06.976232: Pseudo dice [0.5]
2024-04-05 18:49:06.976758: Epoch time: 80.97 s
2024-04-05 18:49:09.698635: 
2024-04-05 18:49:09.699397: Epoch 61
2024-04-05 18:49:09.699880: Current learning rate: 0.00043
2024-04-05 18:50:28.436689: meanmse:       0.019591408
2024-04-05 18:50:28.437795: meanr2:        0.840004467771094
2024-04-05 18:50:28.438615: train_loss 0.553
2024-04-05 18:50:28.439290: val_loss 0.6621
2024-04-05 18:50:28.540160: Pseudo dice [0.5]
2024-04-05 18:50:28.557062: Epoch time: 78.75 s
2024-04-05 18:50:32.140781: 
2024-04-05 18:50:32.141694: Epoch 62
2024-04-05 18:50:32.142217: Current learning rate: 0.00042
2024-04-05 18:51:49.069308: meanmse:       0.017663399
2024-04-05 18:51:49.070739: meanr2:        0.8582660373905845
2024-04-05 18:51:49.071419: train_loss 0.5367
2024-04-05 18:51:49.072016: val_loss 0.6605
2024-04-05 18:51:49.072589: Pseudo dice [0.5]
2024-04-05 18:51:49.073080: Epoch time: 76.94 s
2024-04-05 18:51:53.862870: 
2024-04-05 18:51:53.863816: Epoch 63
2024-04-05 18:51:53.864402: Current learning rate: 0.00041
2024-04-05 18:53:11.128513: meanmse:       0.024497323
2024-04-05 18:53:11.129555: meanr2:        0.8001025651948577
2024-04-05 18:53:11.130042: train_loss 0.5555
2024-04-05 18:53:11.130447: val_loss 0.6911
2024-04-05 18:53:11.130821: Pseudo dice [0.5]
2024-04-05 18:53:11.131225: Epoch time: 77.27 s
2024-04-05 18:53:14.482151: 
2024-04-05 18:53:14.482933: Epoch 64
2024-04-05 18:53:14.483348: Current learning rate: 0.0004
2024-04-05 18:54:34.580778: meanmse:       0.022286953
2024-04-05 18:54:34.582155: meanr2:        0.8255249726105064
2024-04-05 18:54:34.582783: train_loss 0.5286
2024-04-05 18:54:34.583278: val_loss 0.6536
2024-04-05 18:54:34.583809: Pseudo dice [0.5]
2024-04-05 18:54:34.584404: Epoch time: 80.11 s
2024-04-05 18:54:37.296637: 
2024-04-05 18:54:37.297562: Epoch 65
2024-04-05 18:54:37.298073: Current learning rate: 0.00039
2024-04-05 18:56:01.888731: meanmse:       0.01671318
2024-04-05 18:56:01.889659: meanr2:        0.8615821621899763
2024-04-05 18:56:01.890076: train_loss 0.5729
2024-04-05 18:56:01.890530: val_loss 0.5885
2024-04-05 18:56:01.890926: Pseudo dice [0.5]
2024-04-05 18:56:01.891290: Epoch time: 84.6 s
2024-04-05 18:56:04.796891: 
2024-04-05 18:56:04.797596: Epoch 66
2024-04-05 18:56:04.798128: Current learning rate: 0.00038
2024-04-05 18:57:24.289145: meanmse:       0.026572315
2024-04-05 18:57:24.290158: meanr2:        0.7898824873972646
2024-04-05 18:57:24.290634: train_loss 0.533
2024-04-05 18:57:24.291124: val_loss 0.7068
2024-04-05 18:57:24.291535: Pseudo dice [0.5]
2024-04-05 18:57:24.291939: Epoch time: 79.5 s
2024-04-05 18:57:26.852316: 
2024-04-05 18:57:26.853138: Epoch 67
2024-04-05 18:57:26.853599: Current learning rate: 0.00037
2024-04-05 18:58:47.799639: meanmse:       0.022305785
2024-04-05 18:58:47.800776: meanr2:        0.8218935636093266
2024-04-05 18:58:47.801419: train_loss 0.5576
2024-04-05 18:58:47.802087: val_loss 0.6574
2024-04-05 18:58:47.802590: Pseudo dice [0.5]
2024-04-05 18:58:47.803123: Epoch time: 80.96 s
2024-04-05 18:58:50.443653: 
2024-04-05 18:58:50.444413: Epoch 68
2024-04-05 18:58:50.445006: Current learning rate: 0.00036
2024-04-05 19:00:09.849561: meanmse:       0.017790295
2024-04-05 19:00:09.850987: meanr2:        0.8549553790685791
2024-04-05 19:00:09.851542: train_loss 0.5178
2024-04-05 19:00:09.852007: val_loss 0.6422
2024-04-05 19:00:09.852442: Pseudo dice [0.5]
2024-04-05 19:00:09.852952: Epoch time: 79.42 s
2024-04-05 19:00:12.369458: 
2024-04-05 19:00:12.370368: Epoch 69
2024-04-05 19:00:12.370968: Current learning rate: 0.00035
2024-04-05 19:01:32.323875: meanmse:       0.018264992
2024-04-05 19:01:32.325430: meanr2:        0.8499218608742758
2024-04-05 19:01:32.333967: train_loss 0.5468
2024-04-05 19:01:32.334755: val_loss 0.6249
2024-04-05 19:01:32.335365: Pseudo dice [0.5]
2024-04-05 19:01:32.335967: Epoch time: 79.97 s
2024-04-05 19:01:36.437946: 
2024-04-05 19:01:36.472770: Epoch 70
2024-04-05 19:01:36.476056: Current learning rate: 0.00034
2024-04-05 19:02:55.821332: meanmse:       0.021552892
2024-04-05 19:02:55.822819: meanr2:        0.8283836321893865
2024-04-05 19:02:55.823850: train_loss 0.5298
2024-04-05 19:02:55.824378: val_loss 0.6977
2024-04-05 19:02:55.824759: Pseudo dice [0.5]
2024-04-05 19:02:55.825259: Epoch time: 79.4 s
2024-04-05 19:02:59.351509: 
2024-04-05 19:02:59.352355: Epoch 71
2024-04-05 19:02:59.352833: Current learning rate: 0.00033
2024-04-05 19:04:20.280884: meanmse:       0.017401794
2024-04-05 19:04:20.282270: meanr2:        0.858028902474602
2024-04-05 19:04:20.282801: train_loss 0.5361
2024-04-05 19:04:20.283174: val_loss 0.574
2024-04-05 19:04:20.283526: Pseudo dice [0.5]
2024-04-05 19:04:20.283889: Epoch time: 80.94 s
2024-04-05 19:04:22.931944: 
2024-04-05 19:04:22.935406: Epoch 72
2024-04-05 19:04:22.936021: Current learning rate: 0.00032
2024-04-05 19:05:45.048761: meanmse:       0.019270739
2024-04-05 19:05:45.050114: meanr2:        0.8415587368988393
2024-04-05 19:05:45.050838: train_loss 0.5475
2024-04-05 19:05:45.051399: val_loss 0.6076
2024-04-05 19:05:45.051917: Pseudo dice [0.5]
2024-04-05 19:05:45.052464: Epoch time: 82.13 s
2024-04-05 19:05:47.566831: 
2024-04-05 19:05:47.567681: Epoch 73
2024-04-05 19:05:47.568237: Current learning rate: 0.00031
2024-04-05 19:07:07.678780: meanmse:       0.013143891
2024-04-05 19:07:07.680019: meanr2:        0.8924278059538339
2024-04-05 19:07:07.680594: train_loss 0.5197
2024-04-05 19:07:07.681074: val_loss 0.5916
2024-04-05 19:07:07.681500: Pseudo dice [0.5]
2024-04-05 19:07:07.681918: Epoch time: 80.12 s
2024-04-05 19:07:07.682369: Yayy! New best R2: 0.8924
2024-04-05 19:07:10.680063: 
2024-04-05 19:07:10.681107: Epoch 74
2024-04-05 19:07:10.681619: Current learning rate: 0.0003
2024-04-05 19:08:30.428789: meanmse:       0.022909354
2024-04-05 19:08:30.430243: meanr2:        0.816577968801682
2024-04-05 19:08:30.430994: train_loss 0.5088
2024-04-05 19:08:30.432072: val_loss 0.6374
2024-04-05 19:08:30.432698: Pseudo dice [0.5]
2024-04-05 19:08:30.433249: Epoch time: 79.76 s
2024-04-05 19:08:33.115401: 
2024-04-05 19:08:33.116140: Epoch 75
2024-04-05 19:08:33.116615: Current learning rate: 0.00029
2024-04-05 19:09:53.163816: meanmse:       0.024953144
2024-04-05 19:09:53.165294: meanr2:        0.8002148451365536
2024-04-05 19:09:53.165975: train_loss 0.5086
2024-04-05 19:09:53.166507: val_loss 0.7436
2024-04-05 19:09:53.167054: Pseudo dice [0.5]
2024-04-05 19:09:53.167590: Epoch time: 80.06 s
2024-04-05 19:09:55.344704: 
2024-04-05 19:09:55.345549: Epoch 76
2024-04-05 19:09:55.346062: Current learning rate: 0.00028
2024-04-05 19:11:16.037369: meanmse:       0.022097556
2024-04-05 19:11:16.038609: meanr2:        0.8153351722036852
2024-04-05 19:11:16.039145: train_loss 0.5107
2024-04-05 19:11:16.039728: val_loss 0.7299
2024-04-05 19:11:16.040358: Pseudo dice [0.5]
2024-04-05 19:11:16.040901: Epoch time: 80.7 s
2024-04-05 19:11:19.148053: 
2024-04-05 19:11:19.149070: Epoch 77
2024-04-05 19:11:19.149618: Current learning rate: 0.00027
2024-04-05 19:12:44.623923: meanmse:       0.017950878
2024-04-05 19:12:44.627371: meanr2:        0.8532677605080884
2024-04-05 19:12:44.629383: train_loss 0.4954
2024-04-05 19:12:44.629960: val_loss 0.6513
2024-04-05 19:12:44.630667: Pseudo dice [0.5]
2024-04-05 19:12:44.631221: Epoch time: 85.49 s
2024-04-05 19:12:47.135042: 
2024-04-05 19:12:47.135859: Epoch 78
2024-04-05 19:12:47.136431: Current learning rate: 0.00026
2024-04-05 19:14:11.251379: meanmse:       0.01838368
2024-04-05 19:14:11.252611: meanr2:        0.8563623336045368
2024-04-05 19:14:11.253221: train_loss 0.5156
2024-04-05 19:14:11.253715: val_loss 0.5751
2024-04-05 19:14:11.254187: Pseudo dice [0.5]
2024-04-05 19:14:11.254664: Epoch time: 84.13 s
2024-04-05 19:14:13.849921: 
2024-04-05 19:14:13.850792: Epoch 79
2024-04-05 19:14:13.851246: Current learning rate: 0.00025
2024-04-05 19:15:34.142151: meanmse:       0.020228134
2024-04-05 19:15:34.144474: meanr2:        0.8370783679466967
2024-04-05 19:15:34.145727: train_loss 0.5086
2024-04-05 19:15:34.146699: val_loss 0.6254
2024-04-05 19:15:34.147476: Pseudo dice [0.5]
2024-04-05 19:15:34.148462: Epoch time: 80.3 s
2024-04-05 19:15:37.253247: 
2024-04-05 19:15:37.254027: Epoch 80
2024-04-05 19:15:37.254529: Current learning rate: 0.00023
2024-04-05 19:16:57.317440: meanmse:       0.01901541
2024-04-05 19:16:57.318511: meanr2:        0.8449690137906873
2024-04-05 19:16:57.319137: train_loss 0.4828
2024-04-05 19:16:57.319589: val_loss 0.5934
2024-04-05 19:16:57.319973: Pseudo dice [0.5]
2024-04-05 19:16:57.320504: Epoch time: 80.07 s
2024-04-05 19:17:00.177567: 
2024-04-05 19:17:00.178557: Epoch 81
2024-04-05 19:17:00.179421: Current learning rate: 0.00022
2024-04-05 19:18:19.344859: meanmse:       0.02072032
2024-04-05 19:18:19.346182: meanr2:        0.8319512435317633
2024-04-05 19:18:19.346797: train_loss 0.5238
2024-04-05 19:18:19.347330: val_loss 0.6545
2024-04-05 19:18:19.347795: Pseudo dice [0.5]
2024-04-05 19:18:19.348296: Epoch time: 79.18 s
2024-04-05 19:18:22.389042: 
2024-04-05 19:18:22.420104: Epoch 82
2024-04-05 19:18:22.420694: Current learning rate: 0.00021
2024-04-05 19:19:44.007228: meanmse:       0.020296495
2024-04-05 19:19:44.018420: meanr2:        0.8352908622976514
2024-04-05 19:19:44.027245: train_loss 0.4862
2024-04-05 19:19:44.028603: val_loss 0.6025
2024-04-05 19:19:44.029725: Pseudo dice [0.5]
2024-04-05 19:19:44.030898: Epoch time: 81.65 s
2024-04-05 19:19:46.350075: 
2024-04-05 19:19:46.350975: Epoch 83
2024-04-05 19:19:46.351728: Current learning rate: 0.0002
2024-04-05 19:21:06.211713: meanmse:       0.021866577
2024-04-05 19:21:06.212820: meanr2:        0.8249316630547553
2024-04-05 19:21:06.213321: train_loss 0.4868
2024-04-05 19:21:06.213719: val_loss 0.672
2024-04-05 19:21:06.214125: Pseudo dice [0.5]
2024-04-05 19:21:06.214530: Epoch time: 79.87 s
2024-04-05 19:21:08.781555: 
2024-04-05 19:21:08.782349: Epoch 84
2024-04-05 19:21:08.782942: Current learning rate: 0.00019
2024-04-05 19:22:30.657591: meanmse:       0.016644476
2024-04-05 19:22:30.658999: meanr2:        0.862819585196619
2024-04-05 19:22:30.659685: train_loss 0.4911
2024-04-05 19:22:30.660277: val_loss 0.581
2024-04-05 19:22:30.660920: Pseudo dice [0.5]
2024-04-05 19:22:30.661572: Epoch time: 81.89 s
2024-04-05 19:22:33.556417: 
2024-04-05 19:22:33.557155: Epoch 85
2024-04-05 19:22:33.557539: Current learning rate: 0.00018
2024-04-05 19:23:53.928171: meanmse:       0.019486012
2024-04-05 19:23:53.929756: meanr2:        0.8409992913905697
2024-04-05 19:23:53.930610: train_loss 0.504
2024-04-05 19:23:53.931214: val_loss 0.6205
2024-04-05 19:23:53.932120: Pseudo dice [0.5]
2024-04-05 19:23:53.933227: Epoch time: 80.38 s
2024-04-05 19:23:57.139176: 
2024-04-05 19:23:57.139977: Epoch 86
2024-04-05 19:23:57.140723: Current learning rate: 0.00017
2024-04-05 19:25:16.420188: meanmse:       0.017937807
2024-04-05 19:25:16.421438: meanr2:        0.8552869769463349
2024-04-05 19:25:16.422073: train_loss 0.5048
2024-04-05 19:25:16.422561: val_loss 0.5941
2024-04-05 19:25:16.423116: Pseudo dice [0.5]
2024-04-05 19:25:16.423585: Epoch time: 79.29 s
2024-04-05 19:25:19.370926: 
2024-04-05 19:25:19.371859: Epoch 87
2024-04-05 19:25:19.372467: Current learning rate: 0.00016
2024-04-05 19:26:39.911222: meanmse:       0.019263474
2024-04-05 19:26:39.912266: meanr2:        0.8430747456599836
2024-04-05 19:26:39.912729: train_loss 0.4908
2024-04-05 19:26:39.913131: val_loss 0.6622
2024-04-05 19:26:39.913491: Pseudo dice [0.5]
2024-04-05 19:26:39.913926: Epoch time: 80.55 s
2024-04-05 19:26:42.113131: 
2024-04-05 19:26:42.113967: Epoch 88
2024-04-05 19:26:42.114547: Current learning rate: 0.00015
2024-04-05 19:28:02.643873: meanmse:       0.017629215
2024-04-05 19:28:02.645638: meanr2:        0.8539160479886255
2024-04-05 19:28:02.646181: train_loss 0.4641
2024-04-05 19:28:02.646621: val_loss 0.596
2024-04-05 19:28:02.647042: Pseudo dice [0.5]
2024-04-05 19:28:02.647461: Epoch time: 80.54 s
2024-04-05 19:28:05.235075: 
2024-04-05 19:28:05.235823: Epoch 89
2024-04-05 19:28:05.236290: Current learning rate: 0.00014
2024-04-05 19:29:23.631010: meanmse:       0.019572511
2024-04-05 19:29:23.632025: meanr2:        0.8424235676012942
2024-04-05 19:29:23.632568: train_loss 0.4527
2024-04-05 19:29:23.633019: val_loss 0.6248
2024-04-05 19:29:23.633407: Pseudo dice [0.5]
2024-04-05 19:29:23.633789: Epoch time: 78.41 s
2024-04-05 19:29:27.670106: 
2024-04-05 19:29:27.671038: Epoch 90
2024-04-05 19:29:27.671599: Current learning rate: 0.00013
2024-04-05 19:30:45.929730: meanmse:       0.017700037
2024-04-05 19:30:45.932780: meanr2:        0.8566961479806712
2024-04-05 19:30:45.934448: train_loss 0.4554
2024-04-05 19:30:45.937116: val_loss 0.6093
2024-04-05 19:30:45.939276: Pseudo dice [0.5]
2024-04-05 19:30:45.942067: Epoch time: 78.27 s
2024-04-05 19:30:48.825764: 
2024-04-05 19:30:48.840073: Epoch 91
2024-04-05 19:30:48.840853: Current learning rate: 0.00011
2024-04-05 19:32:10.187635: meanmse:       0.014936071
2024-04-05 19:32:10.188712: meanr2:        0.8756994029292852
2024-04-05 19:32:10.189234: train_loss 0.4388
2024-04-05 19:32:10.189675: val_loss 0.6056
2024-04-05 19:32:10.190127: Pseudo dice [0.5]
2024-04-05 19:32:10.190583: Epoch time: 81.37 s
2024-04-05 19:32:12.665692: 
2024-04-05 19:32:12.667110: Epoch 92
2024-04-05 19:32:12.667804: Current learning rate: 0.0001
2024-04-05 19:33:32.835830: meanmse:       0.02235342
2024-04-05 19:33:32.837223: meanr2:        0.8218413755932896
2024-04-05 19:33:32.837844: train_loss 0.4766
2024-04-05 19:33:32.838344: val_loss 0.6253
2024-04-05 19:33:32.838923: Pseudo dice [0.5]
2024-04-05 19:33:32.839577: Epoch time: 80.18 s
2024-04-05 19:33:35.088059: 
2024-04-05 19:33:35.089019: Epoch 93
2024-04-05 19:33:35.089607: Current learning rate: 9e-05
2024-04-05 19:34:54.795135: meanmse:       0.016988339
2024-04-05 19:34:54.796399: meanr2:        0.8625383923724463
2024-04-05 19:34:54.797005: train_loss 0.436
2024-04-05 19:34:54.817127: val_loss 0.6325
2024-04-05 19:34:54.817886: Pseudo dice [0.5]
2024-04-05 19:34:54.818476: Epoch time: 79.72 s
2024-04-05 19:34:58.210141: 
2024-04-05 19:34:58.213858: Epoch 94
2024-04-05 19:34:58.214489: Current learning rate: 8e-05
2024-04-05 19:36:17.402711: meanmse:       0.023793282
2024-04-05 19:36:17.413483: meanr2:        0.8146021433445011
2024-04-05 19:36:17.413968: train_loss 0.459
2024-04-05 19:36:17.414361: val_loss 0.6214
2024-04-05 19:36:17.414781: Pseudo dice [0.5]
2024-04-05 19:36:17.415183: Epoch time: 79.22 s
2024-04-05 19:36:20.229384: 
2024-04-05 19:36:20.230555: Epoch 95
2024-04-05 19:36:20.231176: Current learning rate: 7e-05
2024-04-05 19:37:40.808951: meanmse:       0.022195533
2024-04-05 19:37:40.809826: meanr2:        0.8222251773521138
2024-04-05 19:37:40.810248: train_loss 0.4428
2024-04-05 19:37:40.810901: val_loss 0.6895
2024-04-05 19:37:40.811612: Pseudo dice [0.5]
2024-04-05 19:37:40.812206: Epoch time: 80.59 s
2024-04-05 19:37:43.232840: 
2024-04-05 19:37:43.233493: Epoch 96
2024-04-05 19:37:43.233900: Current learning rate: 6e-05
2024-04-05 19:39:02.622786: meanmse:       0.0116557805
2024-04-05 19:39:02.623809: meanr2:        0.9041507214260978
2024-04-05 19:39:02.624255: train_loss 0.4503
2024-04-05 19:39:02.624734: val_loss 0.5894
2024-04-05 19:39:02.625198: Pseudo dice [0.5]
2024-04-05 19:39:02.625608: Epoch time: 79.4 s
2024-04-05 19:39:02.626077: Yayy! New best R2: 0.9042
2024-04-05 19:39:05.393593: 
2024-04-05 19:39:05.394658: Epoch 97
2024-04-05 19:39:05.395114: Current learning rate: 4e-05
2024-04-05 19:40:26.108237: meanmse:       0.018330254
2024-04-05 19:40:26.109447: meanr2:        0.8499557443225156
2024-04-05 19:40:26.110084: train_loss 0.43
2024-04-05 19:40:26.110624: val_loss 0.6039
2024-04-05 19:40:26.111152: Pseudo dice [0.5]
2024-04-05 19:40:26.111683: Epoch time: 80.73 s
2024-04-05 19:40:28.589388: 
2024-04-05 19:40:28.590333: Epoch 98
2024-04-05 19:40:28.590900: Current learning rate: 3e-05
2024-04-05 19:41:49.369205: meanmse:       0.018594895
2024-04-05 19:41:49.370738: meanr2:        0.851377890837308
2024-04-05 19:41:49.371530: train_loss 0.4405
2024-04-05 19:41:49.372376: val_loss 0.6388
2024-04-05 19:41:49.373134: Pseudo dice [0.5]
2024-04-05 19:41:49.373839: Epoch time: 80.79 s
2024-04-05 19:41:52.131293: 
2024-04-05 19:41:52.132138: Epoch 99
2024-04-05 19:41:52.132658: Current learning rate: 2e-05
2024-04-05 19:43:11.396653: meanmse:       0.016589932
2024-04-05 19:43:11.398303: meanr2:        0.866597677399819
2024-04-05 19:43:11.399101: train_loss 0.4265
2024-04-05 19:43:11.399647: val_loss 0.5764
2024-04-05 19:43:11.400178: Pseudo dice [0.5]
2024-04-05 19:43:11.400686: Epoch time: 79.28 s
2024-04-05 19:43:14.178785: Training done.
2024-04-05 19:43:14.311322: predicting 1111_0069
Traceback (most recent call last):
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 274, in <module>
    run_training_entry()
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 268, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 171, in run_training
    mp.spawn(run_ddp,
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 134, in run_ddp
    nnunet_trainer.perform_actual_validation(npz)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1385, in perform_actual_validation
    data = torch.from_numpy(data)
TypeError: expected np.ndarray (got str)

