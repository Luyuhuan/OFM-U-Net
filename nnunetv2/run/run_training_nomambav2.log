nohup: ignoring input
using port 60277
[W socket.cpp:601] [c10d] The client socket has failed to connect to [localhost]:60277 (errno: 101 - Network is unreachable).
I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 0 oversample 0.0
worker 0 batch_size 2

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 192, 192], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7958984971046448, 0.7958984971046448], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset701_AbdomenCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.7958984971046448, 0.7958984971046448], 'original_median_shape_after_transp': [97, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 97.29716491699219, 'median': 118.0, 'min': -1024.0, 'percentile_00_5': -958.0, 'percentile_99_5': 270.0, 'std': 137.8484649658203}}} 

2024-04-12 21:20:58.057105: unpacking dataset...
2024-04-12 21:20:58.057490: unpacking done...
2024-04-12 21:20:58.058517: do_dummy_2d_data_aug: False
2024-04-12 21:20:58.074503: Unable to plot network architecture:
2024-04-12 21:20:58.074923: No module named 'hiddenlayer'
2024-04-12 21:20:58.085369: 
2024-04-12 21:20:58.085926: Epoch 0
2024-04-12 21:20:58.086367: Current learning rate: 0.001
I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda
worker 1 oversample 0.6600000000000001
worker 1 batch_size 2

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

UMambaEnc: UMambaEnc(
  (encoder): ResidualMambaEncoder(
    (stem): StackedConvBlocks(
      (convs): Sequential(
        (0): ConvDropoutNormReLU(
          (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
          (all_modules): Sequential(
            (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (2): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (5): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (decoder): UNetResDecoder(
    (encoder): ResidualMambaEncoder(
      (stem): StackedConvBlocks(
        (convs): Sequential(
          (0): ConvDropoutNormReLU(
            (conv): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
            (all_modules): Sequential(
              (0): Conv3d(3, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (4): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (5): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  )
                )
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (stages): ModuleList(
      (0): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1-2): 2 x StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (3): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (4): StackedResidualBlocks(
        (blocks): Sequential(
          (0): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            (skip): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
            )
          )
          (1): BasicBlockD(
            (conv1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (conv2): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              )
            )
            (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (transpconvs): ModuleList(
      (0): ConvTranspose3d(32, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (1): ConvTranspose3d(64, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (2): ConvTranspose3d(128, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (3): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2))
      (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2))
    )
    (lzz_layers): ModuleList(
      (0): ModuleList(
        (0): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (1-2): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (1): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-3): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (2): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (3): ModuleList(
        (0-2): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (3): StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
      (4): ModuleList(
        (0-1): 2 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
        (2-4): 3 x StackedResidualBlocks(
          (blocks): Sequential(
            (0): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
              (skip): Sequential(
                (0): AvgPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)
              )
            )
            (1): BasicBlockD(
              (conv1): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (conv2): ConvDropoutNormReLU(
                (conv): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (all_modules): Sequential(
                  (0): Conv3d(40, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                )
              )
              (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)
            )
          )
        )
      )
    )
    (lzz_fc): ModuleList(
      (0-4): 5 x ModuleList(
        (0): Sequential(
          (0): Linear(in_features=288, out_features=72, bias=True)
          (1): Tanh()
        )
        (1): Sequential(
          (0): Linear(in_features=72, out_features=18, bias=True)
          (1): Tanh()
        )
        (2): Sequential(
          (0): Linear(in_features=18, out_features=1, bias=True)
          (1): Tanh()
        )
      )
    )
  )
)
do_dummy_2d_data_aug: False

Epoch 0
Current learning rate: 0.001
using pin_memory on device 1
using pin_memory on device 0
using pin_memory on device 1
meanmse:       0.12748721
meanr2:        -0.016039084937815792
train_loss 3.1905
val_loss 2.6044
Pseudo dice [0.5]
Epoch time: 107.04 s
Yayy! New best R2: -0.016

Epoch 1
Current learning rate: 0.00099
meanmse:       0.12657572
meanr2:        -0.013516424516698681
train_loss 2.5619
val_loss 2.5725
Pseudo dice [0.5]
Epoch time: 50.89 s
Yayy! New best R2: -0.0135

Epoch 2
Current learning rate: 0.00098
meanmse:       0.12500407
meanr2:        -0.02084892356691714
train_loss 2.5541
val_loss 2.5388
Pseudo dice [0.5]
Epoch time: 51.43 s

Epoch 3
Current learning rate: 0.00097
meanmse:       0.12566717
meanr2:        -0.016175243205202982
train_loss 2.5615
val_loss 2.5845
Pseudo dice [0.5]
Epoch time: 51.87 s

Epoch 4
Current learning rate: 0.00096
meanmse:       0.12595369
meanr2:        -0.018635552153990688
train_loss 2.5399
val_loss 2.5718
Pseudo dice [0.5]
Epoch time: 52.0 s

Epoch 5
Current learning rate: 0.00095
meanmse:       0.1274109
meanr2:        -0.02830875182413163
train_loss 2.5628
val_loss 2.549
Pseudo dice [0.5]
Epoch time: 52.1 s

Epoch 6
Current learning rate: 0.00095
meanmse:       0.12675218
meanr2:        -0.03055515844961189
train_loss 2.5474
val_loss 2.5581
Pseudo dice [0.5]
Epoch time: 52.29 s

Epoch 7
Current learning rate: 0.00094
meanmse:       0.12549198
meanr2:        -0.014390412434123468
train_loss 2.5353
val_loss 2.5548
Pseudo dice [0.5]
Epoch time: 50.91 s

Epoch 8
Current learning rate: 0.00093
meanmse:       0.12948652
meanr2:        -0.02470797355280686
train_loss 2.551
val_loss 2.5962
Pseudo dice [0.5]
Epoch time: 62.2 s

Epoch 9
Current learning rate: 0.00092
meanmse:       0.1232408
meanr2:        -0.008164723803873035
train_loss 2.5572
val_loss 2.549
Pseudo dice [0.5]
Epoch time: 64.48 s
Yayy! New best R2: -0.0082

Epoch 10
Current learning rate: 0.00091
meanmse:       0.12538058
meanr2:        -0.014434099551812669
train_loss 2.5518
val_loss 2.5679
Pseudo dice [0.5]
Epoch time: 62.17 s

Epoch 11
Current learning rate: 0.0009
meanmse:       0.12586364
meanr2:        -0.018551842758738512
train_loss 2.5676
val_loss 2.5484
Pseudo dice [0.5]
Epoch time: 57.26 s

Epoch 12
Current learning rate: 0.00089
meanmse:       0.12687904
meanr2:        -0.02363427867955865
train_loss 2.5432
val_loss 2.5936
Pseudo dice [0.5]
Epoch time: 59.18 s

Epoch 13
Current learning rate: 0.00088
meanmse:       0.12343733
meanr2:        -0.008645011084057332
train_loss 2.5538
val_loss 2.5215
Pseudo dice [0.5]
Epoch time: 64.57 s

Epoch 14
Current learning rate: 0.00087
meanmse:       0.13019119
meanr2:        -0.037000280099758
train_loss 2.5575
val_loss 2.5891
Pseudo dice [0.5]
Epoch time: 61.44 s

Epoch 15
Current learning rate: 0.00086
meanmse:       0.1263569
meanr2:        -0.011347100958618194
train_loss 2.5504
val_loss 2.5739
Pseudo dice [0.5]
Epoch time: 57.9 s

Epoch 16
Current learning rate: 0.00085
meanmse:       0.12753937
meanr2:        -0.02589714185831804
train_loss 2.5476
val_loss 2.5607
Pseudo dice [0.5]
Epoch time: 60.2 s

Epoch 17
Current learning rate: 0.00085
meanmse:       0.12150197
meanr2:        -0.012495305782431914
train_loss 2.5441
val_loss 2.5284
Pseudo dice [0.5]
Epoch time: 60.91 s

Epoch 18
Current learning rate: 0.00084
meanmse:       0.13610761
meanr2:        -0.08113739967148914
train_loss 2.5569
val_loss 2.6054
Pseudo dice [0.5]
Epoch time: 62.21 s

Epoch 19
Current learning rate: 0.00083
meanmse:       0.12505482
meanr2:        -0.018167589520356024
train_loss 2.5368
val_loss 2.526
Pseudo dice [0.5]
Epoch time: 60.68 s

Epoch 20
Current learning rate: 0.00082
meanmse:       0.12641414
meanr2:        -0.013730418083477379
train_loss 2.53
val_loss 2.5697
Pseudo dice [0.5]
Epoch time: 66.31 s

Epoch 21
Current learning rate: 0.00081
meanmse:       0.12727119
meanr2:        -0.010366872964594244
train_loss 2.5701
val_loss 2.5784
Pseudo dice [0.5]
Epoch time: 61.59 s

Epoch 22
Current learning rate: 0.0008
meanmse:       0.12492179
meanr2:        -0.0043839745461469485
train_loss 2.5516
val_loss 2.5673
Pseudo dice [0.5]
Epoch time: 61.22 s
Yayy! New best R2: -0.0044

Epoch 23
Current learning rate: 0.00079
meanmse:       0.12454471
meanr2:        -0.008469120518437345
train_loss 2.5388
val_loss 2.5558
Pseudo dice [0.5]
Epoch time: 59.94 s

Epoch 24
Current learning rate: 0.00078
meanmse:       0.12232255
meanr2:        -0.005866436406149109
train_loss 2.5471
val_loss 2.5217
Pseudo dice [0.5]
Epoch time: 61.74 s

Epoch 25
Current learning rate: 0.00077
meanmse:       0.119643
meanr2:        0.0380979298951231
train_loss 2.5242
val_loss 2.5155
Pseudo dice [0.5]
Epoch time: 64.13 s
Yayy! New best R2: 0.0381

Epoch 26
Current learning rate: 0.00076
meanmse:       0.10768631
meanr2:        0.11627785897479441
train_loss 2.4722
val_loss 2.4188
Pseudo dice [0.5]
Epoch time: 63.81 s
Yayy! New best R2: 0.1163

Epoch 27
Current learning rate: 0.00075
meanmse:       0.10787442
meanr2:        0.12858620177754895
train_loss 2.3923
val_loss 2.3616
Pseudo dice [0.5]
Epoch time: 63.26 s
Yayy! New best R2: 0.1286

Epoch 28
Current learning rate: 0.00074
meanmse:       0.10239964
meanr2:        0.16298134670094988
train_loss 2.3312
val_loss 2.332
Pseudo dice [0.5]
Epoch time: 60.0 s
Yayy! New best R2: 0.163

Epoch 29
Current learning rate: 0.00073
meanmse:       0.094847195
meanr2:        0.22598785599423313
train_loss 2.3171
val_loss 2.2704
Pseudo dice [0.5]
Epoch time: 59.24 s
Yayy! New best R2: 0.226

Epoch 30
Current learning rate: 0.00073
meanmse:       0.098580316
meanr2:        0.19967400136716196
train_loss 2.3133
val_loss 2.2944
Pseudo dice [0.5]
Epoch time: 62.17 s

Epoch 31
Current learning rate: 0.00072
meanmse:       0.09627194
meanr2:        0.22470098897031543
train_loss 2.2695
val_loss 2.2554
Pseudo dice [0.5]
Epoch time: 64.96 s

Epoch 32
Current learning rate: 0.00071
meanmse:       0.09435428
meanr2:        0.2417008042265584
train_loss 2.2411
val_loss 2.2524
Pseudo dice [0.5]
Epoch time: 62.74 s
Yayy! New best R2: 0.2417

Epoch 33
Current learning rate: 0.0007
meanmse:       0.08317389
meanr2:        0.3070529287050618
train_loss 2.2054
val_loss 2.1402
Pseudo dice [0.5]
Epoch time: 58.29 s
Yayy! New best R2: 0.3071

Epoch 34
Current learning rate: 0.00069
meanmse:       0.074723184
meanr2:        0.3910329565775779
train_loss 2.0679
val_loss 2.0303
Pseudo dice [0.5]
Epoch time: 61.25 s
Yayy! New best R2: 0.391

Epoch 35
Current learning rate: 0.00068
meanmse:       0.07089003
meanr2:        0.42320780551361636
train_loss 1.9987
val_loss 2.0219
Pseudo dice [0.5]
Epoch time: 65.16 s
Yayy! New best R2: 0.4232

Epoch 36
Current learning rate: 0.00067
meanmse:       0.065921046
meanr2:        0.46665651467716035
train_loss 1.929
val_loss 1.9295
Pseudo dice [0.5]
Epoch time: 61.3 s
Yayy! New best R2: 0.4667

Epoch 37
Current learning rate: 0.00066
meanmse:       0.060750354
meanr2:        0.4970408970744733
train_loss 1.8971
val_loss 1.8458
Pseudo dice [0.5]
Epoch time: 63.61 s
Yayy! New best R2: 0.497

Epoch 38
Current learning rate: 0.00065
meanmse:       0.059286475
meanr2:        0.5169577772426209
train_loss 1.8383
val_loss 1.8148
Pseudo dice [0.5]
Epoch time: 62.99 s
Yayy! New best R2: 0.517

Epoch 39
Current learning rate: 0.00064
meanmse:       0.056439172
meanr2:        0.5353195193625471
train_loss 1.7304
val_loss 1.7515
Pseudo dice [0.5]
Epoch time: 64.51 s
Yayy! New best R2: 0.5353

Epoch 40
Current learning rate: 0.00063
meanmse:       0.056060497
meanr2:        0.5545477686487013
train_loss 1.6434
val_loss 1.6763
Pseudo dice [0.5]
Epoch time: 60.69 s
Yayy! New best R2: 0.5545

Epoch 41
Current learning rate: 0.00062
meanmse:       0.04379253
meanr2:        0.6495645771503997
train_loss 1.5131
val_loss 1.4897
Pseudo dice [0.5]
Epoch time: 62.4 s
Yayy! New best R2: 0.6496

Epoch 42
Current learning rate: 0.00061
meanmse:       0.050228044
meanr2:        0.5998063762916126
train_loss 1.4433
val_loss 1.4852
Pseudo dice [0.5]
Epoch time: 61.6 s

Epoch 43
Current learning rate: 0.0006
meanmse:       0.033394385
meanr2:        0.7307331995484007
train_loss 1.3491
val_loss 1.2792
Pseudo dice [0.5]
Epoch time: 63.42 s
Yayy! New best R2: 0.7307

Epoch 44
Current learning rate: 0.00059
meanmse:       0.03600071
meanr2:        0.7068720503529223
train_loss 1.2211
val_loss 1.2134
Pseudo dice [0.5]
Epoch time: 64.46 s

Epoch 45
Current learning rate: 0.00058
meanmse:       0.036497526
meanr2:        0.7106143254253361
train_loss 1.1298
val_loss 1.1149
Pseudo dice [0.5]
Epoch time: 62.02 s

Epoch 46
Current learning rate: 0.00057
meanmse:       0.033556685
meanr2:        0.7297139915140797
train_loss 0.9852
val_loss 1.022
Pseudo dice [0.5]
Epoch time: 61.21 s

Epoch 47
Current learning rate: 0.00056
meanmse:       0.029883279
meanr2:        0.756244068038356
train_loss 0.9115
val_loss 0.9588
Pseudo dice [0.5]
Epoch time: 68.33 s
Yayy! New best R2: 0.7562

Epoch 48
Current learning rate: 0.00056
meanmse:       0.030275334
meanr2:        0.7560553294552711
train_loss 0.9298
val_loss 1.0367
Pseudo dice [0.5]
Epoch time: 64.65 s

Epoch 49
Current learning rate: 0.00055
meanmse:       0.028508259
meanr2:        0.7702775833936073
train_loss 0.9152
val_loss 0.9393
Pseudo dice [0.5]
Epoch time: 61.3 s
Yayy! New best R2: 0.7703

Epoch 50
Current learning rate: 0.00054
meanmse:       0.026831323
meanr2:        0.779892149986134
train_loss 0.8451
val_loss 0.8331
Pseudo dice [0.5]
Epoch time: 60.85 s
Yayy! New best R2: 0.7799

Epoch 51
Current learning rate: 0.00053
meanmse:       0.01858884
meanr2:        0.8474610652012994
train_loss 0.765
val_loss 0.7484
Pseudo dice [0.5]
Epoch time: 67.47 s
Yayy! New best R2: 0.8475

Epoch 52
Current learning rate: 0.00052
meanmse:       0.027199931
meanr2:        0.7786161689106432
train_loss 0.7741
val_loss 0.8365
Pseudo dice [0.5]
Epoch time: 63.75 s

Epoch 53
Current learning rate: 0.00051
meanmse:       0.029839825
meanr2:        0.7598819672066086
train_loss 0.726
val_loss 0.8855
Pseudo dice [0.5]
Epoch time: 64.49 s

Epoch 54
Current learning rate: 0.0005
meanmse:       0.028148472
meanr2:        0.7714713405802619
train_loss 0.711
val_loss 0.8072
Pseudo dice [0.5]
Epoch time: 66.05 s

Epoch 55
Current learning rate: 0.00049
meanmse:       0.027363192
meanr2:        0.776938520662361
train_loss 0.6725
val_loss 0.8628
Pseudo dice [0.5]
Epoch time: 61.7 s

Epoch 56
Current learning rate: 0.00048
meanmse:       0.022521736
meanr2:        0.8183088407695597
train_loss 0.6728
val_loss 0.7119
Pseudo dice [0.5]
Epoch time: 65.71 s

Epoch 57
Current learning rate: 0.00047
meanmse:       0.026749669
meanr2:        0.7800320635052309
train_loss 0.6236
val_loss 0.7679
Pseudo dice [0.5]
Epoch time: 61.41 s

Epoch 58
Current learning rate: 0.00046
meanmse:       0.023238696
meanr2:        0.811241661802645
train_loss 0.6262
val_loss 0.7245
Pseudo dice [0.5]
Epoch time: 61.62 s

Epoch 59
Current learning rate: 0.00045
meanmse:       0.030990047
meanr2:        0.7586232261855588
train_loss 0.6553
val_loss 0.7482
Pseudo dice [0.5]
Epoch time: 61.77 s

Epoch 60
Current learning rate: 0.00044
meanmse:       0.026847
meanr2:        0.7823259001217391
train_loss 0.6029
val_loss 0.8856
Pseudo dice [0.5]
Epoch time: 66.91 s

Epoch 61
Current learning rate: 0.00043
meanmse:       0.021143537
meanr2:        0.8286417667371139
train_loss 0.6306
val_loss 0.6553
Pseudo dice [0.5]
Epoch time: 66.1 s

Epoch 62
Current learning rate: 0.00042
meanmse:       0.016954325
meanr2:        0.864400115125633
train_loss 0.6191
val_loss 0.6795
Pseudo dice [0.5]
Epoch time: 63.01 s
Yayy! New best R2: 0.8644

Epoch 63
Current learning rate: 0.00041
meanmse:       0.022517355
meanr2:        0.8167346227167034
train_loss 0.61
val_loss 0.6866
Pseudo dice [0.5]
Epoch time: 70.16 s

Epoch 64
Current learning rate: 0.0004
meanmse:       0.032333966
meanr2:        0.7397955559712777
train_loss 0.6152
val_loss 0.7879
Pseudo dice [0.5]
Epoch time: 65.67 s

Epoch 65
Current learning rate: 0.00039
meanmse:       0.020764997
meanr2:        0.8303212043158993
train_loss 0.589
val_loss 0.699
Pseudo dice [0.5]
Epoch time: 62.94 s

Epoch 66
Current learning rate: 0.00038
meanmse:       0.021862553
meanr2:        0.8248079033917789
train_loss 0.6122
val_loss 0.668
Pseudo dice [0.5]
Epoch time: 64.62 s

Epoch 67
Current learning rate: 0.00037
meanmse:       0.02833391
meanr2:        0.7652262001046218
train_loss 0.6082
val_loss 0.7198
Pseudo dice [0.5]
Epoch time: 64.67 s

Epoch 68
Current learning rate: 0.00036
meanmse:       0.025089206
meanr2:        0.7966624274189198
train_loss 0.5811
val_loss 0.6902
Pseudo dice [0.5]
Epoch time: 58.55 s

Epoch 69
Current learning rate: 0.00035
meanmse:       0.025891913
meanr2:        0.7925684395828739
train_loss 0.569
val_loss 0.6611
Pseudo dice [0.5]
Epoch time: 72.36 s

Epoch 70
Current learning rate: 0.00034
meanmse:       0.02242061
meanr2:        0.8181100104753761
train_loss 0.5474
val_loss 0.6442
Pseudo dice [0.5]
Epoch time: 67.12 s

Epoch 71
Current learning rate: 0.00033
meanmse:       0.024318928
meanr2:        0.8032949368755852
train_loss 0.5294
val_loss 0.7338
Pseudo dice [0.5]
Epoch time: 61.94 s

Epoch 72
Current learning rate: 0.00032
meanmse:       0.020609803
meanr2:        0.8342770762477393
train_loss 0.5566
val_loss 0.6586
Pseudo dice [0.5]
Epoch time: 69.58 s

Epoch 73
Current learning rate: 0.00031
meanmse:       0.02155099
meanr2:        0.82678162217858
train_loss 0.5366
val_loss 0.6758
Pseudo dice [0.5]
Epoch time: 67.36 s

Epoch 74
Current learning rate: 0.0003
meanmse:       0.020709055
meanr2:        0.8308143571487684
train_loss 0.5469
val_loss 0.6949
Pseudo dice [0.5]
Epoch time: 68.54 s

Epoch 75
Current learning rate: 0.00029
meanmse:       0.020247715
meanr2:        0.8326334398437436
train_loss 0.5355
val_loss 0.6666
Pseudo dice [0.5]
Epoch time: 65.05 s

Epoch 76
Current learning rate: 0.00028
meanmse:       0.028204167
meanr2:        0.7742265989459157
train_loss 0.4972
val_loss 0.6933
Pseudo dice [0.5]
Epoch time: 65.01 s

Epoch 77
Current learning rate: 0.00027
meanmse:       0.021095768
meanr2:        0.8300962904472597
train_loss 0.535
val_loss 0.6108
Pseudo dice [0.5]
Epoch time: 68.86 s

Epoch 78
Current learning rate: 0.00026
meanmse:       0.021275269
meanr2:        0.8261814088794946
train_loss 0.527
val_loss 0.632
Pseudo dice [0.5]
Epoch time: 63.84 s

Epoch 79
Current learning rate: 0.00025
meanmse:       0.029066311
meanr2:        0.7665350696775911
train_loss 0.4655
val_loss 0.7981
Pseudo dice [0.5]
Epoch time: 61.16 s

Epoch 80
Current learning rate: 0.00023
meanmse:       0.020327697
meanr2:        0.8365236720295557
train_loss 0.5234
val_loss 0.6343
Pseudo dice [0.5]
Epoch time: 72.13 s

Epoch 81
Current learning rate: 0.00022
meanmse:       0.023537017
meanr2:        0.8076469480041932
train_loss 0.5133
val_loss 0.7069
Pseudo dice [0.5]
Epoch time: 60.41 s

Epoch 82
Current learning rate: 0.00021
meanmse:       0.024114681
meanr2:        0.8053153233900298
train_loss 0.4704
val_loss 0.6638
Pseudo dice [0.5]
Epoch time: 58.9 s

Epoch 83
Current learning rate: 0.0002
meanmse:       0.02011718
meanr2:        0.8369420706705771
train_loss 0.4508
val_loss 0.6561
Pseudo dice [0.5]
Epoch time: 57.88 s

Epoch 84
Current learning rate: 0.00019
meanmse:       0.024423433
meanr2:        0.7993620720373247
train_loss 0.4342
val_loss 0.6309
Pseudo dice [0.5]
Epoch time: 59.21 s

Epoch 85
Current learning rate: 0.00018
meanmse:       0.025508614
meanr2:        0.7919861612601218
train_loss 0.4162
val_loss 0.7043
Pseudo dice [0.5]
Epoch time: 61.09 s

Epoch 86
Current learning rate: 0.00017
meanmse:       0.023042
meanr2:        0.8136880036229048
train_loss 0.4522
val_loss 0.6454
Pseudo dice [0.5]
Epoch time: 58.51 s

Epoch 87
Current learning rate: 0.00016
meanmse:       0.023266852
meanr2:        0.8134488449823291
train_loss 0.4163
val_loss 0.7221
Pseudo dice [0.5]
Epoch time: 60.84 s

Epoch 88
Current learning rate: 0.00015
meanmse:       0.021661298
meanr2:        0.8270749022495452
train_loss 0.4522
val_loss 0.6676
Pseudo dice [0.5]
Epoch time: 61.76 s

Epoch 89
Current learning rate: 0.00014
meanmse:       0.020598875
meanr2:        0.8342917344467153
train_loss 0.4547
val_loss 0.5786
Pseudo dice [0.5]
Epoch time: 59.85 s

Epoch 90
Current learning rate: 0.00013
meanmse:       0.018285166
meanr2:        0.8531483921926667
train_loss 0.426
val_loss 0.6397
Pseudo dice [0.5]
Epoch time: 57.5 s

Epoch 91
Current learning rate: 0.00011
meanmse:       0.02356391
meanr2:        0.8161834197411786
train_loss 0.4358
val_loss 0.6538
Pseudo dice [0.5]
Epoch time: 59.95 s

Epoch 92
Current learning rate: 0.0001
meanmse:       0.025808943
meanr2:        0.7922188703732398
train_loss 0.4375
val_loss 0.6583
Pseudo dice [0.5]
Epoch time: 59.59 s

Epoch 93
Current learning rate: 9e-05
meanmse:       0.032639004
meanr2:        0.7430436471621689
train_loss 0.4618
val_loss 0.784
Pseudo dice [0.5]
Epoch time: 60.06 s

Epoch 94
Current learning rate: 8e-05
meanmse:       0.024874963
meanr2:        0.7950507701937017
train_loss 0.405
val_loss 0.6774
Pseudo dice [0.5]
Epoch time: 58.54 s

Epoch 95
Current learning rate: 7e-05
meanmse:       0.02356756
meanr2:        0.812033983370087
train_loss 0.4452
val_loss 0.6325
Pseudo dice [0.5]
Epoch time: 58.19 s

Epoch 96
Current learning rate: 6e-05
meanmse:       0.02041338
meanr2:        0.837367668458845
train_loss 0.4199
val_loss 0.5976
Pseudo dice [0.5]
Epoch time: 60.59 s

Epoch 97
Current learning rate: 4e-05
meanmse:       0.017144514
meanr2:        0.8617307640617823
train_loss 0.4171
val_loss 0.6288
Pseudo dice [0.5]
Epoch time: 57.41 s

Epoch 98
Current learning rate: 3e-05
meanmse:       0.021600375
meanr2:        0.8241764819098834
train_loss 0.4303
val_loss 0.5904
Pseudo dice [0.5]
Epoch time: 60.19 s

Epoch 99
Current learning rate: 2e-05
meanmse:       0.026174538
meanr2:        0.7864171663367077
train_loss 0.4195
val_loss 0.7012
Pseudo dice [0.5]
Epoch time: 60.52 s
Training done.
predicting 20190409_105008_139
using pin_memory on device 0
2024-04-12 21:22:45.132830: meanmse:       0.12497678
2024-04-12 21:22:45.133854: meanr2:        -0.023235174180888454
2024-04-12 21:22:45.134384: train_loss 3.1905
2024-04-12 21:22:45.134852: val_loss 2.6044
2024-04-12 21:22:45.135370: Pseudo dice [0.5]
2024-04-12 21:22:45.135855: Epoch time: 107.05 s
2024-04-12 21:22:45.136222: Yayy! New best R2: -0.0232
2024-04-12 21:22:47.689628: 
2024-04-12 21:22:47.690330: Epoch 1
2024-04-12 21:22:47.690823: Current learning rate: 0.00099
2024-04-12 21:23:36.024353: meanmse:       0.12521172
2024-04-12 21:23:36.025304: meanr2:        -0.010031497016552942
2024-04-12 21:23:36.025729: train_loss 2.5619
2024-04-12 21:23:36.026072: val_loss 2.5725
2024-04-12 21:23:36.026388: Pseudo dice [0.5]
2024-04-12 21:23:36.026781: Epoch time: 48.34 s
2024-04-12 21:23:36.027123: Yayy! New best R2: -0.01
2024-04-12 21:23:39.023092: 
2024-04-12 21:23:39.024834: Epoch 2
2024-04-12 21:23:39.025525: Current learning rate: 0.00098
2024-04-12 21:24:27.454308: meanmse:       0.12511373
2024-04-12 21:24:27.455517: meanr2:        -0.019282627018045548
2024-04-12 21:24:27.456019: train_loss 2.5541
2024-04-12 21:24:27.456453: val_loss 2.5388
2024-04-12 21:24:27.456810: Pseudo dice [0.5]
2024-04-12 21:24:27.457224: Epoch time: 48.44 s
2024-04-12 21:24:30.556537: 
2024-04-12 21:24:30.557105: Epoch 3
2024-04-12 21:24:30.557472: Current learning rate: 0.00097
2024-04-12 21:25:19.327377: meanmse:       0.1292225
2024-04-12 21:25:19.331409: meanr2:        -0.018965427844738446
2024-04-12 21:25:19.332060: train_loss 2.5615
2024-04-12 21:25:19.332646: val_loss 2.5845
2024-04-12 21:25:19.429618: Pseudo dice [0.5]
2024-04-12 21:25:19.524705: Epoch time: 48.78 s
2024-04-12 21:25:22.199831: 
2024-04-12 21:25:22.200644: Epoch 4
2024-04-12 21:25:22.201163: Current learning rate: 0.00096
2024-04-12 21:26:11.332326: meanmse:       0.12558745
2024-04-12 21:26:11.333976: meanr2:        -0.004606993002826818
2024-04-12 21:26:11.335048: train_loss 2.5399
2024-04-12 21:26:11.335572: val_loss 2.5718
2024-04-12 21:26:11.336103: Pseudo dice [0.5]
2024-04-12 21:26:11.336675: Epoch time: 49.14 s
2024-04-12 21:26:11.337193: Yayy! New best R2: -0.0046
2024-04-12 21:26:14.921359: 
2024-04-12 21:26:14.921977: Epoch 5
2024-04-12 21:26:14.922399: Current learning rate: 0.00095
2024-04-12 21:27:03.432029: meanmse:       0.12416518
2024-04-12 21:27:03.432804: meanr2:        -0.019907820299448705
2024-04-12 21:27:03.433272: train_loss 2.5628
2024-04-12 21:27:03.433614: val_loss 2.549
2024-04-12 21:27:03.433937: Pseudo dice [0.5]
2024-04-12 21:27:03.434284: Epoch time: 48.52 s
2024-04-12 21:27:06.274020: 
2024-04-12 21:27:06.274848: Epoch 6
2024-04-12 21:27:06.275400: Current learning rate: 0.00095
2024-04-12 21:27:55.723957: meanmse:       0.123992376
2024-04-12 21:27:55.724903: meanr2:        -0.014160972695225987
2024-04-12 21:27:55.725387: train_loss 2.5474
2024-04-12 21:27:55.725733: val_loss 2.5581
2024-04-12 21:27:55.726089: Pseudo dice [0.5]
2024-04-12 21:27:55.726439: Epoch time: 49.46 s
2024-04-12 21:27:58.421101: 
2024-04-12 21:27:58.421869: Epoch 7
2024-04-12 21:27:58.422325: Current learning rate: 0.00094
2024-04-12 21:28:46.633909: meanmse:       0.12559749
2024-04-12 21:28:46.635172: meanr2:        -0.006067540172257816
2024-04-12 21:28:46.635778: train_loss 2.5353
2024-04-12 21:28:46.636375: val_loss 2.5548
2024-04-12 21:28:46.636936: Pseudo dice [0.5]
2024-04-12 21:28:46.637627: Epoch time: 48.22 s
2024-04-12 21:28:50.231870: 
2024-04-12 21:28:50.232625: Epoch 8
2024-04-12 21:28:50.233202: Current learning rate: 0.00093
2024-04-12 21:29:48.836485: meanmse:       0.12757981
2024-04-12 21:29:48.844698: meanr2:        -0.029341693637095587
2024-04-12 21:29:48.845235: train_loss 2.551
2024-04-12 21:29:48.845617: val_loss 2.5962
2024-04-12 21:29:48.845964: Pseudo dice [0.5]
2024-04-12 21:29:48.846345: Epoch time: 58.62 s
2024-04-12 21:29:52.165275: 
2024-04-12 21:29:52.166083: Epoch 9
2024-04-12 21:29:52.166680: Current learning rate: 0.00092
2024-04-12 21:30:53.320818: meanmse:       0.12589334
2024-04-12 21:30:53.322029: meanr2:        -0.009363492254470822
2024-04-12 21:30:53.322663: train_loss 2.5572
2024-04-12 21:30:53.330000: val_loss 2.549
2024-04-12 21:30:53.330573: Pseudo dice [0.5]
2024-04-12 21:30:53.331013: Epoch time: 61.16 s
2024-04-12 21:30:56.256082: 
2024-04-12 21:30:56.256817: Epoch 10
2024-04-12 21:30:56.257279: Current learning rate: 0.00091
2024-04-12 21:31:55.492452: meanmse:       0.12815548
2024-04-12 21:31:55.493407: meanr2:        -0.02546131966873029
2024-04-12 21:31:55.493873: train_loss 2.5518
2024-04-12 21:31:55.494256: val_loss 2.5679
2024-04-12 21:31:55.494620: Pseudo dice [0.5]
2024-04-12 21:31:55.495000: Epoch time: 59.24 s
2024-04-12 21:31:57.999625: 
2024-04-12 21:31:58.000322: Epoch 11
2024-04-12 21:31:58.000743: Current learning rate: 0.0009
2024-04-12 21:32:52.749033: meanmse:       0.12424922
2024-04-12 21:32:52.750022: meanr2:        -0.009795443550848694
2024-04-12 21:32:52.750518: train_loss 2.5676
2024-04-12 21:32:52.750902: val_loss 2.5484
2024-04-12 21:32:52.751290: Pseudo dice [0.5]
2024-04-12 21:32:52.751707: Epoch time: 54.76 s
2024-04-12 21:32:57.137210: 
2024-04-12 21:32:57.137972: Epoch 12
2024-04-12 21:32:57.138483: Current learning rate: 0.00089
2024-04-12 21:33:51.926773: meanmse:       0.12871855
2024-04-12 21:33:51.927824: meanr2:        -0.021696355972334592
2024-04-12 21:33:51.928321: train_loss 2.5432
2024-04-12 21:33:51.928680: val_loss 2.5936
2024-04-12 21:33:51.929131: Pseudo dice [0.5]
2024-04-12 21:33:51.929575: Epoch time: 54.8 s
2024-04-12 21:33:55.224162: 
2024-04-12 21:33:55.224837: Epoch 13
2024-04-12 21:33:55.225276: Current learning rate: 0.00088
2024-04-12 21:34:56.492956: meanmse:       0.12268135
2024-04-12 21:34:56.543486: meanr2:        -0.020486997471206216
2024-04-12 21:34:56.544020: train_loss 2.5538
2024-04-12 21:34:56.544432: val_loss 2.5215
2024-04-12 21:34:56.544809: Pseudo dice [0.5]
2024-04-12 21:34:56.545194: Epoch time: 61.33 s
2024-04-12 21:34:59.380659: 
2024-04-12 21:34:59.381247: Epoch 14
2024-04-12 21:34:59.381637: Current learning rate: 0.00087
2024-04-12 21:35:57.929105: meanmse:       0.12580174
2024-04-12 21:35:57.929971: meanr2:        -0.007548369049770551
2024-04-12 21:35:57.930414: train_loss 2.5575
2024-04-12 21:35:57.930755: val_loss 2.5891
2024-04-12 21:35:57.931080: Pseudo dice [0.5]
2024-04-12 21:35:57.935293: Epoch time: 58.56 s
2024-04-12 21:36:00.787516: 
2024-04-12 21:36:00.788132: Epoch 15
2024-04-12 21:36:00.788602: Current learning rate: 0.00086
2024-04-12 21:36:55.827687: meanmse:       0.12610048
2024-04-12 21:36:55.828658: meanr2:        -0.016020110323164385
2024-04-12 21:36:55.829354: train_loss 2.5504
2024-04-12 21:36:55.829985: val_loss 2.5739
2024-04-12 21:36:55.833688: Pseudo dice [0.5]
2024-04-12 21:36:55.834218: Epoch time: 55.05 s
2024-04-12 21:37:00.147732: 
2024-04-12 21:37:00.148497: Epoch 16
2024-04-12 21:37:00.149084: Current learning rate: 0.00085
2024-04-12 21:37:56.024455: meanmse:       0.12499356
2024-04-12 21:37:56.025376: meanr2:        -0.026259338071784485
2024-04-12 21:37:56.025824: train_loss 2.5476
2024-04-12 21:37:56.026193: val_loss 2.5607
2024-04-12 21:37:56.026537: Pseudo dice [0.5]
2024-04-12 21:37:56.026893: Epoch time: 55.88 s
2024-04-12 21:37:58.849025: 
2024-04-12 21:37:58.849805: Epoch 17
2024-04-12 21:37:58.850263: Current learning rate: 0.00085
2024-04-12 21:38:56.934072: meanmse:       0.12897314
2024-04-12 21:38:56.934816: meanr2:        -0.03718944179609084
2024-04-12 21:38:56.935259: train_loss 2.5441
2024-04-12 21:38:56.935590: val_loss 2.5284
2024-04-12 21:38:56.935897: Pseudo dice [0.5]
2024-04-12 21:38:56.936226: Epoch time: 58.09 s
2024-04-12 21:39:00.051018: 
2024-04-12 21:39:00.051795: Epoch 18
2024-04-12 21:39:00.052327: Current learning rate: 0.00084
2024-04-12 21:39:59.148784: meanmse:       0.13055219
2024-04-12 21:39:59.149830: meanr2:        -0.06999716909985115
2024-04-12 21:39:59.150266: train_loss 2.5569
2024-04-12 21:39:59.150604: val_loss 2.6054
2024-04-12 21:39:59.150923: Pseudo dice [0.5]
2024-04-12 21:39:59.151261: Epoch time: 59.11 s
2024-04-12 21:40:02.934339: 
2024-04-12 21:40:02.935123: Epoch 19
2024-04-12 21:40:02.935594: Current learning rate: 0.00083
2024-04-12 21:40:59.830077: meanmse:       0.12297979
2024-04-12 21:40:59.831146: meanr2:        -0.009916329463587675
2024-04-12 21:40:59.831682: train_loss 2.5368
2024-04-12 21:40:59.832091: val_loss 2.526
2024-04-12 21:40:59.832500: Pseudo dice [0.5]
2024-04-12 21:40:59.832899: Epoch time: 56.9 s
2024-04-12 21:41:04.868567: 
2024-04-12 21:41:04.869525: Epoch 20
2024-04-12 21:41:04.870228: Current learning rate: 0.00082
2024-04-12 21:42:06.138310: meanmse:       0.12583078
2024-04-12 21:42:06.140162: meanr2:        -0.021869653543538727
2024-04-12 21:42:06.140851: train_loss 2.53
2024-04-12 21:42:06.141405: val_loss 2.5697
2024-04-12 21:42:06.141964: Pseudo dice [0.5]
2024-04-12 21:42:06.142459: Epoch time: 61.28 s
2024-04-12 21:42:09.042249: 
2024-04-12 21:42:09.043013: Epoch 21
2024-04-12 21:42:09.043470: Current learning rate: 0.00081
2024-04-12 21:43:07.726297: meanmse:       0.12578572
2024-04-12 21:43:07.728042: meanr2:        -0.013885561415230447
2024-04-12 21:43:07.728602: train_loss 2.5701
2024-04-12 21:43:07.729037: val_loss 2.5784
2024-04-12 21:43:07.729501: Pseudo dice [0.5]
2024-04-12 21:43:07.729912: Epoch time: 58.69 s
2024-04-12 21:43:10.577403: 
2024-04-12 21:43:10.578111: Epoch 22
2024-04-12 21:43:10.578627: Current learning rate: 0.0008
2024-04-12 21:44:08.948573: meanmse:       0.12769741
2024-04-12 21:44:08.949947: meanr2:        -0.023121933404545155
2024-04-12 21:44:08.950484: train_loss 2.5516
2024-04-12 21:44:08.950844: val_loss 2.5673
2024-04-12 21:44:08.951188: Pseudo dice [0.5]
2024-04-12 21:44:08.951559: Epoch time: 58.38 s
2024-04-12 21:44:12.087256: 
2024-04-12 21:44:12.088048: Epoch 23
2024-04-12 21:44:12.088572: Current learning rate: 0.00079
2024-04-12 21:45:08.887664: meanmse:       0.12600575
2024-04-12 21:45:08.889012: meanr2:        -0.0031872363090854213
2024-04-12 21:45:08.918173: train_loss 2.5388
2024-04-12 21:45:08.918829: val_loss 2.5558
2024-04-12 21:45:08.919305: Pseudo dice [0.5]
2024-04-12 21:45:08.919800: Epoch time: 56.84 s
2024-04-12 21:45:08.920906: Yayy! New best R2: -0.0032
2024-04-12 21:45:13.677571: 
2024-04-12 21:45:13.678457: Epoch 24
2024-04-12 21:45:13.679035: Current learning rate: 0.00078
2024-04-12 21:46:10.628299: meanmse:       0.12231778
2024-04-12 21:46:10.631518: meanr2:        -0.002008442758848211
2024-04-12 21:46:10.640297: train_loss 2.5471
2024-04-12 21:46:10.640966: val_loss 2.5217
2024-04-12 21:46:10.641472: Pseudo dice [0.5]
2024-04-12 21:46:10.641992: Epoch time: 56.97 s
2024-04-12 21:46:10.642517: Yayy! New best R2: -0.002
2024-04-12 21:46:14.969848: 
2024-04-12 21:46:14.970672: Epoch 25
2024-04-12 21:46:14.971121: Current learning rate: 0.00077
2024-04-12 21:47:14.756438: meanmse:       0.12185075
2024-04-12 21:47:14.757920: meanr2:        0.023799680973886607
2024-04-12 21:47:14.758604: train_loss 2.5242
2024-04-12 21:47:14.759119: val_loss 2.5155
2024-04-12 21:47:14.759574: Pseudo dice [0.5]
2024-04-12 21:47:14.760086: Epoch time: 59.8 s
2024-04-12 21:47:14.760601: Yayy! New best R2: 0.0238
2024-04-12 21:47:17.918195: 
2024-04-12 21:47:17.919045: Epoch 26
2024-04-12 21:47:17.919703: Current learning rate: 0.00076
2024-04-12 21:48:18.564893: meanmse:       0.11078906
2024-04-12 21:48:18.566206: meanr2:        0.12700987832127453
2024-04-12 21:48:18.566870: train_loss 2.4722
2024-04-12 21:48:18.567408: val_loss 2.4188
2024-04-12 21:48:18.567869: Pseudo dice [0.5]
2024-04-12 21:48:18.568278: Epoch time: 60.67 s
2024-04-12 21:48:18.568658: Yayy! New best R2: 0.127
2024-04-12 21:48:21.835157: 
2024-04-12 21:48:21.835810: Epoch 27
2024-04-12 21:48:21.836255: Current learning rate: 0.00075
2024-04-12 21:49:21.824765: meanmse:       0.101223975
2024-04-12 21:49:21.825949: meanr2:        0.16342666999070007
2024-04-12 21:49:21.826556: train_loss 2.3923
2024-04-12 21:49:21.827045: val_loss 2.3616
2024-04-12 21:49:21.827483: Pseudo dice [0.5]
2024-04-12 21:49:21.828043: Epoch time: 60.0 s
2024-04-12 21:49:21.828562: Yayy! New best R2: 0.1634
2024-04-12 21:49:24.929713: 
2024-04-12 21:49:24.930294: Epoch 28
2024-04-12 21:49:24.930670: Current learning rate: 0.00074
2024-04-12 21:50:21.827915: meanmse:       0.1046596
2024-04-12 21:50:21.829344: meanr2:        0.16650468399623428
2024-04-12 21:50:21.830000: train_loss 2.3312
2024-04-12 21:50:21.830645: val_loss 2.332
2024-04-12 21:50:21.831128: Pseudo dice [0.5]
2024-04-12 21:50:21.831686: Epoch time: 56.91 s
2024-04-12 21:50:21.832105: Yayy! New best R2: 0.1665
2024-04-12 21:50:25.623607: 
2024-04-12 21:50:25.624317: Epoch 29
2024-04-12 21:50:25.624750: Current learning rate: 0.00073
2024-04-12 21:51:21.065576: meanmse:       0.097790666
2024-04-12 21:51:21.068849: meanr2:        0.20672751081527993
2024-04-12 21:51:21.069341: train_loss 2.3171
2024-04-12 21:51:21.069693: val_loss 2.2704
2024-04-12 21:51:21.070046: Pseudo dice [0.5]
2024-04-12 21:51:21.070420: Epoch time: 55.45 s
2024-04-12 21:51:22.239681: Yayy! New best R2: 0.2067
2024-04-12 21:51:25.854136: 
2024-04-12 21:51:25.854845: Epoch 30
2024-04-12 21:51:25.855359: Current learning rate: 0.00073
2024-04-12 21:52:23.237441: meanmse:       0.097061925
2024-04-12 21:52:23.397875: meanr2:        0.22354292509338666
2024-04-12 21:52:23.458824: train_loss 2.3133
2024-04-12 21:52:23.511024: val_loss 2.2944
2024-04-12 21:52:23.511481: Pseudo dice [0.5]
2024-04-12 21:52:23.511921: Epoch time: 57.61 s
2024-04-12 21:52:23.512285: Yayy! New best R2: 0.2235
2024-04-12 21:52:26.361471: 
2024-04-12 21:52:26.362078: Epoch 31
2024-04-12 21:52:26.362626: Current learning rate: 0.00072
2024-04-12 21:53:28.195719: meanmse:       0.09421685
2024-04-12 21:53:28.196807: meanr2:        0.22421249402093138
2024-04-12 21:53:28.197331: train_loss 2.2695
2024-04-12 21:53:28.197755: val_loss 2.2554
2024-04-12 21:53:28.198271: Pseudo dice [0.5]
2024-04-12 21:53:28.198714: Epoch time: 61.84 s
2024-04-12 21:53:28.199108: Yayy! New best R2: 0.2242
2024-04-12 21:53:31.596180: 
2024-04-12 21:53:31.596772: Epoch 32
2024-04-12 21:53:31.597267: Current learning rate: 0.00071
2024-04-12 21:54:30.934996: meanmse:       0.09389215
2024-04-12 21:54:30.940436: meanr2:        0.23062064236307614
2024-04-12 21:54:30.941025: train_loss 2.2411
2024-04-12 21:54:30.941437: val_loss 2.2524
2024-04-12 21:54:30.941776: Pseudo dice [0.5]
2024-04-12 21:54:30.942178: Epoch time: 59.35 s
2024-04-12 21:54:30.942545: Yayy! New best R2: 0.2306
2024-04-12 21:54:34.938877: 
2024-04-12 21:54:34.939552: Epoch 33
2024-04-12 21:54:34.940027: Current learning rate: 0.0007
2024-04-12 21:55:29.221491: meanmse:       0.087630235
2024-04-12 21:55:29.222607: meanr2:        0.2884166596661171
2024-04-12 21:55:29.223244: train_loss 2.2054
2024-04-12 21:55:29.223704: val_loss 2.1402
2024-04-12 21:55:29.224200: Pseudo dice [0.5]
2024-04-12 21:55:29.224679: Epoch time: 54.29 s
2024-04-12 21:55:29.225140: Yayy! New best R2: 0.2884
2024-04-12 21:55:33.649972: 
2024-04-12 21:55:33.651840: Epoch 34
2024-04-12 21:55:33.652614: Current learning rate: 0.00069
2024-04-12 21:56:30.468273: meanmse:       0.07850292
2024-04-12 21:56:30.469818: meanr2:        0.3787227755325732
2024-04-12 21:56:30.470519: train_loss 2.0679
2024-04-12 21:56:30.471070: val_loss 2.0303
2024-04-12 21:56:30.471556: Pseudo dice [0.5]
2024-04-12 21:56:30.472026: Epoch time: 56.83 s
2024-04-12 21:56:30.472572: Yayy! New best R2: 0.3787
2024-04-12 21:56:33.724458: 
2024-04-12 21:56:33.725197: Epoch 35
2024-04-12 21:56:33.726087: Current learning rate: 0.00068
2024-04-12 21:57:35.628537: meanmse:       0.07642382
2024-04-12 21:57:35.629402: meanr2:        0.38973808185707526
2024-04-12 21:57:35.629840: train_loss 1.9987
2024-04-12 21:57:35.630267: val_loss 2.0219
2024-04-12 21:57:35.630638: Pseudo dice [0.5]
2024-04-12 21:57:35.630995: Epoch time: 61.91 s
2024-04-12 21:57:35.631327: Yayy! New best R2: 0.3897
2024-04-12 21:57:38.815843: 
2024-04-12 21:57:38.816514: Epoch 36
2024-04-12 21:57:38.816922: Current learning rate: 0.00067
2024-04-12 21:58:36.931342: meanmse:       0.070661426
2024-04-12 21:58:36.932832: meanr2:        0.43137024982291194
2024-04-12 21:58:36.933863: train_loss 1.929
2024-04-12 21:58:36.934471: val_loss 1.9295
2024-04-12 21:58:36.934971: Pseudo dice [0.5]
2024-04-12 21:58:36.935546: Epoch time: 58.12 s
2024-04-12 21:58:36.936073: Yayy! New best R2: 0.4314
2024-04-12 21:58:40.702673: 
2024-04-12 21:58:40.703274: Epoch 37
2024-04-12 21:58:40.703739: Current learning rate: 0.00066
2024-04-12 21:59:40.540602: meanmse:       0.06641814
2024-04-12 21:59:40.541598: meanr2:        0.4707593874463267
2024-04-12 21:59:40.542118: train_loss 1.8971
2024-04-12 21:59:40.542475: val_loss 1.8458
2024-04-12 21:59:40.542802: Pseudo dice [0.5]
2024-04-12 21:59:40.543149: Epoch time: 59.85 s
2024-04-12 21:59:40.543561: Yayy! New best R2: 0.4708
2024-04-12 21:59:44.366426: 
2024-04-12 21:59:44.417376: Epoch 38
2024-04-12 21:59:44.417740: Current learning rate: 0.00065
2024-04-12 22:00:43.526893: meanmse:       0.064258106
2024-04-12 22:00:43.527783: meanr2:        0.4846848385227011
2024-04-12 22:00:43.528236: train_loss 1.8383
2024-04-12 22:00:43.528608: val_loss 1.8148
2024-04-12 22:00:43.528944: Pseudo dice [0.5]
2024-04-12 22:00:43.529290: Epoch time: 59.17 s
2024-04-12 22:00:43.529642: Yayy! New best R2: 0.4847
2024-04-12 22:00:46.949885: 
2024-04-12 22:00:46.950583: Epoch 39
2024-04-12 22:00:46.951040: Current learning rate: 0.00064
2024-04-12 22:01:48.041535: meanmse:       0.057333026
2024-04-12 22:01:48.042585: meanr2:        0.5368698618319182
2024-04-12 22:01:48.043103: train_loss 1.7304
2024-04-12 22:01:48.043470: val_loss 1.7515
2024-04-12 22:01:48.043813: Pseudo dice [0.5]
2024-04-12 22:01:48.044187: Epoch time: 61.1 s
2024-04-12 22:01:48.487394: Yayy! New best R2: 0.5369
2024-04-12 22:01:51.433460: 
2024-04-12 22:01:51.434147: Epoch 40
2024-04-12 22:01:51.434636: Current learning rate: 0.00063
2024-04-12 22:02:48.729111: meanmse:       0.049706396
2024-04-12 22:02:48.730213: meanr2:        0.5955808754212832
2024-04-12 22:02:48.730812: train_loss 1.6434
2024-04-12 22:02:48.731251: val_loss 1.6763
2024-04-12 22:02:48.731716: Pseudo dice [0.5]
2024-04-12 22:02:48.732273: Epoch time: 57.3 s
2024-04-12 22:02:48.732734: Yayy! New best R2: 0.5956
2024-04-12 22:02:52.290976: 
2024-04-12 22:02:52.291902: Epoch 41
2024-04-12 22:02:52.292427: Current learning rate: 0.00062
2024-04-12 22:03:51.127212: meanmse:       0.04524316
2024-04-12 22:03:51.128073: meanr2:        0.6401177608420425
2024-04-12 22:03:51.128588: train_loss 1.5131
2024-04-12 22:03:51.128976: val_loss 1.4897
2024-04-12 22:03:51.129386: Pseudo dice [0.5]
2024-04-12 22:03:51.129755: Epoch time: 58.85 s
2024-04-12 22:03:51.130166: Yayy! New best R2: 0.6401
2024-04-12 22:03:54.740078: 
2024-04-12 22:03:54.741046: Epoch 42
2024-04-12 22:03:54.741627: Current learning rate: 0.00061
2024-04-12 22:04:52.731459: meanmse:       0.039792154
2024-04-12 22:04:52.732617: meanr2:        0.6817212183297786
2024-04-12 22:04:52.733133: train_loss 1.4433
2024-04-12 22:04:52.733557: val_loss 1.4852
2024-04-12 22:04:52.733921: Pseudo dice [0.5]
2024-04-12 22:04:52.734306: Epoch time: 58.0 s
2024-04-12 22:04:52.734675: Yayy! New best R2: 0.6817
2024-04-12 22:04:57.034154: 
2024-04-12 22:04:57.035158: Epoch 43
2024-04-12 22:04:57.035784: Current learning rate: 0.0006
2024-04-12 22:05:56.148283: meanmse:       0.039468925
2024-04-12 22:05:56.149330: meanr2:        0.6797256239066255
2024-04-12 22:05:56.149870: train_loss 1.3491
2024-04-12 22:05:56.150287: val_loss 1.2792
2024-04-12 22:05:56.150627: Pseudo dice [0.5]
2024-04-12 22:05:56.150974: Epoch time: 59.12 s
2024-04-12 22:05:58.776730: 
2024-04-12 22:05:58.777240: Epoch 44
2024-04-12 22:05:58.777681: Current learning rate: 0.00059
2024-04-12 22:07:00.608922: meanmse:       0.03481287
2024-04-12 22:07:00.610041: meanr2:        0.7156928011672881
2024-04-12 22:07:00.610583: train_loss 1.2211
2024-04-12 22:07:00.610974: val_loss 1.2134
2024-04-12 22:07:00.611354: Pseudo dice [0.5]
2024-04-12 22:07:00.611756: Epoch time: 61.84 s
2024-04-12 22:07:00.612153: Yayy! New best R2: 0.7157
2024-04-12 22:07:03.478976: 
2024-04-12 22:07:03.479706: Epoch 45
2024-04-12 22:07:03.480266: Current learning rate: 0.00058
2024-04-12 22:08:02.633242: meanmse:       0.030585868
2024-04-12 22:08:02.634400: meanr2:        0.7506355479541024
2024-04-12 22:08:02.634928: train_loss 1.1298
2024-04-12 22:08:02.635335: val_loss 1.1149
2024-04-12 22:08:02.635686: Pseudo dice [0.5]
2024-04-12 22:08:02.636058: Epoch time: 59.16 s
2024-04-12 22:08:02.636486: Yayy! New best R2: 0.7506
2024-04-12 22:08:06.825530: 
2024-04-12 22:08:06.826283: Epoch 46
2024-04-12 22:08:06.826756: Current learning rate: 0.00057
2024-04-12 22:09:03.846689: meanmse:       0.027812403
2024-04-12 22:09:03.851819: meanr2:        0.7756327302458703
2024-04-12 22:09:03.852321: train_loss 0.9852
2024-04-12 22:09:03.852695: val_loss 1.022
2024-04-12 22:09:03.853083: Pseudo dice [0.5]
2024-04-12 22:09:03.853455: Epoch time: 57.03 s
2024-04-12 22:09:03.853961: Yayy! New best R2: 0.7756
2024-04-12 22:09:08.259298: 
2024-04-12 22:09:08.259943: Epoch 47
2024-04-12 22:09:08.260329: Current learning rate: 0.00056
2024-04-12 22:10:12.180274: meanmse:       0.028702151
2024-04-12 22:10:12.181567: meanr2:        0.7680581963747973
2024-04-12 22:10:12.182191: train_loss 0.9115
2024-04-12 22:10:12.182643: val_loss 0.9588
2024-04-12 22:10:12.183067: Pseudo dice [0.5]
2024-04-12 22:10:12.183532: Epoch time: 63.93 s
2024-04-12 22:10:15.058557: 
2024-04-12 22:10:15.059352: Epoch 48
2024-04-12 22:10:15.059848: Current learning rate: 0.00056
2024-04-12 22:11:16.827841: meanmse:       0.03738193
2024-04-12 22:11:16.829174: meanr2:        0.6998770228649925
2024-04-12 22:11:16.829802: train_loss 0.9298
2024-04-12 22:11:16.830240: val_loss 1.0367
2024-04-12 22:11:16.830768: Pseudo dice [0.5]
2024-04-12 22:11:16.831249: Epoch time: 61.78 s
2024-04-12 22:11:20.146397: 
2024-04-12 22:11:20.147172: Epoch 49
2024-04-12 22:11:20.147711: Current learning rate: 0.00055
2024-04-12 22:12:18.123890: meanmse:       0.030496377
2024-04-12 22:12:18.125056: meanr2:        0.7548119595838091
2024-04-12 22:12:18.125727: train_loss 0.9152
2024-04-12 22:12:18.126214: val_loss 0.9393
2024-04-12 22:12:18.126566: Pseudo dice [0.5]
2024-04-12 22:12:18.126923: Epoch time: 57.99 s
2024-04-12 22:12:21.702795: 
2024-04-12 22:12:21.703651: Epoch 50
2024-04-12 22:12:21.704226: Current learning rate: 0.00054
2024-04-12 22:13:18.975449: meanmse:       0.022538064
2024-04-12 22:13:18.976671: meanr2:        0.8173552881115597
2024-04-12 22:13:18.977227: train_loss 0.8451
2024-04-12 22:13:18.977679: val_loss 0.8331
2024-04-12 22:13:18.978194: Pseudo dice [0.5]
2024-04-12 22:13:18.978686: Epoch time: 57.28 s
2024-04-12 22:13:18.979103: Yayy! New best R2: 0.8174
2024-04-12 22:13:22.732590: 
2024-04-12 22:13:22.735614: Epoch 51
2024-04-12 22:13:22.736238: Current learning rate: 0.00053
2024-04-12 22:14:26.442144: meanmse:       0.027396457
2024-04-12 22:14:26.443391: meanr2:        0.7760218953144087
2024-04-12 22:14:26.443928: train_loss 0.765
2024-04-12 22:14:26.444321: val_loss 0.7484
2024-04-12 22:14:26.444706: Pseudo dice [0.5]
2024-04-12 22:14:26.445153: Epoch time: 63.72 s
2024-04-12 22:14:29.195168: 
2024-04-12 22:14:29.195900: Epoch 52
2024-04-12 22:14:29.196349: Current learning rate: 0.00052
2024-04-12 22:15:30.190041: meanmse:       0.02684495
2024-04-12 22:15:30.191676: meanr2:        0.7784525266168111
2024-04-12 22:15:30.192488: train_loss 0.7741
2024-04-12 22:15:30.193068: val_loss 0.8365
2024-04-12 22:15:30.193633: Pseudo dice [0.5]
2024-04-12 22:15:30.194443: Epoch time: 61.0 s
2024-04-12 22:15:33.364155: 
2024-04-12 22:15:33.364868: Epoch 53
2024-04-12 22:15:33.365311: Current learning rate: 0.00051
2024-04-12 22:16:34.683153: meanmse:       0.03204411
2024-04-12 22:16:34.684241: meanr2:        0.7524108483121895
2024-04-12 22:16:34.684782: train_loss 0.726
2024-04-12 22:16:34.685225: val_loss 0.8855
2024-04-12 22:16:34.685616: Pseudo dice [0.5]
2024-04-12 22:16:34.686089: Epoch time: 61.33 s
2024-04-12 22:16:37.442879: 
2024-04-12 22:16:37.443649: Epoch 54
2024-04-12 22:16:37.444025: Current learning rate: 0.0005
2024-04-12 22:17:40.735026: meanmse:       0.025053078
2024-04-12 22:17:40.736091: meanr2:        0.7916382479241961
2024-04-12 22:17:40.737015: train_loss 0.711
2024-04-12 22:17:40.737526: val_loss 0.8072
2024-04-12 22:17:40.737969: Pseudo dice [0.5]
2024-04-12 22:17:40.738438: Epoch time: 63.3 s
2024-04-12 22:17:45.037115: 
2024-04-12 22:17:45.037969: Epoch 55
2024-04-12 22:17:45.038643: Current learning rate: 0.00049
2024-04-12 22:18:42.431136: meanmse:       0.032579053
2024-04-12 22:18:42.432132: meanr2:        0.7397043435018568
2024-04-12 22:18:42.432676: train_loss 0.6725
2024-04-12 22:18:42.433036: val_loss 0.8628
2024-04-12 22:18:42.433374: Pseudo dice [0.5]
2024-04-12 22:18:42.433731: Epoch time: 57.4 s
2024-04-12 22:18:45.245421: 
2024-04-12 22:18:45.246173: Epoch 56
2024-04-12 22:18:45.246696: Current learning rate: 0.00048
2024-04-12 22:19:48.141423: meanmse:       0.02438779
2024-04-12 22:19:48.142688: meanr2:        0.8035462761138583
2024-04-12 22:19:48.143318: train_loss 0.6728
2024-04-12 22:19:48.143793: val_loss 0.7119
2024-04-12 22:19:48.144312: Pseudo dice [0.5]
2024-04-12 22:19:48.144799: Epoch time: 62.9 s
2024-04-12 22:19:50.553210: 
2024-04-12 22:19:50.553937: Epoch 57
2024-04-12 22:19:50.554410: Current learning rate: 0.00047
2024-04-12 22:20:49.549311: meanmse:       0.024000682
2024-04-12 22:20:49.550421: meanr2:        0.8066020169938954
2024-04-12 22:20:49.551002: train_loss 0.6236
2024-04-12 22:20:49.551464: val_loss 0.7679
2024-04-12 22:20:49.551917: Pseudo dice [0.5]
2024-04-12 22:20:49.552416: Epoch time: 59.01 s
2024-04-12 22:20:52.175845: 
2024-04-12 22:20:52.176471: Epoch 58
2024-04-12 22:20:52.176893: Current learning rate: 0.00046
2024-04-12 22:21:51.158835: meanmse:       0.02449963
2024-04-12 22:21:51.160051: meanr2:        0.8006398365477334
2024-04-12 22:21:51.160706: train_loss 0.6262
2024-04-12 22:21:51.161175: val_loss 0.7245
2024-04-12 22:21:51.161607: Pseudo dice [0.5]
2024-04-12 22:21:51.162047: Epoch time: 58.99 s
2024-04-12 22:21:54.672653: 
2024-04-12 22:21:54.673304: Epoch 59
2024-04-12 22:21:54.673735: Current learning rate: 0.00045
2024-04-12 22:22:52.935137: meanmse:       0.021710025
2024-04-12 22:22:52.940812: meanr2:        0.8235903525000313
2024-04-12 22:22:52.941304: train_loss 0.6553
2024-04-12 22:22:52.941632: val_loss 0.7482
2024-04-12 22:22:52.941939: Pseudo dice [0.5]
2024-04-12 22:22:52.942279: Epoch time: 58.28 s
2024-04-12 22:22:53.429743: Yayy! New best R2: 0.8236
2024-04-12 22:22:57.143585: 
2024-04-12 22:22:57.144325: Epoch 60
2024-04-12 22:22:57.144886: Current learning rate: 0.00044
2024-04-12 22:23:59.841041: meanmse:       0.03671879
2024-04-12 22:23:59.850842: meanr2:        0.7055415348269487
2024-04-12 22:23:59.851315: train_loss 0.6029
2024-04-12 22:23:59.851644: val_loss 0.8856
2024-04-12 22:23:59.851951: Pseudo dice [0.5]
2024-04-12 22:23:59.852278: Epoch time: 62.71 s
2024-04-12 22:24:02.544078: 
2024-04-12 22:24:02.544672: Epoch 61
2024-04-12 22:24:02.545130: Current learning rate: 0.00043
2024-04-12 22:25:05.940228: meanmse:       0.021423329
2024-04-12 22:25:05.941608: meanr2:        0.8248901637367063
2024-04-12 22:25:05.942208: train_loss 0.6306
2024-04-12 22:25:05.942694: val_loss 0.6553
2024-04-12 22:25:05.943209: Pseudo dice [0.5]
2024-04-12 22:25:05.943832: Epoch time: 63.4 s
2024-04-12 22:25:05.944443: Yayy! New best R2: 0.8249
2024-04-12 22:25:09.142928: 
2024-04-12 22:25:09.143750: Epoch 62
2024-04-12 22:25:09.144343: Current learning rate: 0.00042
2024-04-12 22:26:08.952761: meanmse:       0.02802912
2024-04-12 22:26:08.954093: meanr2:        0.7792666170841316
2024-04-12 22:26:08.954629: train_loss 0.6191
2024-04-12 22:26:08.955120: val_loss 0.6795
2024-04-12 22:26:08.955584: Pseudo dice [0.5]
2024-04-12 22:26:08.956236: Epoch time: 59.82 s
2024-04-12 22:26:12.518464: 
2024-04-12 22:26:12.519343: Epoch 63
2024-04-12 22:26:12.519949: Current learning rate: 0.00041
2024-04-12 22:27:19.113110: meanmse:       0.022006666
2024-04-12 22:27:19.114352: meanr2:        0.8250796416586573
2024-04-12 22:27:19.114917: train_loss 0.61
2024-04-12 22:27:19.115401: val_loss 0.6866
2024-04-12 22:27:19.115844: Pseudo dice [0.5]
2024-04-12 22:27:19.116309: Epoch time: 66.67 s
2024-04-12 22:27:19.116800: Yayy! New best R2: 0.8251
2024-04-12 22:27:22.786423: 
2024-04-12 22:27:22.787277: Epoch 64
2024-04-12 22:27:22.787856: Current learning rate: 0.0004
2024-04-12 22:28:24.783120: meanmse:       0.02525063
2024-04-12 22:28:24.783991: meanr2:        0.7897757012182324
2024-04-12 22:28:24.784430: train_loss 0.6152
2024-04-12 22:28:24.784776: val_loss 0.7879
2024-04-12 22:28:24.785161: Pseudo dice [0.5]
2024-04-12 22:28:24.785527: Epoch time: 62.0 s
2024-04-12 22:28:27.591014: 
2024-04-12 22:28:27.591710: Epoch 65
2024-04-12 22:28:27.592159: Current learning rate: 0.00039
2024-04-12 22:29:27.724778: meanmse:       0.026212035
2024-04-12 22:29:27.725880: meanr2:        0.7927773395163445
2024-04-12 22:29:27.726426: train_loss 0.589
2024-04-12 22:29:27.726836: val_loss 0.699
2024-04-12 22:29:27.727222: Pseudo dice [0.5]
2024-04-12 22:29:27.727661: Epoch time: 60.14 s
2024-04-12 22:29:31.451871: 
2024-04-12 22:29:31.452464: Epoch 66
2024-04-12 22:29:31.452828: Current learning rate: 0.00038
2024-04-12 22:30:32.348231: meanmse:       0.021164842
2024-04-12 22:30:32.349241: meanr2:        0.8261402709493356
2024-04-12 22:30:32.349678: train_loss 0.6122
2024-04-12 22:30:32.350140: val_loss 0.668
2024-04-12 22:30:32.350553: Pseudo dice [0.5]
2024-04-12 22:30:32.350938: Epoch time: 60.9 s
2024-04-12 22:30:32.351332: Yayy! New best R2: 0.8261
2024-04-12 22:30:35.577746: 
2024-04-12 22:30:35.579194: Epoch 67
2024-04-12 22:30:35.579815: Current learning rate: 0.00037
2024-04-12 22:31:37.019403: meanmse:       0.021593207
2024-04-12 22:31:37.020427: meanr2:        0.8288855953850924
2024-04-12 22:31:37.020938: train_loss 0.6082
2024-04-12 22:31:37.021313: val_loss 0.7198
2024-04-12 22:31:37.021638: Pseudo dice [0.5]
2024-04-12 22:31:37.022004: Epoch time: 61.45 s
2024-04-12 22:31:37.022371: Yayy! New best R2: 0.8289
2024-04-12 22:31:40.585811: 
2024-04-12 22:31:40.586682: Epoch 68
2024-04-12 22:31:40.587107: Current learning rate: 0.00036
2024-04-12 22:32:35.568462: meanmse:       0.021501813
2024-04-12 22:32:35.569453: meanr2:        0.825735017793651
2024-04-12 22:32:35.569952: train_loss 0.5811
2024-04-12 22:32:35.581135: val_loss 0.6902
2024-04-12 22:32:35.581611: Pseudo dice [0.5]
2024-04-12 22:32:35.582019: Epoch time: 54.99 s
2024-04-12 22:32:39.466047: 
2024-04-12 22:32:39.466884: Epoch 69
2024-04-12 22:32:39.467385: Current learning rate: 0.00035
2024-04-12 22:33:47.926584: meanmse:       0.01818787
2024-04-12 22:33:47.927540: meanr2:        0.8525584309785873
2024-04-12 22:33:47.928053: train_loss 0.569
2024-04-12 22:33:47.928454: val_loss 0.6611
2024-04-12 22:33:47.928850: Pseudo dice [0.5]
2024-04-12 22:33:47.929240: Epoch time: 68.47 s
2024-04-12 22:33:48.334174: Yayy! New best R2: 0.8526
2024-04-12 22:33:51.406641: 
2024-04-12 22:33:51.407272: Epoch 70
2024-04-12 22:33:51.407759: Current learning rate: 0.00034
2024-04-12 22:34:55.045763: meanmse:       0.019748857
2024-04-12 22:34:55.046685: meanr2:        0.8395485968787697
2024-04-12 22:34:55.047181: train_loss 0.5474
2024-04-12 22:34:55.047588: val_loss 0.6442
2024-04-12 22:34:55.048011: Pseudo dice [0.5]
2024-04-12 22:34:55.048446: Epoch time: 63.65 s
2024-04-12 22:34:58.458816: 
2024-04-12 22:34:58.459559: Epoch 71
2024-04-12 22:34:58.460022: Current learning rate: 0.00033
2024-04-12 22:35:56.989880: meanmse:       0.030190853
2024-04-12 22:35:57.017917: meanr2:        0.7594693863234795
2024-04-12 22:35:57.018487: train_loss 0.5294
2024-04-12 22:35:57.018933: val_loss 0.7338
2024-04-12 22:35:57.019335: Pseudo dice [0.5]
2024-04-12 22:35:57.019758: Epoch time: 58.57 s
2024-04-12 22:36:00.185770: 
2024-04-12 22:36:00.186563: Epoch 72
2024-04-12 22:36:00.187094: Current learning rate: 0.00032
2024-04-12 22:37:06.569988: meanmse:       0.02333864
2024-04-12 22:37:06.570899: meanr2:        0.810808702239592
2024-04-12 22:37:06.571361: train_loss 0.5566
2024-04-12 22:37:06.571842: val_loss 0.6586
2024-04-12 22:37:06.572232: Pseudo dice [0.5]
2024-04-12 22:37:06.572619: Epoch time: 66.39 s
2024-04-12 22:37:09.624315: 
2024-04-12 22:37:09.624956: Epoch 73
2024-04-12 22:37:09.625376: Current learning rate: 0.00031
2024-04-12 22:38:13.932099: meanmse:       0.02523549
2024-04-12 22:38:13.933266: meanr2:        0.7923891974063906
2024-04-12 22:38:13.933752: train_loss 0.5366
2024-04-12 22:38:13.934315: val_loss 0.6758
2024-04-12 22:38:13.934798: Pseudo dice [0.5]
2024-04-12 22:38:13.935218: Epoch time: 64.32 s
2024-04-12 22:38:17.707165: 
2024-04-12 22:38:17.707856: Epoch 74
2024-04-12 22:38:17.708326: Current learning rate: 0.0003
2024-04-12 22:39:22.470297: meanmse:       0.028625261
2024-04-12 22:39:22.471375: meanr2:        0.7683367251639054
2024-04-12 22:39:22.471909: train_loss 0.5469
2024-04-12 22:39:22.472338: val_loss 0.6949
2024-04-12 22:39:22.472734: Pseudo dice [0.5]
2024-04-12 22:39:22.473128: Epoch time: 64.77 s
2024-04-12 22:39:25.386480: 
2024-04-12 22:39:25.387342: Epoch 75
2024-04-12 22:39:25.387822: Current learning rate: 0.00029
2024-04-12 22:40:27.523767: meanmse:       0.024799246
2024-04-12 22:40:27.524803: meanr2:        0.8044180289462223
2024-04-12 22:40:27.525266: train_loss 0.5355
2024-04-12 22:40:27.525609: val_loss 0.6666
2024-04-12 22:40:27.525948: Pseudo dice [0.5]
2024-04-12 22:40:27.526307: Epoch time: 62.15 s
2024-04-12 22:40:30.869094: 
2024-04-12 22:40:30.869719: Epoch 76
2024-04-12 22:40:30.870132: Current learning rate: 0.00028
2024-04-12 22:41:32.535578: meanmse:       0.021079766
2024-04-12 22:41:32.536696: meanr2:        0.8327165487743377
2024-04-12 22:41:32.537108: train_loss 0.4972
2024-04-12 22:41:32.537488: val_loss 0.6933
2024-04-12 22:41:32.537867: Pseudo dice [0.5]
2024-04-12 22:41:32.538203: Epoch time: 61.68 s
2024-04-12 22:41:35.714450: 
2024-04-12 22:41:35.714995: Epoch 77
2024-04-12 22:41:35.715394: Current learning rate: 0.00027
2024-04-12 22:42:41.390842: meanmse:       0.019812284
2024-04-12 22:42:41.392248: meanr2:        0.8378006703479595
2024-04-12 22:42:41.392841: train_loss 0.535
2024-04-12 22:42:41.393423: val_loss 0.6108
2024-04-12 22:42:41.393919: Pseudo dice [0.5]
2024-04-12 22:42:41.394392: Epoch time: 65.68 s
2024-04-12 22:42:44.163173: 
2024-04-12 22:42:44.164024: Epoch 78
2024-04-12 22:42:44.164450: Current learning rate: 0.00026
2024-04-12 22:43:45.233865: meanmse:       0.021849973
2024-04-12 22:43:45.234985: meanr2:        0.8286303462151551
2024-04-12 22:43:45.235495: train_loss 0.527
2024-04-12 22:43:45.235890: val_loss 0.632
2024-04-12 22:43:45.236287: Pseudo dice [0.5]
2024-04-12 22:43:45.236689: Epoch time: 61.08 s
2024-04-12 22:43:48.664720: 
2024-04-12 22:43:48.665379: Epoch 79
2024-04-12 22:43:48.665752: Current learning rate: 0.00025
2024-04-12 22:44:46.397278: meanmse:       0.030441241
2024-04-12 22:44:46.398411: meanr2:        0.7558416976141609
2024-04-12 22:44:46.398970: train_loss 0.4655
2024-04-12 22:44:46.399423: val_loss 0.7981
2024-04-12 22:44:46.399838: Pseudo dice [0.5]
2024-04-12 22:44:46.400289: Epoch time: 57.74 s
2024-04-12 22:44:50.999568: 
2024-04-12 22:44:51.000325: Epoch 80
2024-04-12 22:44:51.000781: Current learning rate: 0.00023
2024-04-12 22:45:58.531312: meanmse:       0.023655808
2024-04-12 22:45:58.532889: meanr2:        0.8123656472774982
2024-04-12 22:45:58.533480: train_loss 0.5234
2024-04-12 22:45:58.533937: val_loss 0.6343
2024-04-12 22:45:58.534420: Pseudo dice [0.5]
2024-04-12 22:45:58.534958: Epoch time: 67.54 s
2024-04-12 22:46:01.463185: 
2024-04-12 22:46:01.463934: Epoch 81
2024-04-12 22:46:01.464568: Current learning rate: 0.00022
2024-04-12 22:46:58.937738: meanmse:       0.02729572
2024-04-12 22:46:58.938855: meanr2:        0.7775731248432778
2024-04-12 22:46:58.939435: train_loss 0.5133
2024-04-12 22:46:58.939843: val_loss 0.7069
2024-04-12 22:46:58.940251: Pseudo dice [0.5]
2024-04-12 22:46:58.940706: Epoch time: 57.49 s
2024-04-12 22:47:01.601845: 
2024-04-12 22:47:01.602407: Epoch 82
2024-04-12 22:47:01.602855: Current learning rate: 0.00021
2024-04-12 22:47:57.842353: meanmse:       0.022321315
2024-04-12 22:47:57.843305: meanr2:        0.8212984473727913
2024-04-12 22:47:57.843837: train_loss 0.4704
2024-04-12 22:47:57.844234: val_loss 0.6638
2024-04-12 22:47:57.844571: Pseudo dice [0.5]
2024-04-12 22:47:57.844921: Epoch time: 56.25 s
2024-04-12 22:48:00.593707: 
2024-04-12 22:48:00.594308: Epoch 83
2024-04-12 22:48:00.594698: Current learning rate: 0.0002
2024-04-12 22:48:55.722666: meanmse:       0.026268927
2024-04-12 22:48:55.723422: meanr2:        0.7911422339578551
2024-04-12 22:48:55.723833: train_loss 0.4508
2024-04-12 22:48:55.724177: val_loss 0.6561
2024-04-12 22:48:55.724502: Pseudo dice [0.5]
2024-04-12 22:48:55.724870: Epoch time: 55.14 s
2024-04-12 22:48:59.353791: 
2024-04-12 22:48:59.354705: Epoch 84
2024-04-12 22:48:59.355291: Current learning rate: 0.00019
2024-04-12 22:49:54.932885: meanmse:       0.019496275
2024-04-12 22:49:54.933664: meanr2:        0.8423698158426192
2024-04-12 22:49:54.934158: train_loss 0.4342
2024-04-12 22:49:54.934510: val_loss 0.6309
2024-04-12 22:49:54.934814: Pseudo dice [0.5]
2024-04-12 22:49:54.935142: Epoch time: 55.59 s
2024-04-12 22:49:59.151096: 
2024-04-12 22:49:59.151846: Epoch 85
2024-04-12 22:49:59.152309: Current learning rate: 0.00018
2024-04-12 22:50:56.022412: meanmse:       0.025482243
2024-04-12 22:50:56.023463: meanr2:        0.7923462217754104
2024-04-12 22:50:56.023930: train_loss 0.4162
2024-04-12 22:50:56.024256: val_loss 0.7043
2024-04-12 22:50:56.024560: Pseudo dice [0.5]
2024-04-12 22:50:56.024897: Epoch time: 56.88 s
2024-04-12 22:50:59.357595: 
2024-04-12 22:50:59.417861: Epoch 86
2024-04-12 22:50:59.418510: Current learning rate: 0.00017
2024-04-12 22:51:54.536587: meanmse:       0.02117137
2024-04-12 22:51:54.537570: meanr2:        0.8304601648667401
2024-04-12 22:51:54.538171: train_loss 0.4522
2024-04-12 22:51:54.538703: val_loss 0.6454
2024-04-12 22:51:54.539192: Pseudo dice [0.5]
2024-04-12 22:51:54.539675: Epoch time: 55.19 s
2024-04-12 22:51:57.696602: 
2024-04-12 22:51:57.697317: Epoch 87
2024-04-12 22:51:57.697743: Current learning rate: 0.00016
2024-04-12 22:52:55.373147: meanmse:       0.030968009
2024-04-12 22:52:55.374025: meanr2:        0.7572854173414761
2024-04-12 22:52:55.374476: train_loss 0.4163
2024-04-12 22:52:55.374955: val_loss 0.7221
2024-04-12 22:52:55.375450: Pseudo dice [0.5]
2024-04-12 22:52:55.375910: Epoch time: 57.68 s
2024-04-12 22:52:57.999725: 
2024-04-12 22:52:58.000435: Epoch 88
2024-04-12 22:52:58.000833: Current learning rate: 0.00015
2024-04-12 22:53:57.131496: meanmse:       0.025728976
2024-04-12 22:53:57.134766: meanr2:        0.7928087063707658
2024-04-12 22:53:57.137210: train_loss 0.4522
2024-04-12 22:53:57.138096: val_loss 0.6676
2024-04-12 22:53:57.138769: Pseudo dice [0.5]
2024-04-12 22:53:57.139292: Epoch time: 59.14 s
2024-04-12 22:53:59.699696: 
2024-04-12 22:53:59.700522: Epoch 89
2024-04-12 22:53:59.701070: Current learning rate: 0.00014
2024-04-12 22:54:56.986100: meanmse:       0.018203557
2024-04-12 22:54:56.986858: meanr2:        0.8520536279115546
2024-04-12 22:54:56.987291: train_loss 0.4547
2024-04-12 22:54:56.987627: val_loss 0.5786
2024-04-12 22:54:56.987954: Pseudo dice [0.5]
2024-04-12 22:54:56.988293: Epoch time: 57.3 s
2024-04-12 22:55:00.153209: 
2024-04-12 22:55:00.154006: Epoch 90
2024-04-12 22:55:00.154512: Current learning rate: 0.00013
2024-04-12 22:55:54.487304: meanmse:       0.026592504
2024-04-12 22:55:54.493589: meanr2:        0.7870803340558967
2024-04-12 22:55:54.495514: train_loss 0.426
2024-04-12 22:55:54.495900: val_loss 0.6397
2024-04-12 22:55:54.496275: Pseudo dice [0.5]
2024-04-12 22:55:54.557401: Epoch time: 54.35 s
2024-04-12 22:55:58.423961: 
2024-04-12 22:55:58.424772: Epoch 91
2024-04-12 22:55:58.425229: Current learning rate: 0.00011
2024-04-12 22:56:54.436157: meanmse:       0.022477977
2024-04-12 22:56:54.437066: meanr2:        0.8163915908840711
2024-04-12 22:56:54.437503: train_loss 0.4358
2024-04-12 22:56:54.437920: val_loss 0.6538
2024-04-12 22:56:54.438254: Pseudo dice [0.5]
2024-04-12 22:56:54.438636: Epoch time: 56.02 s
2024-04-12 22:56:58.226056: 
2024-04-12 22:56:58.226620: Epoch 92
2024-04-12 22:56:58.236867: Current learning rate: 0.0001
2024-04-12 22:57:54.030147: meanmse:       0.020638065
2024-04-12 22:57:54.031002: meanr2:        0.8344074714858837
2024-04-12 22:57:54.031481: train_loss 0.4375
2024-04-12 22:57:54.031832: val_loss 0.6583
2024-04-12 22:57:54.032187: Pseudo dice [0.5]
2024-04-12 22:57:54.032534: Epoch time: 55.81 s
2024-04-12 22:57:56.732734: 
2024-04-12 22:57:56.733739: Epoch 93
2024-04-12 22:57:56.734256: Current learning rate: 9e-05
2024-04-12 22:58:54.093942: meanmse:       0.027871924
2024-04-12 22:58:54.095102: meanr2:        0.7745826542525013
2024-04-12 22:58:54.095641: train_loss 0.4618
2024-04-12 22:58:54.096052: val_loss 0.784
2024-04-12 22:58:54.096408: Pseudo dice [0.5]
2024-04-12 22:58:54.096785: Epoch time: 57.37 s
2024-04-12 22:58:56.733492: 
2024-04-12 22:58:56.734317: Epoch 94
2024-04-12 22:58:56.734821: Current learning rate: 8e-05
2024-04-12 22:59:52.636149: meanmse:       0.023129886
2024-04-12 22:59:52.637182: meanr2:        0.8120337031126482
2024-04-12 22:59:52.637731: train_loss 0.405
2024-04-12 22:59:52.638193: val_loss 0.6774
2024-04-12 22:59:52.638541: Pseudo dice [0.5]
2024-04-12 22:59:52.638912: Epoch time: 55.91 s
2024-04-12 22:59:55.068889: 
2024-04-12 22:59:55.069527: Epoch 95
2024-04-12 22:59:55.069972: Current learning rate: 7e-05
2024-04-12 23:00:50.828055: meanmse:       0.020390188
2024-04-12 23:00:50.829091: meanr2:        0.8372674929940213
2024-04-12 23:00:50.829618: train_loss 0.4452
2024-04-12 23:00:50.830026: val_loss 0.6325
2024-04-12 23:00:50.830417: Pseudo dice [0.5]
2024-04-12 23:00:50.830870: Epoch time: 55.77 s
2024-04-12 23:00:54.628840: 
2024-04-12 23:00:54.629721: Epoch 96
2024-04-12 23:00:54.630247: Current learning rate: 6e-05
2024-04-12 23:01:51.422874: meanmse:       0.019413099
2024-04-12 23:01:51.423880: meanr2:        0.8420533672286552
2024-04-12 23:01:51.424448: train_loss 0.4199
2024-04-12 23:01:51.424845: val_loss 0.5976
2024-04-12 23:01:51.425205: Pseudo dice [0.5]
2024-04-12 23:01:51.425522: Epoch time: 56.8 s
2024-04-12 23:01:54.406948: 
2024-04-12 23:01:54.407669: Epoch 97
2024-04-12 23:01:54.408122: Current learning rate: 4e-05
2024-04-12 23:02:48.831685: meanmse:       0.02802322
2024-04-12 23:02:48.832584: meanr2:        0.7790962630725379
2024-04-12 23:02:48.833055: train_loss 0.4171
2024-04-12 23:02:48.833420: val_loss 0.6288
2024-04-12 23:02:48.833777: Pseudo dice [0.5]
2024-04-12 23:02:48.834114: Epoch time: 54.45 s
2024-04-12 23:02:52.639609: 
2024-04-12 23:02:52.640657: Epoch 98
2024-04-12 23:02:52.641216: Current learning rate: 3e-05
2024-04-12 23:03:49.023006: meanmse:       0.017471151
2024-04-12 23:03:49.023839: meanr2:        0.8568724178804803
2024-04-12 23:03:49.024245: train_loss 0.4303
2024-04-12 23:03:49.024571: val_loss 0.5904
2024-04-12 23:03:49.024882: Pseudo dice [0.5]
2024-04-12 23:03:49.025212: Epoch time: 56.39 s
2024-04-12 23:03:49.025582: Yayy! New best R2: 0.8569
2024-04-12 23:03:53.048279: 
2024-04-12 23:03:53.048922: Epoch 99
2024-04-12 23:03:53.049371: Current learning rate: 2e-05
2024-04-12 23:04:49.542792: meanmse:       0.024967993
2024-04-12 23:04:49.543632: meanr2:        0.7989483760497474
2024-04-12 23:04:49.544104: train_loss 0.4195
2024-04-12 23:04:49.544461: val_loss 0.7012
2024-04-12 23:04:49.544791: Pseudo dice [0.5]
2024-04-12 23:04:49.545191: Epoch time: 56.5 s
2024-04-12 23:04:52.664048: Training done.
2024-04-12 23:04:52.685863: predicting 20190411_162615_159
Traceback (most recent call last):
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 274, in <module>
    run_training_entry()
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 268, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 171, in run_training
    mp.spawn(run_ddp,
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/root/anaconda3/envs/tryumamba/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/run/run_training.py", line 134, in run_ddp
    nnunet_trainer.perform_actual_validation(npz)
  File "/root/lzz2/cardiac_cycle/mamba/try_umamba/U-Mamba/umamba/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1385, in perform_actual_validation
    data = torch.from_numpy(data)
TypeError: expected np.ndarray (got str)

